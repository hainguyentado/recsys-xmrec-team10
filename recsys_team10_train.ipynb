{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueepVzHpieOB",
    "outputId": "635b442c-7f82-4d03-c6b6-3ded53bbe835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HAI.NH194039\\Documents\\recsyss\\recsys\\recsys-xmrec-team10\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\HAI.NH194039\\Documents\\recsyss\\recsys\\recsys-xmrec-team10\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "from zipfile import ZipFile\n",
    "from copy import deepcopy\n",
    "\n",
    "sys.path.insert(1, 'src')\n",
    "from model import Model\n",
    "from utils import *\n",
    "from data import *\n",
    "from train_baseline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhVFrsS_jWOx",
    "outputId": "b0d817f4-a808-424f-e6c9-5d24bcfc0777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "parser = create_arg_parser()\n",
    "args = parser.parse_args(['--cuda'])\n",
    "args.alias = 'nmf'\n",
    "args.tgt_market = 't1'\n",
    "args.src_markets = 'none' #ne' | 's1' | 's1_s2_s3'\n",
    "args.use_qrel = False\n",
    "args.tgt_market_valid = f'DATA/{args.tgt_market}/valid_run.tsv'\n",
    "args.tgt_market_test = f'DATA/{args.tgt_market}/test_run.tsv'\n",
    "args.exp_name = 'xxz'\n",
    "args.fastmode = True\n",
    "#args.idbank_pretrain = 'checkpoints/t1_none_xxz.pickle'\n",
    "#args.pretrain = 'checkpoints/t1_none_xxz.model'\n",
    "args.train_data_file = 'train_5core.tsv'\n",
    "args.num_negative = 8\n",
    "args.batch_size = 1024\n",
    "args.freeze_bottom = False\n",
    "args.latent_dim = 32\n",
    "args.latent_dim_mlp = 32\n",
    "args.mlp_layers = (64, 80, 48, 24)\n",
    "args.optimizer = 'adam'\n",
    "args.sample_func = lambda: random.uniform(0, 0.1)\n",
    "args.lr = 0.008\n",
    "args.num_epoch = 200\n",
    "args.l2_reg = 1e-7\n",
    "args.seed = 73\n",
    "if torch.cuda.is_available() and args.cuda:\n",
    "    torch.cuda.set_device(0)\n",
    "args.device = torch.device('cuda' if torch.cuda.is_available() and args.cuda else 'cpu')\n",
    "print(\"Device:\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1U1007418': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1005548': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002792': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007846': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009113': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006112': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004231': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004410': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009659': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1001476': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001034': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005319': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001161': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007330': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005339': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003165': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003256': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008683': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004170': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001719': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001981': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002120': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002234': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000336': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006803': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002612': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002875': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1007117': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007571': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1009114': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006594': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002979': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007767': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001113': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000896': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1000116': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007955': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000355': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005406': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008513': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008623': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1003856': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009014': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001992': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002920': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006296': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1009274': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009536': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003058': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002155': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007643': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1002854': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007968': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008131': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000491': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005187': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1000713': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002914': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002685': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1000965': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008871': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002163': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005284': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005534': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001711': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004655': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001789': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000574': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009048': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001804': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001181': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000884': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002641': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008112': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003816': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1006353': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000401': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007806': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1004511': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006877': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007456': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004920': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000169': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008499': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007081': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007540': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001682': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005657': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001988': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003982': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1009535': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001836': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000515': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003220': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008714': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003953': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1007813': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004811': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001366': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1009299': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005221': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003202': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1001778': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007488': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1007701': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000324': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004345': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004842': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007222': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1001852': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009144': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007386': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000153': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003386': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005525': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009308': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009411': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001392': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008792': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003972': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005299': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000258': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001195': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004662': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008962': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1002630': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004194': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000470': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005103': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001535': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1006075': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005542': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004485': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003652': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007710': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003352': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1006610': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000605': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002176': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009042': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008058': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003613': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005292': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006604': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1007442': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004589': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000732': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000261': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009198': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1003628': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008690': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007697': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004930': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008207': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1000962': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000649': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009090': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000453': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009378': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004878': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1005746': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007212': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008229': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004192': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000090': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009456': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008271': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006310': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1009244': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1002207': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008451': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006424': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005514': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009567': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003255': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1006648': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001039': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000969': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006560': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002103': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000524': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005108': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1001032': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005449': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000442': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1001133': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003079': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001148': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1009460': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1005903': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001595': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003416': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1003940': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000282': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008102': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004980': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1008646': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1008874': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003317': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008637': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007784': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000908': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1002442': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004995': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008127': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006459': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006339': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003388': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001380': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006055': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007705': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1008368': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003690': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004436': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1007547': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000068': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002502': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000062': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005859': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009089': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004390': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1006997': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007141': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1002631': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006288': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006864': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007775': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006454': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009453': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009612': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006209': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008745': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1000812': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007906': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001305': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001740': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1008189': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008325': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007641': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003607': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001857': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001912': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006513': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1005253': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001958': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003208': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000993': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008959': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1001695': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1006677': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1002690': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003884': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004807': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000230': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004557': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008481': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003826': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002400': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005071': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006862': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000556': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000805': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008083': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1000972': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004051': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009227': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000007': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001061': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002111': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008783': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000925': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003064': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005095': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1000215': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1002427': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007150': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007874': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1008881': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007541': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005700': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1007485': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003636': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000203': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000600': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1001068': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005384': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001704': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007714': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1008039': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000190': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001573': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1007281': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008372': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004254': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1004308': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002197': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003646': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003802': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000270': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003562': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001811': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006492': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006923': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000128': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1004981': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003347': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002701': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002923': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007649': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1001019': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1002654': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1008549': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1006447': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003726': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1000072': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000628': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1001757': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008568': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005650': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003263': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1001724': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1006445': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002096': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002175': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003554': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000564': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005393': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003836': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008894': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1005696': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009189': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1001521': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009297': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1005066': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1001220': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008456': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002537': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009140': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000179': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004011': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000748': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009491': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1003254': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003281': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006852': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009303': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007716': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007824': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005485': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005265': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002393': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007167': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008221': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1005097': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004461': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1009415': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009513': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1004609': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008044': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004721': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005686': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004432': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008956': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001433': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004326': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006347': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000468': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003660': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006135': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1000034': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004781': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1005084': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002744': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004072': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007452': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008445': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006041': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007076': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004375': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008686': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006340': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003141': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006735': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004351': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005811': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003156': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1000726': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1007100': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009093': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1004367': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009384': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006871': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008024': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001935': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001428': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008610': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009102': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008254': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008060': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004940': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005460': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000367': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003092': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1008701': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008295': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000438': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000126': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001894': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1008932': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1002715': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001736': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004323': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001602': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005841': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001929': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1006942': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003346': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001624': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004202': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008821': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008488': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000052': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002219': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004793': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002750': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002430': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007650': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1006587': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002190': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001018': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000814': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004744': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002559': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006963': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004607': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005462': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006761': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1002157': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005579': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005380': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006399': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006739': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1004915': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006830': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1009057': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008125': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008882': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006231': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1001715': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1003467': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004917': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008178': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008487': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1009310': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1004247': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009123': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007524': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1006223': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000773': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1009143': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1007877': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000480': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003892': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007862': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008292': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1004725': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009549': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000584': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006958': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1004592': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005198': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003877': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009712': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002907': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008412': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002820': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005661': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005304': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004120': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003544': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1008810': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002230': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008370': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1007360': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1000659': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008550': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001963': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1007229': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000479': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002888': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1004573': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007475': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007634': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000882': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002478': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008552': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006301': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009470': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004226': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008707': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000064': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003765': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005640': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007393': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1004146': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1002806': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003540': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004274': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009483': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006390': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1003910': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008543': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1001518': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004400': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1006156': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002776': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1006863': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007136': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005565': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007696': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1009151': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005836': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002254': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001978': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009383': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007077': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008861': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1009472': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006013': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007018': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003285': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1007255': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001387': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005646': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005154': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007178': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000592': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004356': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003229': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1003433': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009571': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007554': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002571': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003942': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1002726': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001824': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005933': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009050': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001799': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008841': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007224': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002241': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003728': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009517': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003797': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001160': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003901': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004314': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000976': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1003154': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003084': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006659': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009284': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003567': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005267': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007918': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005662': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009317': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002420': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009233': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001142': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001152': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008267': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002338': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001985': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007105': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006478': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007832': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003619': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007923': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004767': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1008374': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005589': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006476': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006157': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006134': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006515': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002087': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001365': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000571': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004814': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007972': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000225': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002848': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000145': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1008825': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001891': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008579': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008925': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1000980': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003918': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009510': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004200': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1001671': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005156': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001200': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008689': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003455': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1008636': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005069': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003838': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002414': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001797': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008244': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008365': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000374': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002586': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008459': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006837': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001063': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007841': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1000250': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005666': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008490': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004817': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1000107': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001419': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008893': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1006851': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001085': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005204': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001143': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001986': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003017': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002665': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004028': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002073': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1003321': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000898': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002677': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002095': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002011': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1000930': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009236': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004738': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000869': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003309': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004150': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004660': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000262': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007233': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1002679': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1003640': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000650': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008662': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1005298': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004735': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005505': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008449': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002271': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005450': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003785': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1008895': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1005870': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1002083': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009588': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007275': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002261': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002964': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000715': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1000844': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001903': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009516': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003769': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004422': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008114': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006101': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1000568': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003050': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009226': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004318': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006477': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000101': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1006215': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001565': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005321': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001484': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1002356': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007350': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007429': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008755': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003479': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002412': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008598': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1000642': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003491': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003307': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1008839': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005802': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005925': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003053': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006046': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003211': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008505': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008972': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1003155': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000632': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1006828': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004833': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004789': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006919': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006855': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005008': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007450': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004417': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008419': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008750': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009481': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002662': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009419': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1008164': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003683': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005724': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008913': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1001790': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1007503': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009482': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000699': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005345': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004946': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009235': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000390': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004457': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004802': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008634': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005501': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1003500': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003002': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008866': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003911': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004719': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000136': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000842': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005852': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006009': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1003872': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002313': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003477': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008301': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002998': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008679': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005535': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002632': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008626': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004757': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003919': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002698': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002787': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004307': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000897': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009197': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008606': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007555': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001733': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007631': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008638': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000454': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001235': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003369': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002428': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005615': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006191': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003967': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007075': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002246': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002472': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001881': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003470': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005862': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1000907': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009082': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1002203': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009215': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001970': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006070': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007466': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004420': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006900': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007974': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006358': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001258': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009346': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004250': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008006': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000084': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003143': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007477': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006533': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000158': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000973': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003019': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1008473': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004597': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002469': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008819': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004702': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1001918': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001042': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004346': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008245': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006924': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007399': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1005949': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009515': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005880': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1006491': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006417': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005996': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.38685280723454163,\n",
       "  'map_cut_10': 0.2},\n",
       " 't1U1005407': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001665': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007558': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001607': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007987': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004495': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003866': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007190': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003599': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007513': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001806': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006713': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006354': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1006631': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1003133': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009561': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003557': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1001536': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007673': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003531': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005603': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1004366': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007409': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007013': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1003422': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000975': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004190': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000316': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008675': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1006005': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1003587': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000712': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004329': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008570': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004021': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1002886': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1007137': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007688': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.31546487678572877,\n",
       "  'map_cut_10': 0.125},\n",
       " 't1U1003763': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000450': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008656': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001162': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008835': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009598': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000122': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001728': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003694': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002561': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008520': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1008654': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004929': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000306': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002563': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000457': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1006308': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002195': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3333333333333333,\n",
       "  'map_cut_10': 0.14285714285714285},\n",
       " 't1U1005713': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006667': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005869': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002692': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000789': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1002912': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001878': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.2890648263178879,\n",
       "  'map_cut_10': 0.1},\n",
       " 't1U1005642': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1002341': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006364': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1007041': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003415': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1007343': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003006': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002217': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000720': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008484': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009200': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004138': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005080': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005268': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003453': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3010299956639812,\n",
       "  'map_cut_10': 0.1111111111111111},\n",
       " 't1U1001046': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003287': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1002839': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1009045': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005090': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1009643': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1006998': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002672': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002487': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001000': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003391': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003516': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000939': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003522': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001864': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001524': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001399': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1001139': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1001858': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005660': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009678': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000082': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001310': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008954': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000521': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009381': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005140': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000563': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009193': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003330': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000458': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001059': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006148': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007912': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006361': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002178': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001629': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009283': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008831': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000727': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001753': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001948': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001402': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006292': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002364': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1008985': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004277': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004536': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003998': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002772': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009655': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1008139': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009063': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004879': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002596': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000829': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1006681': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004634': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1006124': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1002180': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.5,\n",
       "  'map_cut_10': 0.3333333333333333},\n",
       " 't1U1006305': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007132': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001980': {'P_5': 0.0,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.3562071871080222,\n",
       "  'map_cut_10': 0.16666666666666666},\n",
       " 't1U1006435': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000171': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005413': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004464': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1009550': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1005717': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005931': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007689': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001548': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1000580': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007699': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004401': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.43067655807339306,\n",
       "  'map_cut_10': 0.25},\n",
       " 't1U1007935': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1000625': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002689': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007268': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1003445': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007414': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009577': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1001477': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005944': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007078': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005800': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1009438': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1001562': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1007179': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004243': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005027': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004830': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005359': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1004229': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1007008': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1005109': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1005550': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1003371': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002225': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1002794': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 1.0,\n",
       "  'map_cut_10': 1.0},\n",
       " 't1U1004264': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1001412': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " 't1U1005825': {'P_5': 0.2,\n",
       "  'P_10': 0.1,\n",
       "  'P_20': 0.05,\n",
       "  'recall_5': 1.0,\n",
       "  'recall_10': 1.0,\n",
       "  'recall_20': 1.0,\n",
       "  'ndcg_cut_10': 0.6309297535714575,\n",
       "  'map_cut_10': 0.5},\n",
       " 't1U1006172': {'P_5': 0.0,\n",
       "  'P_10': 0.0,\n",
       "  'P_20': 0.0,\n",
       "  'recall_5': 0.0,\n",
       "  'recall_10': 0.0,\n",
       "  'recall_20': 0.0,\n",
       "  'ndcg_cut_10': 0.0,\n",
       "  'map_cut_10': 0.0},\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fQRHf_EjKrX",
    "outputId": "9c9c93b8-3a22-43aa-c2c9-04a46b170e98",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data_dir='DATA/', tgt_market='t1', src_markets='none', use_qrel=False, tgt_market_valid='DATA/t1/valid_run.tsv', tgt_market_test='DATA/t1/test_run.tsv', exp_name='xxz', train_data_file='train_5core.tsv', alias='nmf', pretrain=None, idbank_pretrain=None, freeze_bottom=False, num_epoch=200, batch_size=1024, lr=0.008, l2_reg=1e-07, optimizer='adam', latent_dim=32, latent_dim_mlp=32, num_negative=8, sample_func=<function <lambda> at 0x0000013ED7CB8670>, mlp_layers=(64, 80, 48, 24), drop_rate=0.2, cuda=True, seed=73, fastmode=True, device=device(type='cpu'), **{' fastmode': True})\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 32)\n",
      "  (gmf_embedding_item): Embedding(1386, 32)\n",
      "  (mlp_embedding_user): Embedding(2698, 32)\n",
      "  (mlp_embedding_item): Embedding(1386, 32)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=64, out_features=80, bias=True)\n",
      "    (1): Linear(in_features=80, out_features=48, bias=True)\n",
      "    (2): Linear(in_features=48, out_features=24, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=56, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.03101543610581773  Time:  7.724378347396851\n",
      "Total Valid Loss:  2.0357632603910236  Time:  1.5737898349761963\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.022504999318477735  Time:  4.325428247451782\n",
      "Total Valid Loss:  1.9842337292653542  Time:  1.6356239318847656\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.021296576462212325  Time:  4.559800863265991\n",
      "Total Valid Loss:  1.9982014000415802  Time:  1.72538423538208\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.019507004486429207  Time:  5.141247510910034\n",
      "Total Valid Loss:  1.9490669700834486  Time:  2.0136139392852783\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.017205869665940027  Time:  4.608671426773071\n",
      "Total Valid Loss:  1.9358541755764573  Time:  2.064476490020752\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.013864784867561966  Time:  4.513923645019531\n",
      "Total Valid Loss:  1.845996266161954  Time:  1.6974596977233887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.010490159579482726  Time:  4.408207654953003\n",
      "Total Valid Loss:  1.8060079680548773  Time:  1.6934704780578613\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.008201181202200968  Time:  4.272569894790649\n",
      "Total Valid Loss:  1.8285991648832958  Time:  1.7563016414642334\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.00697787212627816  Time:  4.3643248081207275\n",
      "Total Valid Loss:  1.779420600997077  Time:  1.8291072845458984\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.0061005518120320545  Time:  4.970703125\n",
      "Total Valid Loss:  1.7656451121524528  Time:  1.870004653930664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.005573627770463855  Time:  4.750324487686157\n",
      "Total Valid Loss:  1.7835385368929968  Time:  1.753277063369751\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.005169115255376852  Time:  4.876957416534424\n",
      "Total Valid Loss:  1.7236134233298126  Time:  1.917865514755249\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.0048191654038308674  Time:  5.0853986740112305\n",
      "Total Valid Loss:  1.7630820737944708  Time:  1.7652781009674072\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.004557029817877822  Time:  4.921834707260132\n",
      "Total Valid Loss:  1.740751149477782  Time:  1.9557666778564453\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.004383972775987807  Time:  5.452416658401489\n",
      "Total Valid Loss:  1.7227895182591897  Time:  2.515275001525879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.004252608938174958  Time:  5.922154903411865\n",
      "Total Valid Loss:  1.7258883438728474  Time:  2.73368763923645\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.004093617923568525  Time:  5.127285480499268\n",
      "Total Valid Loss:  1.7155986847700897  Time:  1.9707257747650146\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.003935444914342868  Time:  5.225023031234741\n",
      "Total Valid Loss:  1.7448870992219006  Time:  1.9198641777038574\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.003898476674409874  Time:  4.975689649581909\n",
      "Total Valid Loss:  1.7408064228517037  Time:  1.8301069736480713\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.0038026417565203644  Time:  5.63692045211792\n",
      "Total Valid Loss:  1.7056175006760492  Time:  1.8360891342163086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.00367182389714599  Time:  5.411522150039673\n",
      "Total Valid Loss:  1.712740582448465  Time:  1.7892131805419922\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.00361318675655807  Time:  4.678522109985352\n",
      "Total Valid Loss:  1.7285157795305606  Time:  2.008587598800659\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.003596794187236642  Time:  5.041513442993164\n",
      "Total Valid Loss:  1.67216565101235  Time:  1.8041753768920898\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.0036003363407566885  Time:  4.889917373657227\n",
      "Total Valid Loss:  1.7061975609373163  Time:  1.6864879131317139\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.003515440848187646  Time:  4.858004331588745\n",
      "Total Valid Loss:  1.6777946871739846  Time:  1.907895565032959\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.0034846579979006956  Time:  5.37761378288269\n",
      "Total Valid Loss:  1.697634075526838  Time:  1.8330960273742676\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.0034613174418622705  Time:  5.541177749633789\n",
      "Total Valid Loss:  1.6598610061186332  Time:  1.8959271907806396\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.003418036620805546  Time:  4.947764873504639\n",
      "Total Valid Loss:  1.7209298478232489  Time:  1.6645491123199463\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.0033603278688569636  Time:  5.053480386734009\n",
      "Total Valid Loss:  1.6730607085757785  Time:  1.697458028793335\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.0033829679424643  Time:  4.839054584503174\n",
      "Total Valid Loss:  1.688989062000204  Time:  1.8720307350158691\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.003348729721232818  Time:  4.848030090332031\n",
      "Total Valid Loss:  1.7020244201024373  Time:  1.9138824939727783\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.003373363804922714  Time:  5.560125350952148\n",
      "Total Valid Loss:  1.686350922893595  Time:  1.7174053192138672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.0033106560148621744  Time:  5.129277229309082\n",
      "Total Valid Loss:  1.6883412709942571  Time:  2.3228237628936768\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.003316106156289922  Time:  5.758557558059692\n",
      "Total Valid Loss:  1.6641421638153218  Time:  2.1083598136901855\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.0033070816391960562  Time:  5.685790061950684\n",
      "Total Valid Loss:  1.6844880393257848  Time:  1.7493202686309814\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.003266410620861574  Time:  5.902213096618652\n",
      "Total Valid Loss:  1.7003988987869687  Time:  2.1113507747650146\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.003286749621142628  Time:  5.807586908340454\n",
      "Total Valid Loss:  1.6957594520515866  Time:  2.0930261611938477\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.003261115910711488  Time:  5.6443445682525635\n",
      "Total Valid Loss:  1.6784794242293746  Time:  2.2155168056488037\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.0032162554077588756  Time:  6.859687566757202\n",
      "Total Valid Loss:  1.6382858289612665  Time:  2.270392417907715\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.0031903762615291195  Time:  5.702542543411255\n",
      "Total Valid Loss:  1.6959118456752211  Time:  2.051640510559082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.003191509792807302  Time:  5.384557008743286\n",
      "Total Valid Loss:  1.6823889900136877  Time:  2.1960349082946777\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.0031979923335716904  Time:  5.740253448486328\n",
      "Total Valid Loss:  1.660597273597011  Time:  2.1216330528259277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.0031928273894947907  Time:  5.763246059417725\n",
      "Total Valid Loss:  1.6653059698917247  Time:  2.796133518218994\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.0031798292123685684  Time:  6.285786151885986\n",
      "Total Valid Loss:  1.639954180629165  Time:  2.016929864883423\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.0031940313365654968  Time:  6.49020791053772\n",
      "Total Valid Loss:  1.64271186236982  Time:  1.9767115116119385\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.0031453151689207104  Time:  4.902884483337402\n",
      "Total Valid Loss:  1.6548402695744127  Time:  1.706437349319458\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.003106896562307987  Time:  7.200735092163086\n",
      "Total Valid Loss:  1.6651642664715096  Time:  1.8550362586975098\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.0031131157931478725  Time:  5.0534820556640625\n",
      "Total Valid Loss:  1.661318792237176  Time:  1.602712869644165\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.00314038904448379  Time:  4.983668088912964\n",
      "Total Valid Loss:  1.6469908974788807  Time:  2.2240512371063232\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.003112583310811678  Time:  6.458721160888672\n",
      "Total Valid Loss:  1.665478292438719  Time:  2.1472620964050293\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.003114158126143362  Time:  6.160519361495972\n",
      "Total Valid Loss:  1.660479258607935  Time:  2.192135810852051\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.0031276559228389767  Time:  6.18231201171875\n",
      "Total Valid Loss:  1.6552174323134952  Time:  2.100614547729492\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.003116341681903325  Time:  5.3878772258758545\n",
      "Total Valid Loss:  1.6533378186049286  Time:  2.149731397628784\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.003140001369349529  Time:  5.409908771514893\n",
      "Total Valid Loss:  1.639243142472373  Time:  2.139295816421509\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.0031035910925768704  Time:  5.262073278427124\n",
      "Total Valid Loss:  1.6676498982641432  Time:  2.336171865463257\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.0030502623466591786  Time:  6.735004663467407\n",
      "Total Valid Loss:  1.652609900191978  Time:  2.3640217781066895\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.0030687801658332  Time:  6.980482578277588\n",
      "Total Valid Loss:  1.6658239784064117  Time:  1.9926681518554688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.0030768747358028425  Time:  4.778221368789673\n",
      "Total Valid Loss:  1.6267209869843942  Time:  1.894930124282837\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.0031179052136967637  Time:  4.585735082626343\n",
      "Total Valid Loss:  1.6569859440679904  Time:  1.5927393436431885\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.003054806818604211  Time:  5.066444635391235\n",
      "Total Valid Loss:  1.6553020057854828  Time:  1.591742992401123\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.003058238417943778  Time:  4.611661911010742\n",
      "Total Valid Loss:  1.6517636389644057  Time:  1.6814963817596436\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.003105071665331549  Time:  4.77123761177063\n",
      "Total Valid Loss:  1.6380915939807892  Time:  1.6705327033996582\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.0030825478415074893  Time:  4.645570993423462\n",
      "Total Valid Loss:  1.666712882342162  Time:  1.7363550662994385\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.0030791036410504854  Time:  4.831078290939331\n",
      "Total Valid Loss:  1.636537383000056  Time:  1.72837495803833\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.003034900351712814  Time:  5.365646123886108\n",
      "Total Valid Loss:  1.649699827035268  Time:  2.2689311504364014\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.0030130451192508716  Time:  5.872291326522827\n",
      "Total Valid Loss:  1.6193522877163358  Time:  2.6157331466674805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.0030443562757266913  Time:  6.318349838256836\n",
      "Total Valid Loss:  1.6433900098005931  Time:  2.127840518951416\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.003085533190637052  Time:  5.613997220993042\n",
      "Total Valid Loss:  1.6439084929448586  Time:  2.1731503009796143\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.003096809049508389  Time:  5.659748554229736\n",
      "Total Valid Loss:  1.6285001481020893  Time:  2.257816791534424\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.0030222420050423442  Time:  6.788436651229858\n",
      "Total Valid Loss:  1.613253994120492  Time:  2.6180717945098877\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.003060729066555986  Time:  5.670810699462891\n",
      "Total Valid Loss:  1.6444769578951377  Time:  2.164593458175659\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.0030587769982894893  Time:  5.842475891113281\n",
      "Total Valid Loss:  1.648691698356911  Time:  2.210615396499634\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.003017924576620921  Time:  5.762085437774658\n",
      "Total Valid Loss:  1.6464160471050828  Time:  2.296137571334839\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.003005523215764003  Time:  5.995016813278198\n",
      "Total Valid Loss:  1.629578514231576  Time:  2.219205617904663\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.003045243534092614  Time:  5.112936735153198\n",
      "Total Valid Loss:  1.634834286239412  Time:  2.1023736000061035\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.00301698576847382  Time:  5.583064794540405\n",
      "Total Valid Loss:  1.6550557867244438  Time:  1.6685359477996826\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.0029967886845263616  Time:  4.32942008972168\n",
      "Total Valid Loss:  1.634008785088857  Time:  1.644599437713623\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.0030274859419620105  Time:  4.440123558044434\n",
      "Total Valid Loss:  1.6294595455681835  Time:  1.6665399074554443\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.0029827157234654606  Time:  4.38327431678772\n",
      "Total Valid Loss:  1.6550503030971244  Time:  1.6635513305664062\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.003030932848907017  Time:  5.226017713546753\n",
      "Total Valid Loss:  1.6340683698654175  Time:  1.628645420074463\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.003035193454538811  Time:  4.438125848770142\n",
      "Total Valid Loss:  1.652118710456071  Time:  1.875981330871582\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.0030066204940997106  Time:  4.8619959354400635\n",
      "Total Valid Loss:  1.6684522242457778  Time:  1.8899414539337158\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.003007420482695361  Time:  6.490639686584473\n",
      "Total Valid Loss:  1.6233513874036294  Time:  2.7576217651367188\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.0030366667301388664  Time:  5.851346492767334\n",
      "Total Valid Loss:  1.6448375461278137  Time:  2.065474510192871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.003016167160155887  Time:  5.284862518310547\n",
      "Total Valid Loss:  1.6217526351964031  Time:  2.120327949523926\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.0030026757871635217  Time:  5.441445350646973\n",
      "Total Valid Loss:  1.6324896448188357  Time:  2.080432653427124\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.0029620639858713555  Time:  5.706733703613281\n",
      "Total Valid Loss:  1.6343959856916357  Time:  1.8530418872833252\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.0029500541425272393  Time:  4.554816007614136\n",
      "Total Valid Loss:  1.6377148319173742  Time:  1.8121514320373535\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.0029986240602276055  Time:  5.3147852420806885\n",
      "Total Valid Loss:  1.6278529244440574  Time:  2.1552326679229736\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.003035801434566434  Time:  4.736328840255737\n",
      "Total Valid Loss:  1.6448731278931652  Time:  1.7613229751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.0030258146687976027  Time:  4.41016960144043\n",
      "Total Valid Loss:  1.6383977675879444  Time:  1.4970319271087646\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.002971885614150952  Time:  4.29158878326416\n",
      "Total Valid Loss:  1.64713344640202  Time:  1.5159430503845215\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.0029741849957540026  Time:  4.380281925201416\n",
      "Total Valid Loss:  1.6051858531104193  Time:  1.7543094158172607\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.0029567039970071676  Time:  4.78420615196228\n",
      "Total Valid Loss:  1.6299823379075085  Time:  1.8580284118652344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.002971957395972975  Time:  6.381927967071533\n",
      "Total Valid Loss:  1.6341686535764623  Time:  2.5342211723327637\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.0029887458419890246  Time:  5.227049112319946\n",
      "Total Valid Loss:  1.6395012151311945  Time:  1.9776763916015625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.002958628342276967  Time:  5.014589071273804\n",
      "Total Valid Loss:  1.6105260385407343  Time:  2.3028390407562256\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.002935247113551363  Time:  5.59403657913208\n",
      "Total Valid Loss:  1.6198440746024803  Time:  2.1033740043640137\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.0029377906873951413  Time:  6.381927728652954\n",
      "Total Valid Loss:  1.6181786976478718  Time:  2.0774412155151367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.0029474646754756658  Time:  6.269892692565918\n",
      "Total Valid Loss:  1.6273556726950187  Time:  2.198899984359741\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 100 starts !\n",
      "Total Train Loss:  0.002988102631858749  Time:  7.23661208152771\n",
      "Total Valid Loss:  1.6455618882620777  Time:  2.0891425609588623\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 101 starts !\n",
      "Total Train Loss:  0.0029763422793348056  Time:  5.570067644119263\n",
      "Total Valid Loss:  1.6380550276350092  Time:  2.291769027709961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 102 starts !\n",
      "Total Train Loss:  0.002947506065496561  Time:  5.5355401039123535\n",
      "Total Valid Loss:  1.6361772738121174  Time:  2.551457643508911\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 103 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.002929819291565201  Time:  5.731805086135864\n",
      "Total Valid Loss:  1.6214451558060117  Time:  1.966778039932251\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 104 starts !\n",
      "Total Train Loss:  0.0029251880007069237  Time:  5.595688104629517\n",
      "Total Valid Loss:  1.6156870987680223  Time:  2.0486226081848145\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 105 starts !\n",
      "Total Train Loss:  0.002929457591179048  Time:  5.534341096878052\n",
      "Total Valid Loss:  1.623913460307651  Time:  2.5498616695404053\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 106 starts !\n",
      "Total Train Loss:  0.0029232001168965605  Time:  5.418761253356934\n",
      "Total Valid Loss:  1.629021473504879  Time:  1.9983923435211182\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 107 starts !\n",
      "Total Train Loss:  0.0028886344308044353  Time:  6.000860691070557\n",
      "Total Valid Loss:  1.622124716087624  Time:  2.0196750164031982\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 108 starts !\n",
      "Total Train Loss:  0.0028956692969975615  Time:  6.634068727493286\n",
      "Total Valid Loss:  1.6238935026857588  Time:  2.7175886631011963\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 109 starts !\n",
      "Total Train Loss:  0.0029011147898874877  Time:  6.672405481338501\n",
      "Total Valid Loss:  1.627982368071874  Time:  2.781968832015991\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 110 starts !\n",
      "Total Train Loss:  0.0028918659465247496  Time:  6.149636745452881\n",
      "Total Valid Loss:  1.5879524129408378  Time:  2.044127941131592\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 111 starts !\n",
      "Total Train Loss:  0.002929971145595171  Time:  5.36535906791687\n",
      "Total Valid Loss:  1.6365636598180842  Time:  2.199037790298462\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 112 starts !\n",
      "Total Train Loss:  0.0029527422813214145  Time:  5.147466659545898\n",
      "Total Valid Loss:  1.6389581274103235  Time:  2.520305871963501\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 113 starts !\n",
      "Total Train Loss:  0.0029281719582359917  Time:  5.7461097240448\n",
      "Total Valid Loss:  1.6454123600765511  Time:  2.586350679397583\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 114 starts !\n",
      "Total Train Loss:  0.002925449721192177  Time:  5.250447511672974\n",
      "Total Valid Loss:  1.6195077509791762  Time:  2.1330955028533936\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 115 starts !\n",
      "Total Train Loss:  0.002939453828982966  Time:  5.881998300552368\n",
      "Total Valid Loss:  1.6407064342940296  Time:  2.4385344982147217\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 116 starts !\n",
      "Total Train Loss:  0.0029144721856674536  Time:  4.9883873462677\n",
      "Total Valid Loss:  1.63873181409306  Time:  1.8491721153259277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 117 starts !\n",
      "Total Train Loss:  0.0028797932981238887  Time:  4.879114866256714\n",
      "Total Valid Loss:  1.6333175577499248  Time:  1.892904281616211\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 118 starts !\n",
      "Total Train Loss:  0.002857379171179037  Time:  5.068324565887451\n",
      "Total Valid Loss:  1.6115036562637046  Time:  2.830723285675049\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 119 starts !\n",
      "Total Train Loss:  0.0028905493161517242  Time:  7.107111215591431\n",
      "Total Valid Loss:  1.6197858055432637  Time:  2.0405964851379395\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 120 starts !\n",
      "Total Train Loss:  0.0028619608960270535  Time:  5.358295440673828\n",
      "Total Valid Loss:  1.627533973367126  Time:  2.1415345668792725\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 121 starts !\n",
      "Total Train Loss:  0.002894522533402105  Time:  6.968419790267944\n",
      "Total Valid Loss:  1.5947292888606037  Time:  2.519117593765259\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 122 starts !\n",
      "Total Train Loss:  0.0029061592434333756  Time:  6.874547958374023\n",
      "Total Valid Loss:  1.646964430809021  Time:  2.1337673664093018\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 123 starts !\n",
      "Total Train Loss:  0.002955556170196633  Time:  6.217329978942871\n",
      "Total Valid Loss:  1.647483034266366  Time:  2.4169745445251465\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 124 starts !\n",
      "Total Train Loss:  0.0028825174031962206  Time:  6.094151020050049\n",
      "Total Valid Loss:  1.6147209140989516  Time:  2.254185199737549\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 125 starts !\n",
      "Total Train Loss:  0.002870664369271842  Time:  5.181497573852539\n",
      "Total Valid Loss:  1.6315611998240154  Time:  2.0407400131225586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 126 starts !\n",
      "Total Train Loss:  0.002885369614918711  Time:  5.005717039108276\n",
      "Total Valid Loss:  1.6160223583380382  Time:  1.8692903518676758\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 127 starts !\n",
      "Total Train Loss:  0.002896631534905792  Time:  5.52147650718689\n",
      "Total Valid Loss:  1.6247021268915247  Time:  2.2117698192596436\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 128 starts !\n",
      "Total Train Loss:  0.0028670709095679958  Time:  5.449068546295166\n",
      "Total Valid Loss:  1.6423079128618594  Time:  2.042320489883423\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 129 starts !\n",
      "Total Train Loss:  0.002858463319481453  Time:  5.823206663131714\n",
      "Total Valid Loss:  1.6149160045164603  Time:  2.2041783332824707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 130 starts !\n",
      "Total Train Loss:  0.00287746426493274  Time:  5.412434101104736\n",
      "Total Valid Loss:  1.6198434465461307  Time:  1.9148149490356445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 131 starts !\n",
      "Total Train Loss:  0.0028335777692755177  Time:  5.326921701431274\n",
      "Total Valid Loss:  1.618508627017339  Time:  1.7658195495605469\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 132 starts !\n",
      "Total Train Loss:  0.0028490272775895335  Time:  5.580565690994263\n",
      "Total Valid Loss:  1.6092372293825503  Time:  2.207622528076172\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 133 starts !\n",
      "Total Train Loss:  0.0028855091935249765  Time:  5.244523286819458\n",
      "Total Valid Loss:  1.6167967231185347  Time:  2.1534881591796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 134 starts !\n",
      "Total Train Loss:  0.002876813297369921  Time:  5.463892698287964\n",
      "Total Valid Loss:  1.623655163579517  Time:  1.9385972023010254\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 135 starts !\n",
      "Total Train Loss:  0.0029066991077122315  Time:  5.386500358581543\n",
      "Total Valid Loss:  1.599577650979713  Time:  1.9688701629638672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 136 starts !\n",
      "Total Train Loss:  0.002914856828619979  Time:  5.064062118530273\n",
      "Total Valid Loss:  1.6434076538792364  Time:  2.1325833797454834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 137 starts !\n",
      "Total Train Loss:  0.0028474627189187473  Time:  5.355484962463379\n",
      "Total Valid Loss:  1.6534997754626803  Time:  2.2446000576019287\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 138 starts !\n",
      "Total Train Loss:  0.002855446030832612  Time:  4.922492265701294\n",
      "Total Valid Loss:  1.6364833138607167  Time:  1.8104972839355469\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 139 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.002826838032746246  Time:  5.0050368309021\n",
      "Total Valid Loss:  1.6053958689724956  Time:  1.8002328872680664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 140 starts !\n",
      "Total Train Loss:  0.0028497445938107423  Time:  4.98117208480835\n",
      "Total Valid Loss:  1.621280595108315  Time:  1.8621387481689453\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 141 starts !\n",
      "Total Train Loss:  0.0028593784286990503  Time:  4.653414726257324\n",
      "Total Valid Loss:  1.5987164168446153  Time:  1.8570172786712646\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 142 starts !\n",
      "Total Train Loss:  0.002872026864589983  Time:  4.805262088775635\n",
      "Total Valid Loss:  1.6384409224545513  Time:  1.9030382633209229\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 143 starts !\n",
      "Total Train Loss:  0.0028497132289659424  Time:  5.361129522323608\n",
      "Total Valid Loss:  1.6133087189109236  Time:  2.1635823249816895\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 144 starts !\n",
      "Total Train Loss:  0.0028850204093284863  Time:  5.493001937866211\n",
      "Total Valid Loss:  1.6093978318903182  Time:  2.1756644248962402\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 145 starts !\n",
      "Total Train Loss:  0.002860708358681443  Time:  5.326514005661011\n",
      "Total Valid Loss:  1.6255757919064275  Time:  2.0386786460876465\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 146 starts !\n",
      "Total Train Loss:  0.002849140021454737  Time:  5.266663074493408\n",
      "Total Valid Loss:  1.6264728329799794  Time:  1.981095552444458\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 147 starts !\n",
      "Total Train Loss:  0.002851520595006171  Time:  5.4987876415252686\n",
      "Total Valid Loss:  1.6007823988243386  Time:  1.9108705520629883\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 148 starts !\n",
      "Total Train Loss:  0.002832402367510892  Time:  5.628694772720337\n",
      "Total Valid Loss:  1.637921252736339  Time:  2.3761885166168213\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 149 starts !\n",
      "Total Train Loss:  0.0028491771653445298  Time:  5.723831415176392\n",
      "Total Valid Loss:  1.6153135928842757  Time:  2.392916202545166\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 150 starts !\n",
      "Total Train Loss:  0.0028137702379117295  Time:  5.027557134628296\n",
      "Total Valid Loss:  1.6284654769632552  Time:  1.8765408992767334\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 151 starts !\n",
      "Total Train Loss:  0.0028328888920388815  Time:  5.333067178726196\n",
      "Total Valid Loss:  1.632728276429353  Time:  2.0546858310699463\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 152 starts !\n",
      "Total Train Loss:  0.0028475390591071867  Time:  4.964759826660156\n",
      "Total Valid Loss:  1.6404196399229545  Time:  2.1152141094207764\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 153 starts !\n",
      "Total Train Loss:  0.002872058921197505  Time:  5.080739736557007\n",
      "Total Valid Loss:  1.611552016602622  Time:  2.2922170162200928\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 154 starts !\n",
      "Total Train Loss:  0.0028442535899321124  Time:  6.334630012512207\n",
      "Total Valid Loss:  1.6433856167175152  Time:  1.9772241115570068\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 155 starts !\n",
      "Total Train Loss:  0.00279803874342557  Time:  6.789492845535278\n",
      "Total Valid Loss:  1.5910027612138677  Time:  2.732693672180176\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 156 starts !\n",
      "Total Train Loss:  0.002837762077785813  Time:  5.875596523284912\n",
      "Total Valid Loss:  1.6246602281376168  Time:  2.7416813373565674\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 157 starts !\n",
      "Total Train Loss:  0.002831399832405365  Time:  6.715649843215942\n",
      "Total Valid Loss:  1.6210274398326874  Time:  2.242762327194214\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 158 starts !\n",
      "Total Train Loss:  0.002868164922891325  Time:  5.65754508972168\n",
      "Total Valid Loss:  1.636695706182056  Time:  2.8164994716644287\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 159 starts !\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "indv = build(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.024670196435181424  Time:  3.6103062629699707\n",
      "Total Valid Loss:  2.2042336463928223  Time:  0.07579970359802246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.024134494810520362  Time:  3.5465149879455566\n",
      "Total Valid Loss:  2.1303322315216064  Time:  0.047902584075927734\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.023962698876857758  Time:  3.8576529026031494\n",
      "Total Valid Loss:  2.1682893435160318  Time:  0.026966571807861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.02395763241414291  Time:  3.6243019104003906\n",
      "Total Valid Loss:  2.125359853108724  Time:  0.023941993713378906\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.02388343237301645  Time:  4.383241653442383\n",
      "Total Valid Loss:  2.0884768962860107  Time:  0.02692723274230957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.02376603426334138  Time:  3.6412642002105713\n",
      "Total Valid Loss:  2.2113616466522217  Time:  0.034911155700683594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.0238667457694343  Time:  4.107019424438477\n",
      "Total Valid Loss:  2.0630273818969727  Time:  0.03191566467285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.023872343202431996  Time:  4.51592493057251\n",
      "Total Valid Loss:  2.1464880307515464  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.023595342334980767  Time:  4.105022668838501\n",
      "Total Valid Loss:  2.176320791244507  Time:  0.029922008514404297\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.023631086058837052  Time:  4.140925407409668\n",
      "Total Valid Loss:  2.1961349646250405  Time:  0.03590512275695801\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.023739075656825055  Time:  4.63360857963562\n",
      "Total Valid Loss:  2.135016838709513  Time:  0.02992105484008789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.023508520059597988  Time:  3.732018232345581\n",
      "Total Valid Loss:  2.143762191136678  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.02365524184036379  Time:  3.9504363536834717\n",
      "Total Valid Loss:  2.1196349461873374  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.023645536712137982  Time:  3.6771650314331055\n",
      "Total Valid Loss:  2.1408073902130127  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.023319171140125643  Time:  3.7200520038604736\n",
      "Total Valid Loss:  2.159491777420044  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.023533260139326256  Time:  4.061140060424805\n",
      "Total Valid Loss:  2.0907203356424966  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.023544707238518942  Time:  4.171844244003296\n",
      "Total Valid Loss:  2.1504526933034263  Time:  0.030918359756469727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.023331883867892127  Time:  3.554494619369507\n",
      "Total Valid Loss:  2.130406618118286  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.02358213855768554  Time:  3.7759041786193848\n",
      "Total Valid Loss:  2.1562914848327637  Time:  0.029921531677246094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.023515046855512384  Time:  3.7380032539367676\n",
      "Total Valid Loss:  2.1040480931599936  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.023388313905646402  Time:  4.372337102890015\n",
      "Total Valid Loss:  2.221799453099569  Time:  0.029890775680541992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.02325916931537601  Time:  4.560803174972534\n",
      "Total Valid Loss:  2.104278087615967  Time:  0.034906625747680664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.02349829063556778  Time:  4.669015169143677\n",
      "Total Valid Loss:  2.164740721384684  Time:  0.039893388748168945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.02334094747978573  Time:  4.173839807510376\n",
      "Total Valid Loss:  2.170943101247152  Time:  0.028921842575073242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.023443264023323234  Time:  4.418196201324463\n",
      "Total Valid Loss:  2.1599326133728027  Time:  0.02991938591003418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.02319365437142551  Time:  4.640591621398926\n",
      "Total Valid Loss:  2.170290549596151  Time:  0.04089164733886719\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.0233133090659976  Time:  4.068121433258057\n",
      "Total Valid Loss:  2.1510721842447915  Time:  0.03191518783569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.023476479177285608  Time:  3.5694544315338135\n",
      "Total Valid Loss:  2.1668646335601807  Time:  0.02892446517944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.023371350155988086  Time:  4.104024171829224\n",
      "Total Valid Loss:  2.1478984355926514  Time:  0.027927637100219727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.023521966349411134  Time:  4.1399266719818115\n",
      "Total Valid Loss:  2.214067538579305  Time:  0.032912492752075195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.02327713444052885  Time:  3.8207833766937256\n",
      "Total Valid Loss:  2.1236175696055093  Time:  0.03091907501220703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.02310005222291996  Time:  4.454120397567749\n",
      "Total Valid Loss:  2.0876665115356445  Time:  0.029923200607299805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.023306097359939788  Time:  4.144880533218384\n",
      "Total Valid Loss:  2.1046807765960693  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.02346707895048894  Time:  3.7399978637695312\n",
      "Total Valid Loss:  2.122089227040609  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.02320287992673305  Time:  4.1110053062438965\n",
      "Total Valid Loss:  2.144674380620321  Time:  0.0359036922454834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.023305253659297403  Time:  3.7080862522125244\n",
      "Total Valid Loss:  2.146566947301229  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.023306958823620032  Time:  4.533910036087036\n",
      "Total Valid Loss:  2.088955799738566  Time:  0.03690147399902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.023231908184243366  Time:  4.415160894393921\n",
      "Total Valid Loss:  2.1181604067484536  Time:  0.04089188575744629\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.02317017430323176  Time:  4.31346583366394\n",
      "Total Valid Loss:  2.1530913511912027  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.023074854650379468  Time:  3.641263246536255\n",
      "Total Valid Loss:  2.06980037689209  Time:  0.0299227237701416\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.023231489224902663  Time:  3.7240402698516846\n",
      "Total Valid Loss:  2.136300563812256  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.023207092289036762  Time:  4.206751823425293\n",
      "Total Valid Loss:  2.166910966237386  Time:  0.039927005767822266\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.02310704652336426  Time:  4.59870171546936\n",
      "Total Valid Loss:  2.1178454558054605  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.022880907432409003  Time:  3.5734469890594482\n",
      "Total Valid Loss:  2.155550718307495  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.02319204939218859  Time:  4.3254311084747314\n",
      "Total Valid Loss:  2.1128900051116943  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.02310060552554205  Time:  3.683152437210083\n",
      "Total Valid Loss:  2.1321869691212973  Time:  0.028924942016601562\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.023091543533761676  Time:  3.570451021194458\n",
      "Total Valid Loss:  2.161346912384033  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.022999108671986807  Time:  3.516594409942627\n",
      "Total Valid Loss:  2.114822785059611  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.023294067980411153  Time:  3.5305588245391846\n",
      "Total Valid Loss:  2.141964912414551  Time:  0.029921293258666992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.02325000784670313  Time:  3.5016376972198486\n",
      "Total Valid Loss:  2.0929505030314126  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  73.02093887329102\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.675253292941 =======\n",
      "======= Set val : score(recall_10)=0.735632183908 =======\n",
      "======= Set val : score(recall_20)=0.776418242492 =======\n",
      "======= Set val : score(map_cut_10)=0.656487661187 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  9\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.024238520180927467  Time:  2.6329305171966553\n",
      "Total Valid Loss:  2.102098226547241  Time:  0.02293872833251953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.023782529541617865  Time:  2.6479151248931885\n",
      "Total Valid Loss:  2.166977326075236  Time:  0.0249330997467041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.02367909432860551  Time:  2.688810348510742\n",
      "Total Valid Loss:  2.1415578524271646  Time:  0.02892470359802246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.02361097520628533  Time:  2.634953737258911\n",
      "Total Valid Loss:  2.131452798843384  Time:  0.024933338165283203\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.023684708558797063  Time:  2.749645471572876\n",
      "Total Valid Loss:  2.1080356438954673  Time:  0.06482648849487305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.02369749237626017  Time:  2.852374315261841\n",
      "Total Valid Loss:  2.129873355229696  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.023644919313683913  Time:  3.1445910930633545\n",
      "Total Valid Loss:  2.161357879638672  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.023588266332524938  Time:  3.3979129791259766\n",
      "Total Valid Loss:  2.1251207987467446  Time:  0.03590226173400879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.0236404494128444  Time:  3.572446823120117\n",
      "Total Valid Loss:  2.0550482273101807  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.023605749833506422  Time:  3.71706223487854\n",
      "Total Valid Loss:  2.032998482386271  Time:  0.028928279876708984\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.023525036810957765  Time:  3.6053569316864014\n",
      "Total Valid Loss:  2.1148056189219155  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.023409852068629357  Time:  3.318127155303955\n",
      "Total Valid Loss:  2.149402936299642  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.02330149332811306  Time:  3.3181285858154297\n",
      "Total Valid Loss:  2.096574385960897  Time:  0.030916929244995117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.023626276799900967  Time:  3.148582935333252\n",
      "Total Valid Loss:  2.0988001823425293  Time:  0.027926921844482422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.023575236851518803  Time:  3.1575562953948975\n",
      "Total Valid Loss:  2.0925145149230957  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.02327070931916113  Time:  3.0907340049743652\n",
      "Total Valid Loss:  2.1008119583129883  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.023486467199279118  Time:  3.460745334625244\n",
      "Total Valid Loss:  2.144545316696167  Time:  0.04986715316772461\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.023495335990635604  Time:  3.258289098739624\n",
      "Total Valid Loss:  2.144052584966024  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.02345433964260987  Time:  3.103698968887329\n",
      "Total Valid Loss:  2.103749910990397  Time:  0.03194689750671387\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.023345603329407705  Time:  3.083721399307251\n",
      "Total Valid Loss:  2.156270901362101  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.023512711603339616  Time:  3.015937089920044\n",
      "Total Valid Loss:  2.1868065198262534  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.023414487527175384  Time:  2.948115348815918\n",
      "Total Valid Loss:  2.060279687245687  Time:  0.026930570602416992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.02358182445894201  Time:  2.845390796661377\n",
      "Total Valid Loss:  2.0327910582224527  Time:  0.06383228302001953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.023560455806746886  Time:  2.939138174057007\n",
      "Total Valid Loss:  2.080132563908895  Time:  0.06283259391784668\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.023285704156891865  Time:  2.796555995941162\n",
      "Total Valid Loss:  2.117924690246582  Time:  0.028890132904052734\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.023367087513982476  Time:  2.884286642074585\n",
      "Total Valid Loss:  2.0983266035715737  Time:  0.030918121337890625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.02327735677313108  Time:  3.022914409637451\n",
      "Total Valid Loss:  2.173089027404785  Time:  0.04886960983276367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.023712214977516757  Time:  2.922185182571411\n",
      "Total Valid Loss:  2.1195228099823  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.023355458887269746  Time:  2.992997646331787\n",
      "Total Valid Loss:  2.0364158948262534  Time:  0.033908843994140625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.02324308811795789  Time:  3.091738700866699\n",
      "Total Valid Loss:  2.0988717079162598  Time:  0.03290605545043945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.023263356200866885  Time:  3.1286356449127197\n",
      "Total Valid Loss:  2.176091432571411  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.023268806312668634  Time:  3.104696035385132\n",
      "Total Valid Loss:  2.122944196065267  Time:  0.04886937141418457\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.02331554080516874  Time:  3.105695962905884\n",
      "Total Valid Loss:  2.0768307050069175  Time:  0.09175610542297363\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.02329893364244467  Time:  3.4068899154663086\n",
      "Total Valid Loss:  2.074613571166992  Time:  0.06482744216918945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.023483139704671  Time:  2.892265796661377\n",
      "Total Valid Loss:  2.128434658050537  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.023334376925191323  Time:  3.4158647060394287\n",
      "Total Valid Loss:  2.0549093882242837  Time:  0.02995467185974121\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.023289961655708877  Time:  3.298182725906372\n",
      "Total Valid Loss:  2.126421848932902  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.02323790891216947  Time:  3.357020378112793\n",
      "Total Valid Loss:  2.1433807214101157  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.02307164234822834  Time:  2.856363296508789\n",
      "Total Valid Loss:  2.1547773679097495  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.02301420671744393  Time:  3.2353484630584717\n",
      "Total Valid Loss:  2.0903658866882324  Time:  0.0279238224029541\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.023334514325508822  Time:  3.086747884750366\n",
      "Total Valid Loss:  2.1021599769592285  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.023272315802221947  Time:  3.153567314147949\n",
      "Total Valid Loss:  2.1481423377990723  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.023215536003956545  Time:  3.0229151248931885\n",
      "Total Valid Loss:  2.0837297439575195  Time:  0.07081246376037598\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.023317516503202452  Time:  3.6801581382751465\n",
      "Total Valid Loss:  2.095799287160238  Time:  0.07280349731445312\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.023354783388120786  Time:  3.228367805480957\n",
      "Total Valid Loss:  2.116978963216146  Time:  0.028922319412231445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.023084005607025965  Time:  2.918196439743042\n",
      "Total Valid Loss:  2.102276007334391  Time:  0.06382918357849121\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.023182523545700235  Time:  2.972052574157715\n",
      "Total Valid Loss:  2.094158887863159  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.023303261679875387  Time:  2.8114819526672363\n",
      "Total Valid Loss:  2.1288376649220786  Time:  0.027924776077270508\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.023106101404440093  Time:  2.9929964542388916\n",
      "Total Valid Loss:  2.101726849873861  Time:  0.03391003608703613\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.02307787663363791  Time:  2.885284185409546\n",
      "Total Valid Loss:  2.092211882273356  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  71.62750792503357\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.669034523562 =======\n",
      "======= Set val : score(recall_10)=0.727104189841 =======\n",
      "======= Set val : score(recall_20)=0.767519466073 =======\n",
      "======= Set val : score(map_cut_10)=0.650681680409 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  7\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.0245684578852809  Time:  1.9856889247894287\n",
      "Total Valid Loss:  2.101334492365519  Time:  0.024933815002441406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.023662296779777693  Time:  1.903909683227539\n",
      "Total Valid Loss:  2.071857134501139  Time:  0.024934053421020508\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.02361641952201076  Time:  1.9078965187072754\n",
      "Total Valid Loss:  2.0614267190297446  Time:  0.022938966751098633\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.023983313370010126  Time:  1.8909432888031006\n",
      "Total Valid Loss:  2.1072567303975425  Time:  0.02393651008605957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.023716391412460285  Time:  1.8779783248901367\n",
      "Total Valid Loss:  2.0804946422576904  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.023564240012479865  Time:  2.373652458190918\n",
      "Total Valid Loss:  2.1023876667022705  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.023695651101677314  Time:  2.3696627616882324\n",
      "Total Valid Loss:  2.1285018920898438  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.023408652226562087  Time:  2.211087942123413\n",
      "Total Valid Loss:  2.054063081741333  Time:  0.0299222469329834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.023498202358251032  Time:  2.1971240043640137\n",
      "Total Valid Loss:  2.113614877065023  Time:  0.03391003608703613\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.023707588535288107  Time:  2.215074300765991\n",
      "Total Valid Loss:  2.112988551457723  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.023620695491199908  Time:  2.1612229347229004\n",
      "Total Valid Loss:  2.065679947535197  Time:  0.03091716766357422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.023712527476575065  Time:  2.2220547199249268\n",
      "Total Valid Loss:  2.0729292233784995  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.023333922708811967  Time:  2.2380151748657227\n",
      "Total Valid Loss:  2.06837264696757  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.023373293228771377  Time:  2.1223244667053223\n",
      "Total Valid Loss:  2.1267157395680747  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.023583358299473056  Time:  2.0914082527160645\n",
      "Total Valid Loss:  2.0556832949320474  Time:  0.027927398681640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.02355943024158478  Time:  2.230034112930298\n",
      "Total Valid Loss:  2.1032016277313232  Time:  0.04787302017211914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.0234338931415392  Time:  2.665869951248169\n",
      "Total Valid Loss:  2.1110123793284097  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.02342382245089697  Time:  2.1532440185546875\n",
      "Total Valid Loss:  2.13388729095459  Time:  0.03091597557067871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.02396542783016744  Time:  2.106367588043213\n",
      "Total Valid Loss:  2.119293451309204  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.023632088805670325  Time:  2.134326934814453\n",
      "Total Valid Loss:  2.0619232654571533  Time:  0.026891469955444336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.023396405318508978  Time:  2.1801705360412598\n",
      "Total Valid Loss:  2.0517585277557373  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.023377651332513145  Time:  2.255969524383545\n",
      "Total Valid Loss:  2.0750795205434165  Time:  0.03091740608215332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.023228850863550022  Time:  2.3237860202789307\n",
      "Total Valid Loss:  2.0682380199432373  Time:  0.031916141510009766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.023381653460471528  Time:  2.7306952476501465\n",
      "Total Valid Loss:  2.1040172576904297  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.023319833547524784  Time:  2.217071056365967\n",
      "Total Valid Loss:  2.1109743118286133  Time:  0.028925657272338867\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.023227142283450002  Time:  2.2679331302642822\n",
      "Total Valid Loss:  2.099515994389852  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.023394190455260484  Time:  2.363680124282837\n",
      "Total Valid Loss:  2.089307943979899  Time:  0.0299222469329834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.0233284798167322  Time:  2.3547027111053467\n",
      "Total Valid Loss:  2.1228278477986655  Time:  0.027926921844482422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.023444141172196554  Time:  2.1223225593566895\n",
      "Total Valid Loss:  2.0947497685750327  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.023369994840544202  Time:  2.1672043800354004\n",
      "Total Valid Loss:  2.0934746265411377  Time:  0.033910274505615234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.023353255329572636  Time:  2.4155406951904297\n",
      "Total Valid Loss:  2.153334935506185  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.02327650882627653  Time:  2.3128154277801514\n",
      "Total Valid Loss:  2.1110049883524575  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.023269315906192946  Time:  2.168198823928833\n",
      "Total Valid Loss:  2.052237391471863  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.02320801918597325  Time:  2.2041077613830566\n",
      "Total Valid Loss:  2.0983734130859375  Time:  0.052857398986816406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.02319842934932398  Time:  2.9331560134887695\n",
      "Total Valid Loss:  2.0887956619262695  Time:  0.049869537353515625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.023649394933296288  Time:  2.4364819526672363\n",
      "Total Valid Loss:  2.1250008742014566  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.023428807504799056  Time:  2.269929885864258\n",
      "Total Valid Loss:  2.0850889682769775  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.023330623802283536  Time:  2.4095582962036133\n",
      "Total Valid Loss:  2.0974251429239907  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.023214927121349004  Time:  2.9251742362976074\n",
      "Total Valid Loss:  2.1173088550567627  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.023223312798401584  Time:  2.7745797634124756\n",
      "Total Valid Loss:  2.0582985083262124  Time:  0.03989529609680176\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.023284481789754785  Time:  2.5501739978790283\n",
      "Total Valid Loss:  2.1091482639312744  Time:  0.04787182807922363\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.023004560415511546  Time:  2.5721218585968018\n",
      "Total Valid Loss:  2.085883458455404  Time:  0.04388594627380371\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.023390893686724746  Time:  2.624953508377075\n",
      "Total Valid Loss:  2.0746171474456787  Time:  0.0329129695892334\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.023178035296175792  Time:  2.676841974258423\n",
      "Total Valid Loss:  2.065627177556356  Time:  0.0498661994934082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.023271805209958037  Time:  3.0139405727386475\n",
      "Total Valid Loss:  2.12191104888916  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.02312075869868631  Time:  2.5691304206848145\n",
      "Total Valid Loss:  2.0988384087880454  Time:  0.04787325859069824\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.0235203028049158  Time:  2.4404783248901367\n",
      "Total Valid Loss:  2.1263575553894043  Time:  0.031911611557006836\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.023112117823051368  Time:  2.775578260421753\n",
      "Total Valid Loss:  2.116896470387777  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.023145816151214683  Time:  2.671855926513672\n",
      "Total Valid Loss:  2.091094493865967  Time:  0.04587912559509277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.0231966693116271  Time:  2.5282320976257324\n",
      "Total Valid Loss:  2.0677403608957925  Time:  0.04487919807434082\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  79.47253322601318\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.670984712230 =======\n",
      "======= Set val : score(recall_10)=0.725250278087 =======\n",
      "======= Set val : score(recall_20)=0.765294771969 =======\n",
      "======= Set val : score(map_cut_10)=0.654050208639 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  5\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.02430234467247864  Time:  1.4072356224060059\n",
      "Total Valid Loss:  2.0883236726125083  Time:  0.02393651008605957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.023595721860017096  Time:  1.2885560989379883\n",
      "Total Valid Loss:  2.0412871837615967  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.023374420118989884  Time:  1.4301741123199463\n",
      "Total Valid Loss:  2.097905238469442  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.023381295577659236  Time:  1.2945384979248047\n",
      "Total Valid Loss:  2.043670892715454  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.02338644443684584  Time:  1.7154133319854736\n",
      "Total Valid Loss:  2.0832866032918296  Time:  0.024932861328125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.023370950543261194  Time:  1.57977294921875\n",
      "Total Valid Loss:  2.0934669971466064  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.02320779013362798  Time:  1.5468878746032715\n",
      "Total Valid Loss:  2.03853448232015  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.023562205132919473  Time:  1.4501216411590576\n",
      "Total Valid Loss:  2.0663681030273438  Time:  0.02892160415649414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.022965456419563914  Time:  1.7144145965576172\n",
      "Total Valid Loss:  2.071761131286621  Time:  0.030918359756469727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.023277275457784727  Time:  1.7104251384735107\n",
      "Total Valid Loss:  2.0654799143473306  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.02312763606186037  Time:  1.657569408416748\n",
      "Total Valid Loss:  2.0830509662628174  Time:  0.029918670654296875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.023444454778324474  Time:  1.6296441555023193\n",
      "Total Valid Loss:  2.0963186422983804  Time:  0.0359036922454834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.023120117821283155  Time:  1.6196670532226562\n",
      "Total Valid Loss:  2.0896337827046714  Time:  0.02892589569091797\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.023154688974866618  Time:  1.5817673206329346\n",
      "Total Valid Loss:  2.045090595881144  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.023156487757896447  Time:  1.7612876892089844\n",
      "Total Valid Loss:  2.075638214747111  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.023148349208104147  Time:  1.5129566192626953\n",
      "Total Valid Loss:  2.0910730361938477  Time:  0.028920888900756836\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.023227646051869763  Time:  1.6655452251434326\n",
      "Total Valid Loss:  2.103597561518351  Time:  0.05584907531738281\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.02308092246969025  Time:  1.8879518508911133\n",
      "Total Valid Loss:  2.0624547799428306  Time:  0.03490710258483887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.023226702029441857  Time:  1.6077024936676025\n",
      "Total Valid Loss:  2.070834239323934  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.02292534730747923  Time:  1.582766056060791\n",
      "Total Valid Loss:  2.0856836636861167  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.022766377994572963  Time:  1.823124885559082\n",
      "Total Valid Loss:  2.073120673497518  Time:  0.03191518783569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.022904334855931147  Time:  1.7393548488616943\n",
      "Total Valid Loss:  2.0641001065572104  Time:  0.03590536117553711\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.023205413858031296  Time:  1.7144463062286377\n",
      "Total Valid Loss:  2.1001555919647217  Time:  0.03287863731384277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.02278964233572607  Time:  1.750352144241333\n",
      "Total Valid Loss:  2.0760576725006104  Time:  0.029890060424804688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.023040545547937417  Time:  2.080437660217285\n",
      "Total Valid Loss:  2.0477503140767417  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.023061946953658933  Time:  1.757333755493164\n",
      "Total Valid Loss:  2.0609629154205322  Time:  0.03786587715148926\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.023247493600303478  Time:  1.7882165908813477\n",
      "Total Valid Loss:  2.0648231506347656  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.02315307597254778  Time:  1.827115774154663\n",
      "Total Valid Loss:  2.0839285055796304  Time:  0.03892707824707031\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.0227813364139625  Time:  1.8909127712249756\n",
      "Total Valid Loss:  2.0777167479197183  Time:  0.031914710998535156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.02327237210490487  Time:  1.7483246326446533\n",
      "Total Valid Loss:  2.0606419245402017  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.02310488573819786  Time:  1.7872180938720703\n",
      "Total Valid Loss:  2.0594120820363364  Time:  0.033911943435668945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.022930845255395033  Time:  1.8271126747131348\n",
      "Total Valid Loss:  2.0832045873006186  Time:  0.03390860557556152\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.02294867072109278  Time:  2.124455690383911\n",
      "Total Valid Loss:  2.0514140923817954  Time:  0.04088854789733887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.023137931288643318  Time:  2.2220559120178223\n",
      "Total Valid Loss:  2.055012861887614  Time:  0.03989291191101074\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.0229780636002104  Time:  2.2659409046173096\n",
      "Total Valid Loss:  2.0654032230377197  Time:  0.056847572326660156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.02281526272947138  Time:  2.0834288597106934\n",
      "Total Valid Loss:  2.0795506636301675  Time:  0.03690314292907715\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.02340285535659883  Time:  1.6426057815551758\n",
      "Total Valid Loss:  2.0531606674194336  Time:  0.032913923263549805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.022640174666008393  Time:  1.8749847412109375\n",
      "Total Valid Loss:  2.0792298316955566  Time:  0.03191018104553223\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.022820749041902556  Time:  2.051513433456421\n",
      "Total Valid Loss:  2.0557119051615396  Time:  0.04288125038146973\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.023026165104918665  Time:  1.8570351600646973\n",
      "Total Valid Loss:  2.055023511250814  Time:  0.031915903091430664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.02292525175620209  Time:  1.9308350086212158\n",
      "Total Valid Loss:  2.0771013100941977  Time:  0.031915903091430664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.023108738147980208  Time:  1.8580303192138672\n",
      "Total Valid Loss:  2.1175173123677573  Time:  0.039893150329589844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.02314226897796253  Time:  1.8101611137390137\n",
      "Total Valid Loss:  2.0652883847554526  Time:  0.03490495681762695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.022900902363774064  Time:  1.790212631225586\n",
      "Total Valid Loss:  2.085503260294596  Time:  0.02892613410949707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.02302879588557528  Time:  1.8600246906280518\n",
      "Total Valid Loss:  2.0841095447540283  Time:  0.03194904327392578\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.02296487038785761  Time:  1.734358787536621\n",
      "Total Valid Loss:  2.071115573247274  Time:  0.030913352966308594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.022809061499965654  Time:  1.6805071830749512\n",
      "Total Valid Loss:  2.1099135875701904  Time:  0.04387998580932617\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.022802912472904502  Time:  1.7603282928466797\n",
      "Total Valid Loss:  2.077492078145345  Time:  0.0308835506439209\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.022504438126048486  Time:  1.6974599361419678\n",
      "Total Valid Loss:  2.105268716812134  Time:  0.04089093208312988\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.0227143702085142  Time:  1.8330965042114258\n",
      "Total Valid Loss:  2.0909101168314614  Time:  0.045877933502197266\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  85.16006851196289\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.674164673700 =======\n",
      "======= Set val : score(recall_10)=0.731924360400 =======\n",
      "======= Set val : score(recall_20)=0.773451983686 =======\n",
      "======= Set val : score(map_cut_10)=0.656279169683 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  3\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.024237458426982928  Time:  1.1309754848480225\n",
      "Total Valid Loss:  2.0134023825327554  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.020764832599804953  Time:  0.9245266914367676\n",
      "Total Valid Loss:  2.0241947968800864  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.020405834588484887  Time:  0.7849025726318359\n",
      "Total Valid Loss:  2.0187527338663735  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.020032450508994933  Time:  0.8876245021820068\n",
      "Total Valid Loss:  2.0333274205525718  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.020009335512534168  Time:  1.037226676940918\n",
      "Total Valid Loss:  2.025327483812968  Time:  0.04587745666503906\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.020328283835297976  Time:  0.9414827823638916\n",
      "Total Valid Loss:  2.0268165667851767  Time:  0.025929927825927734\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.020264635340143472  Time:  0.9295144081115723\n",
      "Total Valid Loss:  2.041879733403524  Time:  0.026929616928100586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.020250353293541152  Time:  0.9285182952880859\n",
      "Total Valid Loss:  2.0475106636683145  Time:  0.030916213989257812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.019980724518879864  Time:  1.088097095489502\n",
      "Total Valid Loss:  2.0146411259969077  Time:  0.058836936950683594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.020024219002479162  Time:  1.0930771827697754\n",
      "Total Valid Loss:  2.067145506540934  Time:  0.054851531982421875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.01955434508048571  Time:  1.0511882305145264\n",
      "Total Valid Loss:  2.0105909506479898  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.019597864208313134  Time:  0.8916149139404297\n",
      "Total Valid Loss:  2.021293878555298  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.01992333236222084  Time:  0.9973325729370117\n",
      "Total Valid Loss:  2.0505735874176025  Time:  0.034906864166259766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.02010016845395932  Time:  0.9684112071990967\n",
      "Total Valid Loss:  2.047440449396769  Time:  0.03390693664550781\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.019700058282185823  Time:  1.0003266334533691\n",
      "Total Valid Loss:  2.032736619313558  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.02000354139659649  Time:  1.0053107738494873\n",
      "Total Valid Loss:  2.024435798327128  Time:  0.03690147399902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.019966682992302455  Time:  0.964425802230835\n",
      "Total Valid Loss:  2.0648361841837564  Time:  0.03689908981323242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.019898579623072576  Time:  0.9674117565155029\n",
      "Total Valid Loss:  2.037059466044108  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.02000118596240496  Time:  1.089087724685669\n",
      "Total Valid Loss:  2.0619895458221436  Time:  0.04388260841369629\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.0203392809877793  Time:  0.9564418792724609\n",
      "Total Valid Loss:  2.0180830160776773  Time:  0.03191542625427246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.019818717518295996  Time:  1.0192780494689941\n",
      "Total Valid Loss:  2.011503299077352  Time:  0.03689837455749512\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.020292148280602235  Time:  0.9614286422729492\n",
      "Total Valid Loss:  2.0306445757548013  Time:  0.03490710258483887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.019838776869269516  Time:  1.0252583026885986\n",
      "Total Valid Loss:  2.0046672026316323  Time:  0.05086469650268555\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.01978244384129842  Time:  0.9893543720245361\n",
      "Total Valid Loss:  2.0249048868815103  Time:  0.031915903091430664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.020209312009123657  Time:  0.9574382305145264\n",
      "Total Valid Loss:  2.0177534421284995  Time:  0.03789854049682617\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.020042541699531752  Time:  0.9664156436920166\n",
      "Total Valid Loss:  2.007654587427775  Time:  0.036902666091918945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.02023923163039562  Time:  0.9873597621917725\n",
      "Total Valid Loss:  2.0254125197728476  Time:  0.035902976989746094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.01996035759265606  Time:  1.0182771682739258\n",
      "Total Valid Loss:  2.024652640024821  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.020030285924291  Time:  0.9664158821105957\n",
      "Total Valid Loss:  1.9890278975168865  Time:  0.03291177749633789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.02021265746309207  Time:  0.8896210193634033\n",
      "Total Valid Loss:  2.020108779271444  Time:  0.03490757942199707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.02003243087958067  Time:  0.8906188011169434\n",
      "Total Valid Loss:  2.014192978541056  Time:  0.03191566467285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.019845554796166908  Time:  0.8866274356842041\n",
      "Total Valid Loss:  2.0103856325149536  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.0200586914538573  Time:  0.8886234760284424\n",
      "Total Valid Loss:  2.0427900155385337  Time:  0.03091716766357422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.019579458360870678  Time:  0.7938766479492188\n",
      "Total Valid Loss:  2.0198022524515786  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.020085070950862687  Time:  0.8417479991912842\n",
      "Total Valid Loss:  2.012401739756266  Time:  0.0329127311706543\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.019895118064223193  Time:  0.8706707954406738\n",
      "Total Valid Loss:  1.999688982963562  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.019878931152514923  Time:  0.9225344657897949\n",
      "Total Valid Loss:  2.0211805502573648  Time:  0.03390908241271973\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.019635672227312356  Time:  0.9265232086181641\n",
      "Total Valid Loss:  2.0132352908452353  Time:  0.038897037506103516\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.01989598013460636  Time:  0.8656837940216064\n",
      "Total Valid Loss:  2.0264594157536826  Time:  0.030931711196899414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.019745867365063764  Time:  1.0312273502349854\n",
      "Total Valid Loss:  2.0296094020207724  Time:  0.030921459197998047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.020028497498386946  Time:  0.935495138168335\n",
      "Total Valid Loss:  2.0278009176254272  Time:  0.03690290451049805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.02012310138879678  Time:  0.8696720600128174\n",
      "Total Valid Loss:  2.0358265240987143  Time:  0.02792811393737793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.019932115546021707  Time:  0.8816430568695068\n",
      "Total Valid Loss:  1.9920986890792847  Time:  0.028921127319335938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.02010586232137986  Time:  0.8527204990386963\n",
      "Total Valid Loss:  2.0300947030385337  Time:  0.057845115661621094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.01956614001821249  Time:  0.9354982376098633\n",
      "Total Valid Loss:  2.0353508790334067  Time:  0.0329127311706543\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.019777155075317774  Time:  0.9714021682739258\n",
      "Total Valid Loss:  2.0100327730178833  Time:  0.04188799858093262\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.019456509644022353  Time:  1.0870928764343262\n",
      "Total Valid Loss:  2.0212822755177817  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.019837534102873925  Time:  0.9265241622924805\n",
      "Total Valid Loss:  2.0397636890411377  Time:  0.04587888717651367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.01963987430700889  Time:  1.1329691410064697\n",
      "Total Valid Loss:  2.029837210973104  Time:  0.050862789154052734\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.019375484675551072  Time:  0.9853658676147461\n",
      "Total Valid Loss:  1.9890378316243489  Time:  0.028922080993652344\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  78.65928530693054\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.669570894605 =======\n",
      "======= Set val : score(recall_10)=0.731553578050 =======\n",
      "======= Set val : score(recall_20)=0.773081201335 =======\n",
      "======= Set val : score(map_cut_10)=0.650302805586 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  1\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for _, do in enumerate([9, 5, 2]):\n",
    "    args.num_negative = do\n",
    "    ndcg = build(args)\n",
    "    print('num_negative: ', do)\n",
    "    score.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data_dir='DATA/', tgt_market='t1', src_markets='none', use_qrel=False, tgt_market_valid='DATA/t1/valid_run.tsv', tgt_market_test='DATA/t1/test_run.tsv', exp_name='xx1', train_data_file='train_5core.tsv', alias='nmf', pretrain='checkpoints/t1_none_xx1.model', idbank_pretrain='checkpoints/t1_none_xx1.pickle', freeze_bottom=False, num_epoch=10, batch_size=1024, lr=0.01, l2_reg=1e-07, optimizer='adam', latent_dim=512, latent_dim_mlp=512, num_negative=2, sample_func=<function <lambda> at 0x000001CFD2D16310>, mlp_layers=(1024, 512, 256, 128, 64), drop_rate=0.2, cuda=True, seed=73, fastmode=True, device=device(type='opengl'), **{' fastmode': True})\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 512)\n",
      "  (gmf_embedding_item): Embedding(1386, 512)\n",
      "  (mlp_embedding_user): Embedding(2698, 512)\n",
      "  (mlp_embedding_item): Embedding(1386, 512)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=576, out_features=1, bias=True)\n",
      "  (affine_output2): Linear(in_features=12, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "indv = build(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.02280645820757617  Time:  2.1492154598236084\n",
      "Total Valid Loss:  2.078596512476603  Time:  0.02393651008605957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.022477439742373383  Time:  2.1223275661468506\n",
      "Total Valid Loss:  2.105891704559326  Time:  0.03689837455749512\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.022278782158442166  Time:  1.9637513160705566\n",
      "Total Valid Loss:  2.111255168914795  Time:  0.023937225341796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.022770280261402546  Time:  2.249983549118042\n",
      "Total Valid Loss:  2.0855756600697837  Time:  0.025930166244506836\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.02210188723452713  Time:  2.1752588748931885\n",
      "Total Valid Loss:  2.081767956415812  Time:  0.0249330997467041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.022372297942638397  Time:  1.8899459838867188\n",
      "Total Valid Loss:  2.11018705368042  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.022206625228990678  Time:  1.8929402828216553\n",
      "Total Valid Loss:  2.1242193380991616  Time:  0.024933338165283203\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.022140329428341078  Time:  2.142275810241699\n",
      "Total Valid Loss:  2.0394074122111  Time:  0.024932384490966797\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.022262514868508214  Time:  2.207101345062256\n",
      "Total Valid Loss:  2.085021734237671  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.02237939956071584  Time:  1.957766056060791\n",
      "Total Valid Loss:  2.116692622502645  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.02234690908504569  Time:  1.8909425735473633\n",
      "Total Valid Loss:  2.092081308364868  Time:  0.024933815002441406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.022152133577543757  Time:  1.9218635559082031\n",
      "Total Valid Loss:  2.08197013537089  Time:  0.03390860557556152\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.02195526951033136  Time:  2.0634853839874268\n",
      "Total Valid Loss:  2.0996580918629966  Time:  0.024932384490966797\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.021803305524846783  Time:  2.1821649074554443\n",
      "Total Valid Loss:  2.105177640914917  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.022039850687851078  Time:  2.3367552757263184\n",
      "Total Valid Loss:  2.070020914077759  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.021939113817137222  Time:  2.436488389968872\n",
      "Total Valid Loss:  2.097860336303711  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.022177213883918266  Time:  2.225051164627075\n",
      "Total Valid Loss:  2.14866312344869  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.021979821068437204  Time:  2.3657078742980957\n",
      "Total Valid Loss:  2.130892356236776  Time:  0.030887365341186523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.022454418339159177  Time:  2.1642117500305176\n",
      "Total Valid Loss:  2.124079942703247  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.022098773669289504  Time:  2.1332993507385254\n",
      "Total Valid Loss:  2.105394204457601  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  74.61357045173645\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.663801698063 =======\n",
      "======= Set val : score(recall_10)=0.721171672228 =======\n",
      "======= Set val : score(recall_20)=0.757879124954 =======\n",
      "======= Set val : score(map_cut_10)=0.646043369764 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  10\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.02258884922965713  Time:  2.0654408931732178\n",
      "Total Valid Loss:  2.124430020650228  Time:  0.0249326229095459\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.022045083003847495  Time:  1.8889501094818115\n",
      "Total Valid Loss:  2.104304790496826  Time:  0.02393627166748047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.021973604255396385  Time:  2.1771790981292725\n",
      "Total Valid Loss:  2.1109229723612466  Time:  0.024933576583862305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.022153136425692103  Time:  2.0026464462280273\n",
      "Total Valid Loss:  2.1121412913004556  Time:  0.024933576583862305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.02177129078494466  Time:  2.0206003189086914\n",
      "Total Valid Loss:  2.0757188399632773  Time:  0.0408933162689209\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.02187477094323739  Time:  2.1003828048706055\n",
      "Total Valid Loss:  2.1294796466827393  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.02202378597272479  Time:  2.451446533203125\n",
      "Total Valid Loss:  2.136617739995321  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.021961499118934507  Time:  2.3776440620422363\n",
      "Total Valid Loss:  2.0475898583730063  Time:  0.034881591796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.02205541219724261  Time:  2.1781771183013916\n",
      "Total Valid Loss:  2.1031126976013184  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.02206470047974068  Time:  2.180169105529785\n",
      "Total Valid Loss:  2.11591108640035  Time:  0.046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.021955777656124987  Time:  2.2779107093811035\n",
      "Total Valid Loss:  2.0939101378122964  Time:  0.03690314292907715\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.021748472847368406  Time:  2.155238151550293\n",
      "Total Valid Loss:  2.0763407548268638  Time:  0.03091740608215332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.021708543064153714  Time:  2.129307746887207\n",
      "Total Valid Loss:  2.090968290964762  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.021618783959875935  Time:  2.1622228622436523\n",
      "Total Valid Loss:  2.1019184589385986  Time:  0.029918909072875977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.02186245557082736  Time:  2.5092897415161133\n",
      "Total Valid Loss:  2.073515256245931  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.0218315363092267  Time:  2.2051098346710205\n",
      "Total Valid Loss:  2.088211456934611  Time:  0.027922630310058594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.021866336999380072  Time:  2.2948648929595947\n",
      "Total Valid Loss:  2.1311470667521157  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.021754499686800915  Time:  2.075448751449585\n",
      "Total Valid Loss:  2.13519279162089  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.022269442272575005  Time:  2.1721954345703125\n",
      "Total Valid Loss:  2.1157514254252114  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.021957892130898393  Time:  2.1422715187072754\n",
      "Total Valid Loss:  2.110623757044474  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  76.42485165596008\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.664209296455 =======\n",
      "======= Set val : score(recall_10)=0.720800889878 =======\n",
      "======= Set val : score(recall_20)=0.763440860215 =======\n",
      "======= Set val : score(map_cut_10)=0.646544661617 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  8\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.02266171652337779  Time:  1.8619763851165771\n",
      "Total Valid Loss:  2.120984156926473  Time:  0.02393651008605957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.022067594560592072  Time:  1.9009203910827637\n",
      "Total Valid Loss:  2.1164429982503257  Time:  0.024972915649414062\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.021878674901697946  Time:  2.015570640563965\n",
      "Total Valid Loss:  2.106852372487386  Time:  0.05884504318237305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.022112447444511497  Time:  1.9078974723815918\n",
      "Total Valid Loss:  2.0893354415893555  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.021740012875069742  Time:  2.0076329708099365\n",
      "Total Valid Loss:  2.0873874028523765  Time:  0.04089045524597168\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.02187180779874325  Time:  2.351713180541992\n",
      "Total Valid Loss:  2.1327993869781494  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.02180946104876373  Time:  2.246992826461792\n",
      "Total Valid Loss:  2.1197498639424643  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.021757839846870172  Time:  2.135294198989868\n",
      "Total Valid Loss:  2.044910271962484  Time:  0.03590512275695801\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.021870312289051386  Time:  2.4953267574310303\n",
      "Total Valid Loss:  2.0995917320251465  Time:  0.04089164733886719\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.021977333627317262  Time:  2.3227896690368652\n",
      "Total Valid Loss:  2.108863194783529  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.02198315484692221  Time:  2.3088314533233643\n",
      "Total Valid Loss:  2.1191726525624595  Time:  0.038895368576049805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.021848674993152205  Time:  2.5192666053771973\n",
      "Total Valid Loss:  2.087519963582357  Time:  0.033908843994140625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.021758605669374053  Time:  2.9162051677703857\n",
      "Total Valid Loss:  2.087371349334717  Time:  0.03989291191101074\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.021726408778973246  Time:  2.8164708614349365\n",
      "Total Valid Loss:  2.1139768759409585  Time:  0.0468745231628418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.02190232949088449  Time:  2.6788389682769775\n",
      "Total Valid Loss:  2.0885510444641113  Time:  0.026931047439575195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.02164409222162288  Time:  3.0029704570770264\n",
      "Total Valid Loss:  2.103627920150757  Time:  0.05086684226989746\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.02179700108649938  Time:  3.3829548358917236\n",
      "Total Valid Loss:  2.1408437887827554  Time:  0.03390979766845703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.021523149295345597  Time:  3.1056952476501465\n",
      "Total Valid Loss:  2.1405980587005615  Time:  0.040891408920288086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.02206492803019026  Time:  3.4627432823181152\n",
      "Total Valid Loss:  2.097272793451945  Time:  0.04587578773498535\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.021946973288836685  Time:  3.8716483116149902\n",
      "Total Valid Loss:  2.1006104946136475  Time:  0.04488062858581543\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  87.25374579429626\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.663826008675 =======\n",
      "======= Set val : score(recall_10)=0.718946978124 =======\n",
      "======= Set val : score(recall_20)=0.762699295514 =======\n",
      "======= Set val : score(map_cut_10)=0.646697094361 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  6\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.02268292544328648  Time:  1.8709993362426758\n",
      "Total Valid Loss:  2.133024533589681  Time:  0.02493453025817871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.021992290781243987  Time:  1.9577674865722656\n",
      "Total Valid Loss:  2.1006178061167398  Time:  0.023937225341796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.021910976731906767  Time:  1.873988151550293\n",
      "Total Valid Loss:  2.109727462132772  Time:  0.02393651008605957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.02204388088506201  Time:  1.8819682598114014\n",
      "Total Valid Loss:  2.093283176422119  Time:  0.04288649559020996\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.021733463587968245  Time:  2.1442668437957764\n",
      "Total Valid Loss:  2.0995909372965493  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.021780172460105107  Time:  2.173192262649536\n",
      "Total Valid Loss:  2.1007864475250244  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.021822635537904242  Time:  2.194131374359131\n",
      "Total Valid Loss:  2.1248720486958823  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.021706561112533444  Time:  2.592071771621704\n",
      "Total Valid Loss:  2.0593045949935913  Time:  0.030918359756469727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.021764030631469644  Time:  2.5980615615844727\n",
      "Total Valid Loss:  2.0878728230794272  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.02199524781950142  Time:  2.445462465286255\n",
      "Total Valid Loss:  2.126983563105265  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.021845264943397565  Time:  2.2549731731414795\n",
      "Total Valid Loss:  2.0976248582204184  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.021811933977448423  Time:  3.118662118911743\n",
      "Total Valid Loss:  2.0928356647491455  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.02168014056008795  Time:  2.52325439453125\n",
      "Total Valid Loss:  2.0891059239705405  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.0216027756586023  Time:  3.1785011291503906\n",
      "Total Valid Loss:  2.117183049519857  Time:  0.027930259704589844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.021857703493341155  Time:  2.4035751819610596\n",
      "Total Valid Loss:  2.1047933101654053  Time:  0.04188728332519531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.02182248289818349  Time:  2.3547048568725586\n",
      "Total Valid Loss:  2.1001177628835044  Time:  0.05485868453979492\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.02176580144011456  Time:  2.6509127616882324\n",
      "Total Valid Loss:  2.147714376449585  Time:  0.039893388748168945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.02173701004813547  Time:  2.579106330871582\n",
      "Total Valid Loss:  2.1391701698303223  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.022291413613635562  Time:  2.489342451095581\n",
      "Total Valid Loss:  2.11763596534729  Time:  0.043883323669433594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.0219830430234256  Time:  2.8025081157684326\n",
      "Total Valid Loss:  2.098956823348999  Time:  0.04288935661315918\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  76.37885761260986\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.663785795246 =======\n",
      "======= Set val : score(recall_10)=0.720800889878 =======\n",
      "======= Set val : score(recall_20)=0.764182424917 =======\n",
      "======= Set val : score(map_cut_10)=0.645959649464 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  4\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_xx1.model are loaded!\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.0225942750663861  Time:  2.079439163208008\n",
      "Total Valid Loss:  2.1321855386098227  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.021912950180147005  Time:  1.9627528190612793\n",
      "Total Valid Loss:  2.115006764729818  Time:  0.024933576583862305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.021897416416069737  Time:  1.9218621253967285\n",
      "Total Valid Loss:  2.1034987767537436  Time:  0.029921531677246094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.022159702217449312  Time:  2.2220592498779297\n",
      "Total Valid Loss:  2.099131425221761  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.021722138543491778  Time:  2.214080810546875\n",
      "Total Valid Loss:  2.0914885997772217  Time:  0.027924776077270508\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.02182090026528939  Time:  2.1731903553009033\n",
      "Total Valid Loss:  2.1090593338012695  Time:  0.0329134464263916\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.0217650451251994  Time:  2.2330291271209717\n",
      "Total Valid Loss:  2.126244306564331  Time:  0.03690195083618164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.02178687769109788  Time:  2.5252485275268555\n",
      "Total Valid Loss:  2.068419615427653  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.021738024687637452  Time:  2.4883475303649902\n",
      "Total Valid Loss:  2.0904111862182617  Time:  0.03889584541320801\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.02203730247590853  Time:  2.3048391342163086\n",
      "Total Valid Loss:  2.127281109491984  Time:  0.02991938591003418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.021885971141898115  Time:  2.456432580947876\n",
      "Total Valid Loss:  2.104795296986898  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.02174513560274373  Time:  2.5761163234710693\n",
      "Total Valid Loss:  2.0846877892812095  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.021616373227342316  Time:  2.3158071041107178\n",
      "Total Valid Loss:  2.0815059343973794  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.021691134086121684  Time:  2.233030080795288\n",
      "Total Valid Loss:  2.103319009145101  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.021843278246081392  Time:  2.3596925735473633\n",
      "Total Valid Loss:  2.091890811920166  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.021605052831380263  Time:  2.1442673206329346\n",
      "Total Valid Loss:  2.1131288210550943  Time:  0.029921531677246094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.021686136819746182  Time:  2.249985933303833\n",
      "Total Valid Loss:  2.1362756888071694  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.021635828426350718  Time:  2.435487985610962\n",
      "Total Valid Loss:  2.1390204429626465  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.02201063696133054  Time:  2.191145181655884\n",
      "Total Valid Loss:  2.1194349924723306  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.022026879081259602  Time:  2.258990526199341\n",
      "Total Valid Loss:  2.1013335386912027  Time:  0.03587198257446289\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  74.98959589004517\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.662412478463 =======\n",
      "======= Set val : score(recall_10)=0.714126807564 =======\n",
      "======= Set val : score(recall_20)=0.764923989618 =======\n",
      "======= Set val : score(map_cut_10)=0.646143863552 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "num_negative:  2\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for _, do in enumerate([10, 8, 6, 4, 2]):\n",
    "    args.num_negative = 5\n",
    "    ndcg = build(args)\n",
    "    print('num_negative: ', do)\n",
    "    #score.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.14473690824664157  Time:  4.7237770557403564\n",
      "Total Valid Loss:  2.556901693344116  Time:  0.03490757942199707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.09884700373463008  Time:  2.300846815109253\n",
      "Total Valid Loss:  2.553904136021932  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.09704477041959762  Time:  2.3028411865234375\n",
      "Total Valid Loss:  2.5041595300038657  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.09652394930953564  Time:  1.9338293075561523\n",
      "Total Valid Loss:  2.4526928265889487  Time:  0.0359039306640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.09487009618593299  Time:  2.024585723876953\n",
      "Total Valid Loss:  2.436297575632731  Time:  0.046877384185791016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.09368777177903963  Time:  2.678835153579712\n",
      "Total Valid Loss:  2.5746235052744546  Time:  0.042870283126831055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.08930743816106215  Time:  2.3138129711151123\n",
      "Total Valid Loss:  2.484591563542684  Time:  0.02393651008605957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.08371956108704857  Time:  2.463412046432495\n",
      "Total Valid Loss:  2.4385040601094565  Time:  0.03391122817993164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.07744494469269463  Time:  2.503305196762085\n",
      "Total Valid Loss:  2.266333738962809  Time:  0.043881893157958984\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.07163111194968223  Time:  2.1642119884490967\n",
      "Total Valid Loss:  2.248179276784261  Time:  0.06382918357849121\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.06525742330628892  Time:  2.251979351043701\n",
      "Total Valid Loss:  2.2930822372436523  Time:  0.04587674140930176\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.06038362610599269  Time:  2.9072654247283936\n",
      "Total Valid Loss:  2.2599547704060874  Time:  0.040851593017578125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.0560794556270475  Time:  2.4584269523620605\n",
      "Total Valid Loss:  2.194915850957235  Time:  0.0608363151550293\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.05177796091074529  Time:  2.2430028915405273\n",
      "Total Valid Loss:  2.2177247206370034  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.04752798624660658  Time:  2.261953115463257\n",
      "Total Valid Loss:  2.2401676177978516  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.04438887533286343  Time:  2.073453664779663\n",
      "Total Valid Loss:  2.1906967957814536  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.041622567209212674  Time:  1.998656988143921\n",
      "Total Valid Loss:  2.202279885609945  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.03902687180949294  Time:  2.074451208114624\n",
      "Total Valid Loss:  2.156055450439453  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.0370046085961487  Time:  2.268932580947876\n",
      "Total Valid Loss:  2.298457622528076  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.035431554200856585  Time:  2.170196771621704\n",
      "Total Valid Loss:  2.171903212865194  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.03361988422339377  Time:  2.117339849472046\n",
      "Total Valid Loss:  2.1873292128245034  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.03280515818168288  Time:  2.0694639682769775\n",
      "Total Valid Loss:  2.175504446029663  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.031561896399311395  Time:  2.0714609622955322\n",
      "Total Valid Loss:  2.1475722789764404  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.03066856368728306  Time:  2.064481019973755\n",
      "Total Valid Loss:  2.17671807607015  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.029402756804357406  Time:  2.044530153274536\n",
      "Total Valid Loss:  2.1867576440175376  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.029003932796742606  Time:  2.1143484115600586\n",
      "Total Valid Loss:  2.219932238260905  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.02819159304642159  Time:  2.0934035778045654\n",
      "Total Valid Loss:  2.116415103276571  Time:  0.03091597557067871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.02768583032100097  Time:  2.135289430618286\n",
      "Total Valid Loss:  2.132348378499349  Time:  0.03291177749633789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.027079603545691656  Time:  1.9846930503845215\n",
      "Total Valid Loss:  2.121882597605387  Time:  0.026927471160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.026547674024882523  Time:  2.0295732021331787\n",
      "Total Valid Loss:  2.1170485814412436  Time:  0.026927471160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.026363157416167467  Time:  2.9012420177459717\n",
      "Total Valid Loss:  2.1616318225860596  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.025705070761234863  Time:  2.2779088020324707\n",
      "Total Valid Loss:  2.154442230860392  Time:  0.04488086700439453\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.025514261440738387  Time:  2.6698601245880127\n",
      "Total Valid Loss:  2.1679166158040366  Time:  0.031914710998535156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.025080214942926945  Time:  2.3417375087738037\n",
      "Total Valid Loss:  2.1576531728108725  Time:  0.02692866325378418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.025037164273469345  Time:  2.368669271469116\n",
      "Total Valid Loss:  2.152761618296305  Time:  0.04088759422302246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.024715763152293537  Time:  2.2370197772979736\n",
      "Total Valid Loss:  2.062739690144857  Time:  0.025931835174560547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.024138602241873742  Time:  2.2928664684295654\n",
      "Total Valid Loss:  2.1818930308024087  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.023919361181881118  Time:  2.1751835346221924\n",
      "Total Valid Loss:  2.1225443681081138  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.023807627723916716  Time:  2.511284589767456\n",
      "Total Valid Loss:  2.1249636809031167  Time:  0.026927471160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.02398122968557088  Time:  2.481365442276001\n",
      "Total Valid Loss:  2.208533843358358  Time:  0.024933338165283203\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.02359199698852456  Time:  2.24798846244812\n",
      "Total Valid Loss:  2.1958245436350503  Time:  0.026930809020996094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.023281253615151282  Time:  2.3726539611816406\n",
      "Total Valid Loss:  2.103669802347819  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.023078790209863496  Time:  2.423518419265747\n",
      "Total Valid Loss:  2.120337804158529  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.022832884736683056  Time:  2.215075731277466\n",
      "Total Valid Loss:  2.2024178504943848  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.02248983804298484  Time:  2.830432176589966\n",
      "Total Valid Loss:  2.122711102167765  Time:  0.04887104034423828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.022697708836716155  Time:  2.7925329208374023\n",
      "Total Valid Loss:  2.2084310054779053  Time:  0.0359041690826416\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.02234010085787462  Time:  2.2808997631073\n",
      "Total Valid Loss:  2.132944663365682  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.022460887240974798  Time:  2.3367514610290527\n",
      "Total Valid Loss:  2.058821121851603  Time:  0.03091883659362793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.02220743560920591  Time:  2.847386121749878\n",
      "Total Valid Loss:  2.124841054280599  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.02214811102527639  Time:  2.399583339691162\n",
      "Total Valid Loss:  2.0677267710367837  Time:  0.03590559959411621\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.021818538026317308  Time:  2.6718533039093018\n",
      "Total Valid Loss:  2.12958296140035  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.0216054478255303  Time:  2.6668694019317627\n",
      "Total Valid Loss:  2.1150478521982827  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.021707188176072163  Time:  2.3287711143493652\n",
      "Total Valid Loss:  2.123676379521688  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.021644394666604373  Time:  2.9291675090789795\n",
      "Total Valid Loss:  2.084124485651652  Time:  0.03091907501220703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.0213908936990344  Time:  2.4205265045166016\n",
      "Total Valid Loss:  2.0876012643178306  Time:  0.05485272407531738\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.021194646701864574  Time:  2.205103635787964\n",
      "Total Valid Loss:  2.150813420613607  Time:  0.0359041690826416\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.02075526392006356  Time:  2.551177740097046\n",
      "Total Valid Loss:  2.149447758992513  Time:  0.02692866325378418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.02140339450991672  Time:  2.34572696685791\n",
      "Total Valid Loss:  2.174696445465088  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.02140531792588856  Time:  2.087416648864746\n",
      "Total Valid Loss:  2.171629031499227  Time:  0.03690171241760254\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.02119178909646428  Time:  2.122324228286743\n",
      "Total Valid Loss:  2.0955185095469155  Time:  0.026929140090942383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.021159049317888593  Time:  2.3866195678710938\n",
      "Total Valid Loss:  2.1779492696126304  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.02091963067650795  Time:  2.225050210952759\n",
      "Total Valid Loss:  2.1481932004292807  Time:  0.02692866325378418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.020711363916811734  Time:  2.121330499649048\n",
      "Total Valid Loss:  2.1213313738505044  Time:  0.02593231201171875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.020530374380557433  Time:  2.255964994430542\n",
      "Total Valid Loss:  2.1190810998280845  Time:  0.03291153907775879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.020349436642035194  Time:  2.1851565837860107\n",
      "Total Valid Loss:  2.1299455165863037  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.02055889010105444  Time:  2.3417396545410156\n",
      "Total Valid Loss:  2.0727761586507163  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.02070099748671055  Time:  2.7187275886535645\n",
      "Total Valid Loss:  2.1254994869232178  Time:  0.026929378509521484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.020345528391392333  Time:  2.0894105434417725\n",
      "Total Valid Loss:  2.1386566956837973  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.020335157847274906  Time:  2.5013108253479004\n",
      "Total Valid Loss:  2.176991621653239  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.020655862954647646  Time:  2.3616864681243896\n",
      "Total Valid Loss:  2.1873625119527182  Time:  0.03490567207336426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.020450119593221208  Time:  2.220062017440796\n",
      "Total Valid Loss:  2.105240980784098  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.020722756308058032  Time:  2.7985172271728516\n",
      "Total Valid Loss:  2.1499122778574624  Time:  0.05585122108459473\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.02028705416166264  Time:  2.400581121444702\n",
      "Total Valid Loss:  2.108326514561971  Time:  0.0578463077545166\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.020133399850000507  Time:  2.553171157836914\n",
      "Total Valid Loss:  2.1196311314900718  Time:  0.02992105484008789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.019839918904978295  Time:  2.459423542022705\n",
      "Total Valid Loss:  2.0518210728963218  Time:  0.04986715316772461\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.020018561605526054  Time:  2.3217899799346924\n",
      "Total Valid Loss:  2.0662319660186768  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.019819282545991565  Time:  2.6439309120178223\n",
      "Total Valid Loss:  2.0981558163960776  Time:  0.04487895965576172\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.01998770128449668  Time:  2.5990893840789795\n",
      "Total Valid Loss:  2.0838557879130044  Time:  0.03387284278869629\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.01981487878314827  Time:  2.085421323776245\n",
      "Total Valid Loss:  2.147011915842692  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.01972639217324879  Time:  2.059492826461792\n",
      "Total Valid Loss:  2.0927597681681314  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.019477856677511465  Time:  2.5751140117645264\n",
      "Total Valid Loss:  2.1298865477244058  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.019764744636157284  Time:  2.0714612007141113\n",
      "Total Valid Loss:  2.1142119566599527  Time:  0.026927709579467773\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.019472823713136755  Time:  2.0235888957977295\n",
      "Total Valid Loss:  2.1566436290740967  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.019499118026831876  Time:  2.353705644607544\n",
      "Total Valid Loss:  2.112517754236857  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.02004015421413857  Time:  2.700779438018799\n",
      "Total Valid Loss:  2.1333773930867515  Time:  0.03690195083618164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.019677379079487013  Time:  2.163214921951294\n",
      "Total Valid Loss:  2.1093289057413735  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.01988975494776083  Time:  2.2848899364471436\n",
      "Total Valid Loss:  2.124643564224243  Time:  0.029921770095825195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.019596402557647746  Time:  2.5052995681762695\n",
      "Total Valid Loss:  2.0857906341552734  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.019043296122032663  Time:  2.7855498790740967\n",
      "Total Valid Loss:  2.1178008715311685  Time:  0.03590583801269531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.019196224747144656  Time:  2.233029842376709\n",
      "Total Valid Loss:  2.093630313873291  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.01954399374840052  Time:  2.5292348861694336\n",
      "Total Valid Loss:  2.1103128592173257  Time:  0.029921770095825195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.01937796232169089  Time:  2.5830941200256348\n",
      "Total Valid Loss:  2.150695482889811  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.0194509483711875  Time:  3.072770595550537\n",
      "Total Valid Loss:  2.1531318028767905  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.01924665748425152  Time:  2.3068318367004395\n",
      "Total Valid Loss:  2.1493612925211587  Time:  0.027927398681640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.019114023301264514  Time:  2.404569625854492\n",
      "Total Valid Loss:  2.1608850955963135  Time:  0.030919313430786133\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.01919711368239444  Time:  2.441470146179199\n",
      "Total Valid Loss:  2.1581008434295654  Time:  0.026929855346679688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.019116666362337446  Time:  2.2739171981811523\n",
      "Total Valid Loss:  2.176354090372721  Time:  0.03490924835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.018895587681428246  Time:  2.804500102996826\n",
      "Total Valid Loss:  2.1085036595662436  Time:  0.034905195236206055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.019080833961134372  Time:  2.858358383178711\n",
      "Total Valid Loss:  2.1178393363952637  Time:  0.03191328048706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.019154135251174802  Time:  2.7526392936706543\n",
      "Total Valid Loss:  2.1973540782928467  Time:  0.0299222469329834\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  81.54330277442932\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.649119221361 =======\n",
      "======= Set val : score(recall_10)=0.703374119392 =======\n",
      "======= Set val : score(recall_20)=0.741564701520 =======\n",
      "======= Set val : score(map_cut_10)=0.632230108704 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.14746398115935533  Time:  2.714613914489746\n",
      "Total Valid Loss:  2.6904714902242026  Time:  0.02493572235107422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.1009608078909957  Time:  2.143265962600708\n",
      "Total Valid Loss:  2.6636743545532227  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.09902512444102246  Time:  2.321824073791504\n",
      "Total Valid Loss:  2.749199867248535  Time:  0.02490067481994629\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.09801503303258316  Time:  2.1023781299591064\n",
      "Total Valid Loss:  2.575749238332113  Time:  0.0249330997467041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.09664125520250072  Time:  2.419529914855957\n",
      "Total Valid Loss:  2.565523862838745  Time:  0.03291177749633789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.09536552170048589  Time:  2.366671323776245\n",
      "Total Valid Loss:  2.4399962425231934  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.09179135463807894  Time:  2.5761117935180664\n",
      "Total Valid Loss:  2.452143748601278  Time:  0.03390836715698242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.08663297243740248  Time:  2.4344897270202637\n",
      "Total Valid Loss:  2.4854017893473306  Time:  0.045877695083618164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.08090022906013157  Time:  2.5342233180999756\n",
      "Total Valid Loss:  2.4015084902445474  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.0754594896150672  Time:  2.3367514610290527\n",
      "Total Valid Loss:  2.4508015314737954  Time:  0.031914472579956055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.06959064421446427  Time:  2.5162713527679443\n",
      "Total Valid Loss:  2.352516492207845  Time:  0.026929140090942383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.06516076711856801  Time:  2.559159755706787\n",
      "Total Valid Loss:  2.366084575653076  Time:  0.1166849136352539\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.060807420151389166  Time:  2.53023362159729\n",
      "Total Valid Loss:  2.2355196475982666  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.05685828117572743  Time:  2.4714651107788086\n",
      "Total Valid Loss:  2.329528013865153  Time:  0.031912803649902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.053149679141200105  Time:  2.476379156112671\n",
      "Total Valid Loss:  2.27274227142334  Time:  0.07878780364990234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.050528420507907866  Time:  2.791537284851074\n",
      "Total Valid Loss:  2.2357038656870523  Time:  0.03091883659362793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.047889004842094754  Time:  2.4634475708007812\n",
      "Total Valid Loss:  2.2885149319966636  Time:  0.039858102798461914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.04522201295780099  Time:  2.5122792720794678\n",
      "Total Valid Loss:  2.2971408367156982  Time:  0.029923439025878906\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.0432678317570168  Time:  2.877302885055542\n",
      "Total Valid Loss:  2.2500327428181968  Time:  0.030910491943359375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.04190571058703505  Time:  2.4344897270202637\n",
      "Total Valid Loss:  2.2113704681396484  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.04020747189288554  Time:  2.5192642211914062\n",
      "Total Valid Loss:  2.1795295079549155  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.039292899292448294  Time:  3.1166656017303467\n",
      "Total Valid Loss:  2.148305892944336  Time:  0.05684971809387207\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.0382034809369108  Time:  2.779566764831543\n",
      "Total Valid Loss:  2.1814169883728027  Time:  0.031916141510009766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.03726484943991122  Time:  2.94711971282959\n",
      "Total Valid Loss:  2.2089428106943765  Time:  0.03490853309631348\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.03637253152935401  Time:  2.8593544960021973\n",
      "Total Valid Loss:  2.150232950846354  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.03547924601513407  Time:  2.676870822906494\n",
      "Total Valid Loss:  2.191114902496338  Time:  0.027893781661987305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.034651238633238754  Time:  2.322788715362549\n",
      "Total Valid Loss:  2.149477005004883  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.03495264595941357  Time:  2.1163411140441895\n",
      "Total Valid Loss:  2.1775689919789634  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.03428753476751887  Time:  2.1502525806427\n",
      "Total Valid Loss:  2.0679259300231934  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.03377752007673616  Time:  2.3038406372070312\n",
      "Total Valid Loss:  2.1382671197255454  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.03323420665186384  Time:  2.1362881660461426\n",
      "Total Valid Loss:  2.236797491709391  Time:  0.028958559036254883\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.03273733593523502  Time:  2.166175127029419\n",
      "Total Valid Loss:  2.106888691584269  Time:  0.03191328048706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.032668122924540355  Time:  2.8174660205841064\n",
      "Total Valid Loss:  2.0364593664805093  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.03205458682192409  Time:  2.170196294784546\n",
      "Total Valid Loss:  2.1400481859842935  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.032029062541930574  Time:  2.174187660217285\n",
      "Total Valid Loss:  2.1970953146616616  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.032031850727355995  Time:  2.550178050994873\n",
      "Total Valid Loss:  2.1059888203938804  Time:  0.04886937141418457\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.031419727773122165  Time:  2.450448989868164\n",
      "Total Valid Loss:  2.192076841990153  Time:  0.036932945251464844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.03104637412597304  Time:  2.3566648960113525\n",
      "Total Valid Loss:  2.107841650644938  Time:  0.03889632225036621\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.030660782981178036  Time:  2.7386763095855713\n",
      "Total Valid Loss:  2.1303667227427163  Time:  0.06283164024353027\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.03051879001052483  Time:  2.9231858253479004\n",
      "Total Valid Loss:  2.045476039250692  Time:  0.0418853759765625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.030390587157529333  Time:  2.5441970825195312\n",
      "Total Valid Loss:  2.1423627535502114  Time:  0.034944772720336914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.030239405466810518  Time:  2.599013566970825\n",
      "Total Valid Loss:  2.155795097351074  Time:  0.0359039306640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.02991795282325019  Time:  3.076793670654297\n",
      "Total Valid Loss:  2.1100026766459146  Time:  0.038877010345458984\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.02968912978211175  Time:  2.6489148139953613\n",
      "Total Valid Loss:  2.111290772755941  Time:  0.0329134464263916\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.029180294615419013  Time:  2.471391201019287\n",
      "Total Valid Loss:  2.190557877222697  Time:  0.02991938591003418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.029198280559933704  Time:  2.1981232166290283\n",
      "Total Valid Loss:  2.11332368850708  Time:  0.031916141510009766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.029117525984411655  Time:  2.15024733543396\n",
      "Total Valid Loss:  2.0948754151662192  Time:  0.04288601875305176\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.028715676619954732  Time:  2.214078903198242\n",
      "Total Valid Loss:  2.0892425378163657  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.028555170203680577  Time:  2.128308057785034\n",
      "Total Valid Loss:  2.029879331588745  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.02851388697390971  Time:  2.4444634914398193\n",
      "Total Valid Loss:  2.1200597286224365  Time:  0.03690338134765625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.02820122700346553  Time:  2.3517112731933594\n",
      "Total Valid Loss:  2.0902806917826333  Time:  0.029921293258666992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.02812628982507664  Time:  2.1592235565185547\n",
      "Total Valid Loss:  2.129563649495443  Time:  0.028922080993652344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.028314295459700666  Time:  2.552178382873535\n",
      "Total Valid Loss:  2.1161506175994873  Time:  0.046872615814208984\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.0279912613818179  Time:  2.189145088195801\n",
      "Total Valid Loss:  2.120776812235514  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.027884264338923537  Time:  2.1662070751190186\n",
      "Total Valid Loss:  2.0813426971435547  Time:  0.04089069366455078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.027502921920107757  Time:  2.2130839824676514\n",
      "Total Valid Loss:  2.18220321337382  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.027677800765504006  Time:  2.181197166442871\n",
      "Total Valid Loss:  2.11374831199646  Time:  0.02992534637451172\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.027791018751652345  Time:  2.3237483501434326\n",
      "Total Valid Loss:  2.0477543671925864  Time:  0.026927471160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.027422243129947912  Time:  2.2440006732940674\n",
      "Total Valid Loss:  2.102851231892904  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.027334671726693276  Time:  2.4943771362304688\n",
      "Total Valid Loss:  2.0787854194641113  Time:  0.02892446517944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.027422821764712748  Time:  2.18615460395813\n",
      "Total Valid Loss:  2.022714098294576  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.027120269138527952  Time:  2.3187966346740723\n",
      "Total Valid Loss:  2.033712943394979  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.02684706971049309  Time:  2.1801695823669434\n",
      "Total Valid Loss:  2.070110241572062  Time:  0.030919313430786133\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.0268855223675137  Time:  2.3108205795288086\n",
      "Total Valid Loss:  2.0367721716562905  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.026732114929219952  Time:  2.5023066997528076\n",
      "Total Valid Loss:  2.0366387367248535  Time:  0.03291440010070801\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.026651690155267714  Time:  2.3187994956970215\n",
      "Total Valid Loss:  2.1003143787384033  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.026639799838480742  Time:  2.3237853050231934\n",
      "Total Valid Loss:  2.0394150416056314  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.026651191095943036  Time:  2.444460391998291\n",
      "Total Valid Loss:  2.1163302262624106  Time:  0.03191566467285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.02639908630238927  Time:  2.1462604999542236\n",
      "Total Valid Loss:  2.0375959873199463  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.02640174518784751  Time:  2.202113389968872\n",
      "Total Valid Loss:  2.100139617919922  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.02589933676240237  Time:  2.516268730163574\n",
      "Total Valid Loss:  2.080357392628988  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.02613373082940993  Time:  2.694796085357666\n",
      "Total Valid Loss:  2.1431403160095215  Time:  0.08178162574768066\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.026104632360131844  Time:  2.4185330867767334\n",
      "Total Valid Loss:  2.0964914162953696  Time:  0.03091716766357422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.02582852153674416  Time:  2.1941306591033936\n",
      "Total Valid Loss:  2.1752731005350747  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.025843875531269156  Time:  2.236020088195801\n",
      "Total Valid Loss:  2.0749614238739014  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.02586074714427409  Time:  2.172191619873047\n",
      "Total Valid Loss:  2.072136402130127  Time:  0.03490638732910156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.025923920536170836  Time:  2.2868850231170654\n",
      "Total Valid Loss:  2.063109874725342  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.02573069645010907  Time:  2.2180707454681396\n",
      "Total Valid Loss:  2.1246660550435386  Time:  0.028926372528076172\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.02545792756845122  Time:  2.509284257888794\n",
      "Total Valid Loss:  2.1011380354563394  Time:  0.0359044075012207\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.025615589045312092  Time:  2.1741878986358643\n",
      "Total Valid Loss:  2.1533125241597495  Time:  0.040889739990234375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.025463417399188747  Time:  2.344731092453003\n",
      "Total Valid Loss:  2.0865138371785483  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.02541526411862477  Time:  2.190141439437866\n",
      "Total Valid Loss:  2.0972612698872886  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.02528429735937844  Time:  2.3965935707092285\n",
      "Total Valid Loss:  2.1066016356150308  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.02501453959747501  Time:  2.28788161277771\n",
      "Total Valid Loss:  2.1264286041259766  Time:  0.030918598175048828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.025036658913544986  Time:  2.3906047344207764\n",
      "Total Valid Loss:  2.0981051921844482  Time:  0.03789949417114258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.025515426339014716  Time:  2.42551326751709\n",
      "Total Valid Loss:  2.0505297978719077  Time:  0.028925180435180664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.025349192450875822  Time:  2.6838226318359375\n",
      "Total Valid Loss:  2.1107874711354575  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.024952190660912057  Time:  2.3078291416168213\n",
      "Total Valid Loss:  2.1083617210388184  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.02480678273283917  Time:  2.2120864391326904\n",
      "Total Valid Loss:  2.0678180853525796  Time:  0.03092479705810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.02483677706964638  Time:  2.342726469039917\n",
      "Total Valid Loss:  2.117636760075887  Time:  0.04188799858093262\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.024813488579314688  Time:  2.3576953411102295\n",
      "Total Valid Loss:  2.072019020716349  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.024822759385342185  Time:  2.2340281009674072\n",
      "Total Valid Loss:  2.0757404963175454  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.024978861115548923  Time:  2.477372646331787\n",
      "Total Valid Loss:  2.09696102142334  Time:  0.029956340789794922\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.025045356122048005  Time:  2.1871514320373535\n",
      "Total Valid Loss:  2.101602077484131  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.02459764971357325  Time:  2.2300384044647217\n",
      "Total Valid Loss:  2.0959330399831138  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.024486104269390522  Time:  2.189142942428589\n",
      "Total Valid Loss:  2.0549267133076987  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.024619000324088595  Time:  2.206101417541504\n",
      "Total Valid Loss:  2.0640064080556235  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.02415801448666531  Time:  2.2120859622955322\n",
      "Total Valid Loss:  2.0589224894841514  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.024405585844879566  Time:  2.585085868835449\n",
      "Total Valid Loss:  2.1345836321512857  Time:  0.03191423416137695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.024364887080762697  Time:  2.9201912879943848\n",
      "Total Valid Loss:  2.0704564253489175  Time:  0.04886603355407715\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  77.91836881637573\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.659817060084 =======\n",
      "======= Set val : score(recall_10)=0.713385242862 =======\n",
      "======= Set val : score(recall_20)=0.756766777901 =======\n",
      "======= Set val : score(map_cut_10)=0.642969701785 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.1\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.14989327399627023  Time:  1.9477920532226562\n",
      "Total Valid Loss:  2.6847728888193765  Time:  0.024970293045043945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.10277988567300465  Time:  2.0375137329101562\n",
      "Total Valid Loss:  2.731638034184774  Time:  0.023935556411743164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.10015251234821651  Time:  1.8729937076568604\n",
      "Total Valid Loss:  2.678408940633138  Time:  0.025966405868530273\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.09912175762912502  Time:  2.1083247661590576\n",
      "Total Valid Loss:  2.596853017807007  Time:  0.03191518783569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.0980661383141642  Time:  2.147258758544922\n",
      "Total Valid Loss:  2.610900084177653  Time:  0.04886817932128906\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.09714902432068534  Time:  2.2420060634613037\n",
      "Total Valid Loss:  2.471210797627767  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.09335558071084644  Time:  2.338742971420288\n",
      "Total Valid Loss:  2.502582311630249  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.08883965417094852  Time:  2.1921372413635254\n",
      "Total Valid Loss:  2.4714293479919434  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.08306935798862707  Time:  2.151249408721924\n",
      "Total Valid Loss:  2.4251255989074707  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.07738416849271111  Time:  2.9680609703063965\n",
      "Total Valid Loss:  2.469768444697062  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.0715545088376688  Time:  2.2400460243225098\n",
      "Total Valid Loss:  2.3600082397460938  Time:  0.02792835235595703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.0669826774817446  Time:  2.403533935546875\n",
      "Total Valid Loss:  2.4049890836079917  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.06244041255634764  Time:  2.546196460723877\n",
      "Total Valid Loss:  2.2202134132385254  Time:  0.05386066436767578\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.058515132412962294  Time:  2.347721815109253\n",
      "Total Valid Loss:  2.3827482064565024  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.054692087678805644  Time:  2.616002321243286\n",
      "Total Valid Loss:  2.315336227416992  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.05172387504059336  Time:  2.6120917797088623\n",
      "Total Valid Loss:  2.2150800228118896  Time:  0.031914472579956055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.04941830648028332  Time:  2.3517134189605713\n",
      "Total Valid Loss:  2.355074405670166  Time:  0.031912803649902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.04693059542256853  Time:  2.2978546619415283\n",
      "Total Valid Loss:  2.2370547453562417  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.0451344082860843  Time:  2.2669379711151123\n",
      "Total Valid Loss:  2.2096927960713706  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.04391557519202647  Time:  2.6698622703552246\n",
      "Total Valid Loss:  2.173053741455078  Time:  0.05385470390319824\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.04219849310491396  Time:  2.458425998687744\n",
      "Total Valid Loss:  2.174091418584188  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.040998985521171406  Time:  2.446457624435425\n",
      "Total Valid Loss:  2.162289539972941  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.04014863054389539  Time:  2.403573513031006\n",
      "Total Valid Loss:  2.1678620179494223  Time:  0.02892446517944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.03928220369245695  Time:  2.3826262950897217\n",
      "Total Valid Loss:  2.1660792032877603  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.038241909865451895  Time:  2.3916053771972656\n",
      "Total Valid Loss:  2.174298127492269  Time:  0.0359036922454834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.03725351396462192  Time:  2.3038394451141357\n",
      "Total Valid Loss:  2.160489559173584  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.03672073237274004  Time:  2.3447301387786865\n",
      "Total Valid Loss:  2.100010792414347  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.03687530046571856  Time:  2.4404752254486084\n",
      "Total Valid Loss:  2.187363942464193  Time:  0.025931835174560547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.036225649552500766  Time:  2.404571533203125\n",
      "Total Valid Loss:  2.136475404103597  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.035673805212844974  Time:  2.353703022003174\n",
      "Total Valid Loss:  2.1254096031188965  Time:  0.0329134464263916\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.035332297096433846  Time:  2.588078498840332\n",
      "Total Valid Loss:  2.1817679405212402  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.03475674922051637  Time:  2.38462495803833\n",
      "Total Valid Loss:  2.138840993245443  Time:  0.0329132080078125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.03468462714682455  Time:  2.24200177192688\n",
      "Total Valid Loss:  2.085841099421183  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.03416101240917392  Time:  3.1216533184051514\n",
      "Total Valid Loss:  2.137066920598348  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.033863323117079944  Time:  2.5781054496765137\n",
      "Total Valid Loss:  2.177808920542399  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.033722170215585955  Time:  3.369987726211548\n",
      "Total Valid Loss:  2.152899185816447  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.03320853802496972  Time:  2.6409382820129395\n",
      "Total Valid Loss:  2.1179258028666177  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.03324050231148367  Time:  2.1741859912872314\n",
      "Total Valid Loss:  2.111191431681315  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.032810635556993276  Time:  2.1701977252960205\n",
      "Total Valid Loss:  2.133953253428141  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.03268729155154332  Time:  2.5382134914398193\n",
      "Total Valid Loss:  2.0437537829081216  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.03252881752408069  Time:  2.658888101577759\n",
      "Total Valid Loss:  2.1322859128316245  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.032608146560580836  Time:  2.800508499145508\n",
      "Total Valid Loss:  2.175547202428182  Time:  0.040892601013183594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.03234790952309318  Time:  2.6828267574310303\n",
      "Total Valid Loss:  2.1272059281667075  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.03214734514122424  Time:  2.866333246231079\n",
      "Total Valid Loss:  2.0724445978800454  Time:  0.05186176300048828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.031697938332091204  Time:  2.2330307960510254\n",
      "Total Valid Loss:  2.179691712061564  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.03166695177231146  Time:  2.3776416778564453\n",
      "Total Valid Loss:  2.2017078399658203  Time:  0.032910823822021484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.03153463639318943  Time:  2.9471230506896973\n",
      "Total Valid Loss:  2.124584674835205  Time:  0.028918743133544922\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.031226625714613043  Time:  2.3566980361938477\n",
      "Total Valid Loss:  2.1152966817220054  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.03146833027510539  Time:  2.3916049003601074\n",
      "Total Valid Loss:  2.1404693126678467  Time:  0.03394603729248047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.031168530022968415  Time:  2.4813289642333984\n",
      "Total Valid Loss:  2.159597396850586  Time:  0.035906314849853516\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.03065710827384306  Time:  2.581094980239868\n",
      "Total Valid Loss:  2.150038242340088  Time:  0.04388284683227539\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.030477258028543515  Time:  2.2001166343688965\n",
      "Total Valid Loss:  2.1658247311909995  Time:  0.045877695083618164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.030665430280825367  Time:  2.280902862548828\n",
      "Total Valid Loss:  2.048184633255005  Time:  0.029921531677246094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.030584051654390668  Time:  2.674851655960083\n",
      "Total Valid Loss:  2.1346017519632974  Time:  0.05085945129394531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.03036522968955662  Time:  3.3590171337127686\n",
      "Total Valid Loss:  2.0493189493815103  Time:  0.05186128616333008\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.030503082550738168  Time:  2.671860933303833\n",
      "Total Valid Loss:  2.129722833633423  Time:  0.04587268829345703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.03027041965852613  Time:  2.8763020038604736\n",
      "Total Valid Loss:  2.1098074913024902  Time:  0.030916929244995117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.030559489762653474  Time:  2.728703022003174\n",
      "Total Valid Loss:  2.1469934781392417  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.029869166356713876  Time:  2.581099510192871\n",
      "Total Valid Loss:  2.1201812426249185  Time:  0.05884218215942383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.030031165237659994  Time:  3.185480833053589\n",
      "Total Valid Loss:  2.1296616395314536  Time:  0.039894819259643555\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.029874831664821376  Time:  2.7715888023376465\n",
      "Total Valid Loss:  2.0543351968129477  Time:  0.032911062240600586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.029583140592212263  Time:  3.4308300018310547\n",
      "Total Valid Loss:  2.067900021870931  Time:  0.028926372528076172\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.02959730599237525  Time:  2.5307462215423584\n",
      "Total Valid Loss:  2.143561919530233  Time:  0.03191328048706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.029480893067691638  Time:  2.6118369102478027\n",
      "Total Valid Loss:  2.067921002705892  Time:  0.032872915267944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.029664716189322263  Time:  2.7758915424346924\n",
      "Total Valid Loss:  2.051396052042643  Time:  0.04687356948852539\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.029467325949150584  Time:  2.6723599433898926\n",
      "Total Valid Loss:  2.13654096921285  Time:  0.04986739158630371\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.02921181329242561  Time:  2.807718515396118\n",
      "Total Valid Loss:  2.0383549531300864  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.029196802024608073  Time:  3.611767053604126\n",
      "Total Valid Loss:  2.0453950564066568  Time:  0.033997297286987305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.02959224314469358  Time:  2.7302205562591553\n",
      "Total Valid Loss:  2.0692756175994873  Time:  0.04294443130493164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.02908643840447716  Time:  2.757702350616455\n",
      "Total Valid Loss:  2.1137311458587646  Time:  0.03790140151977539\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.028848387884057088  Time:  2.7208361625671387\n",
      "Total Valid Loss:  2.0950490633646646  Time:  0.0329127311706543\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.02877890598838744  Time:  2.8986928462982178\n",
      "Total Valid Loss:  2.139751116434733  Time:  0.04588723182678223\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.028756559915516688  Time:  2.585171937942505\n",
      "Total Valid Loss:  2.1240965525309243  Time:  0.052045583724975586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.028687169888745184  Time:  2.744337797164917\n",
      "Total Valid Loss:  2.1680544217427573  Time:  0.03790640830993652\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.028645104769131412  Time:  2.948073148727417\n",
      "Total Valid Loss:  2.113478342692057  Time:  0.04818224906921387\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.02868996523320675  Time:  2.740358352661133\n",
      "Total Valid Loss:  2.0512972672780356  Time:  0.047518253326416016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.028555091762024424  Time:  2.631937265396118\n",
      "Total Valid Loss:  2.071322758992513  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.028400522033157558  Time:  2.7404208183288574\n",
      "Total Valid Loss:  2.075701872507731  Time:  0.030916213989257812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.02824915793278943  Time:  2.580341339111328\n",
      "Total Valid Loss:  2.0739850997924805  Time:  0.0299224853515625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.028412732012245968  Time:  2.7518374919891357\n",
      "Total Valid Loss:  2.07878049214681  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.028022879248727924  Time:  2.779928684234619\n",
      "Total Valid Loss:  2.097174962361654  Time:  0.030994653701782227\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.028313341024129288  Time:  2.761767864227295\n",
      "Total Valid Loss:  2.138090213139852  Time:  0.032912492752075195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.028125119436046352  Time:  2.751250982284546\n",
      "Total Valid Loss:  2.110959847768148  Time:  0.029921531677246094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.028152602020165195  Time:  2.7001285552978516\n",
      "Total Valid Loss:  2.075178384780884  Time:  0.03804445266723633\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.02835838376827862  Time:  2.9859368801116943\n",
      "Total Valid Loss:  2.06742795308431  Time:  0.0489501953125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.028257374546450116  Time:  2.870227336883545\n",
      "Total Valid Loss:  2.1421453952789307  Time:  0.027933597564697266\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.028098828685672386  Time:  3.1320059299468994\n",
      "Total Valid Loss:  2.137436787287394  Time:  0.05031895637512207\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.027822100209153218  Time:  2.704312324523926\n",
      "Total Valid Loss:  2.0879416465759277  Time:  0.030918121337890625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.027759526362237722  Time:  3.0207509994506836\n",
      "Total Valid Loss:  2.1044180393218994  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.027681479700233626  Time:  2.757624864578247\n",
      "Total Valid Loss:  2.1014827887217202  Time:  0.030918359756469727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.027617396819202795  Time:  2.52923583984375\n",
      "Total Valid Loss:  2.069676081339518  Time:  0.0468752384185791\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.027863166546044142  Time:  2.2449960708618164\n",
      "Total Valid Loss:  2.087923844655355  Time:  0.03590559959411621\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.027885823632064072  Time:  3.095721483230591\n",
      "Total Valid Loss:  2.0972912311553955  Time:  0.05385589599609375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.027508876748059106  Time:  2.771620750427246\n",
      "Total Valid Loss:  2.108367919921875  Time:  0.028934717178344727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.02757585077829983  Time:  3.0408239364624023\n",
      "Total Valid Loss:  2.1526814301808677  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.02742289217269939  Time:  3.326108455657959\n",
      "Total Valid Loss:  2.079158624013265  Time:  0.044878482818603516\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.02774778759997824  Time:  2.9201927185058594\n",
      "Total Valid Loss:  2.1019914944966636  Time:  0.05485391616821289\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.027323716846497162  Time:  2.9132089614868164\n",
      "Total Valid Loss:  2.1094199816385903  Time:  0.03790092468261719\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.027598580750434296  Time:  3.1066908836364746\n",
      "Total Valid Loss:  2.1186023553212485  Time:  0.02991938591003418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.027531829767900966  Time:  2.8722121715545654\n",
      "Total Valid Loss:  2.088866949081421  Time:  0.06389999389648438\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  82.87852358818054\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.662360376932 =======\n",
      "======= Set val : score(recall_10)=0.723396366333 =======\n",
      "======= Set val : score(recall_20)=0.760845383760 =======\n",
      "======= Set val : score(map_cut_10)=0.643423615893 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.2\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.15277789235115052  Time:  2.2735722064971924\n",
      "Total Valid Loss:  2.7920732498168945  Time:  0.025415897369384766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.10510789926933206  Time:  2.629868268966675\n",
      "Total Valid Loss:  2.6981047789255777  Time:  0.032912492752075195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.10118172771256903  Time:  2.3806848526000977\n",
      "Total Valid Loss:  2.677555243174235  Time:  0.02994680404663086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.10023604313964429  Time:  2.6595330238342285\n",
      "Total Valid Loss:  2.572885831197103  Time:  0.033878326416015625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.09956809683986333  Time:  2.787207841873169\n",
      "Total Valid Loss:  2.669088045756022  Time:  0.07480049133300781\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.09893846667331198  Time:  2.555997133255005\n",
      "Total Valid Loss:  2.4736066659291587  Time:  0.030951976776123047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.09554604330788488  Time:  2.5801076889038086\n",
      "Total Valid Loss:  2.5812756220499673  Time:  0.03091883659362793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.0906187258336855  Time:  2.5385489463806152\n",
      "Total Valid Loss:  2.5020036697387695  Time:  0.04811453819274902\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.084892932811509  Time:  2.5571935176849365\n",
      "Total Valid Loss:  2.472106615702311  Time:  0.03889608383178711\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.07927694864895032  Time:  2.5856189727783203\n",
      "Total Valid Loss:  2.523409446080526  Time:  0.029922962188720703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.07315121124620023  Time:  2.739345073699951\n",
      "Total Valid Loss:  2.406789938608805  Time:  0.03601694107055664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.06831416866701583  Time:  2.62125825881958\n",
      "Total Valid Loss:  2.443596283594767  Time:  0.05485415458679199\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.06383889732153519  Time:  3.30055570602417\n",
      "Total Valid Loss:  2.2463141282399497  Time:  0.045876502990722656\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.05958947510175083  Time:  3.0129003524780273\n",
      "Total Valid Loss:  2.3834630648295083  Time:  0.029035091400146484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.05566914272697075  Time:  3.626774311065674\n",
      "Total Valid Loss:  2.308672825495402  Time:  0.043881893157958984\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.05306357686286387  Time:  2.831840753555298\n",
      "Total Valid Loss:  2.198509693145752  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.050427270518696825  Time:  2.43847918510437\n",
      "Total Valid Loss:  2.3503268559773765  Time:  0.027926921844482422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.04820034322531327  Time:  2.318796157836914\n",
      "Total Valid Loss:  2.2300384044647217  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.04604707574066908  Time:  3.409883737564087\n",
      "Total Valid Loss:  2.1813011964162192  Time:  0.029918432235717773\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.04475875681509142  Time:  2.567135810852051\n",
      "Total Valid Loss:  2.15259051322937  Time:  0.05285811424255371\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.043292747340772465  Time:  2.892265558242798\n",
      "Total Valid Loss:  2.1633631388346353  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.042148046098325564  Time:  2.6738555431365967\n",
      "Total Valid Loss:  2.1955864429473877  Time:  0.02992105484008789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.04114223164708718  Time:  2.732691526412964\n",
      "Total Valid Loss:  2.128712256749471  Time:  0.08078217506408691\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.04026361020362895  Time:  2.421527147293091\n",
      "Total Valid Loss:  2.1808804670969644  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.03940122328374697  Time:  2.5252461433410645\n",
      "Total Valid Loss:  2.1664164066314697  Time:  0.07280492782592773\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.03851161242827125  Time:  2.801509141921997\n",
      "Total Valid Loss:  2.1829586029052734  Time:  0.06781792640686035\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.03780761205631754  Time:  2.5661375522613525\n",
      "Total Valid Loss:  2.0948425928751626  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.03787161908719851  Time:  3.5608694553375244\n",
      "Total Valid Loss:  2.1506542364756265  Time:  0.03390383720397949\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.03721931826161302  Time:  3.1366140842437744\n",
      "Total Valid Loss:  2.1526400248209634  Time:  0.06382942199707031\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.03661013085233129  Time:  2.566138744354248\n",
      "Total Valid Loss:  2.1026976108551025  Time:  0.03889584541320801\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.036563777858796324  Time:  2.727722644805908\n",
      "Total Valid Loss:  2.1859912872314453  Time:  0.07579493522644043\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.035893240959747975  Time:  2.935175895690918\n",
      "Total Valid Loss:  2.1631219387054443  Time:  0.07479381561279297\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.035760538506767026  Time:  3.000976085662842\n",
      "Total Valid Loss:  2.0891335010528564  Time:  0.03590273857116699\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.035106432842819585  Time:  3.0311951637268066\n",
      "Total Valid Loss:  2.1047226587931314  Time:  0.05126523971557617\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.03511112512129804  Time:  2.800793409347534\n",
      "Total Valid Loss:  2.200594504674276  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.0351258318061414  Time:  2.9079418182373047\n",
      "Total Valid Loss:  2.132457733154297  Time:  0.033942461013793945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.03438088890650998  Time:  2.685093402862549\n",
      "Total Valid Loss:  2.1088353792826333  Time:  0.03490591049194336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.034563782892149425  Time:  3.181540012359619\n",
      "Total Valid Loss:  2.125978708267212  Time:  0.04388284683227539\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.03403905958909056  Time:  2.7455244064331055\n",
      "Total Valid Loss:  2.1473401387532554  Time:  0.04201364517211914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.033980901442144225  Time:  2.614274024963379\n",
      "Total Valid Loss:  2.067537705103556  Time:  0.030918598175048828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.03407902244640433  Time:  2.7276837825775146\n",
      "Total Valid Loss:  2.104562759399414  Time:  0.03490805625915527\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.03381238710945067  Time:  3.7475433349609375\n",
      "Total Valid Loss:  2.1654202143351235  Time:  0.03490710258483887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.033388805875311726  Time:  2.7156686782836914\n",
      "Total Valid Loss:  2.102808713912964  Time:  0.03490734100341797\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.033122747504840726  Time:  2.6535141468048096\n",
      "Total Valid Loss:  2.069222847620646  Time:  0.0397343635559082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.032850821348636046  Time:  2.69811749458313\n",
      "Total Valid Loss:  2.183375120162964  Time:  0.033910512924194336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.03302017929761306  Time:  2.797844409942627\n",
      "Total Valid Loss:  2.1532885233561196  Time:  0.03891181945800781\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.03273690527547961  Time:  2.926820755004883\n",
      "Total Valid Loss:  2.094113032023112  Time:  0.02893519401550293\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.03248860716171886  Time:  2.7684202194213867\n",
      "Total Valid Loss:  2.140109062194824  Time:  0.036224365234375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.03256139274200667  Time:  2.7179224491119385\n",
      "Total Valid Loss:  2.0626107851664224  Time:  0.04189038276672363\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.03251971936096316  Time:  3.020224094390869\n",
      "Total Valid Loss:  2.1146320501963296  Time:  0.0359044075012207\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.03207886314586453  Time:  2.651546001434326\n",
      "Total Valid Loss:  2.149897495905558  Time:  0.03574228286743164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.031910201923354815  Time:  2.793457269668579\n",
      "Total Valid Loss:  2.139454205830892  Time:  0.04242300987243652\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.03192182983393255  Time:  2.728949546813965\n",
      "Total Valid Loss:  2.0687222480773926  Time:  0.031914472579956055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.031868815405861194  Time:  2.6891353130340576\n",
      "Total Valid Loss:  2.1273910999298096  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.031715522431161096  Time:  2.7088210582733154\n",
      "Total Valid Loss:  2.033709406852722  Time:  0.04295611381530762\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.031724667079422786  Time:  2.6864137649536133\n",
      "Total Valid Loss:  2.1243306001027427  Time:  0.03716540336608887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.031406710879958194  Time:  2.6733720302581787\n",
      "Total Valid Loss:  2.1084906260172525  Time:  0.030920743942260742\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.031702535550879395  Time:  2.758335590362549\n",
      "Total Valid Loss:  2.0225141843159995  Time:  0.04787158966064453\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.031258105859160425  Time:  2.7149505615234375\n",
      "Total Valid Loss:  2.135108550389608  Time:  0.0330355167388916\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.031353727809113004  Time:  2.758213520050049\n",
      "Total Valid Loss:  2.101792812347412  Time:  0.03294515609741211\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.031159052349950957  Time:  2.7648370265960693\n",
      "Total Valid Loss:  2.066108306248983  Time:  0.029986858367919922\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.030988915604741676  Time:  3.5180389881134033\n",
      "Total Valid Loss:  2.052997907002767  Time:  0.053777456283569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.030902747162010358  Time:  3.4753310680389404\n",
      "Total Valid Loss:  2.1151297887166343  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.03078968737112439  Time:  3.0326106548309326\n",
      "Total Valid Loss:  2.0917040506998696  Time:  0.0299222469329834\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.030854665439413943  Time:  3.6732418537139893\n",
      "Total Valid Loss:  2.0319712162017822  Time:  0.05684638023376465\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.030590858197082644  Time:  4.0792131423950195\n",
      "Total Valid Loss:  2.115020434061686  Time:  0.058841705322265625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.03075325949036557  Time:  2.784555196762085\n",
      "Total Valid Loss:  2.0355908473332724  Time:  0.05584096908569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.030700337190342986  Time:  2.6937968730926514\n",
      "Total Valid Loss:  2.1088605721791587  Time:  0.030916929244995117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.03075093364586001  Time:  2.735912561416626\n",
      "Total Valid Loss:  2.038590908050537  Time:  0.029106855392456055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.030723109808952914  Time:  2.870927333831787\n",
      "Total Valid Loss:  2.124333302179972  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.030291482984371808  Time:  2.866366147994995\n",
      "Total Valid Loss:  2.1120095252990723  Time:  0.03209328651428223\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.030210452494413956  Time:  2.627824544906616\n",
      "Total Valid Loss:  2.1507782141367593  Time:  0.0349884033203125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.030220419314244518  Time:  2.7860159873962402\n",
      "Total Valid Loss:  2.126139005025228  Time:  0.03092050552368164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.029957223635004915  Time:  3.0548720359802246\n",
      "Total Valid Loss:  2.1323649088541665  Time:  0.04887223243713379\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.029910017647173093  Time:  2.676344633102417\n",
      "Total Valid Loss:  2.1077307065327964  Time:  0.03196549415588379\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.03018191547497459  Time:  2.7258920669555664\n",
      "Total Valid Loss:  2.0677072207132974  Time:  0.03107929229736328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.03019242354709169  Time:  3.5494587421417236\n",
      "Total Valid Loss:  2.0984275341033936  Time:  0.03391766548156738\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.03000817313466383  Time:  2.5585672855377197\n",
      "Total Valid Loss:  2.1321999231974282  Time:  0.03365683555603027\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.02969442191331283  Time:  2.651383399963379\n",
      "Total Valid Loss:  2.0560782750447593  Time:  0.03193044662475586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.02987796899093234  Time:  2.670114517211914\n",
      "Total Valid Loss:  2.052071491877238  Time:  0.03502225875854492\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.029538103355013806  Time:  2.711580991744995\n",
      "Total Valid Loss:  2.125462770462036  Time:  0.03789877891540527\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.029758301134342732  Time:  2.7188618183135986\n",
      "Total Valid Loss:  2.0976012547810874  Time:  0.032910823822021484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.029405825844277506  Time:  2.589137077331543\n",
      "Total Valid Loss:  2.119314750035604  Time:  0.04288673400878906\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.029546969027622886  Time:  3.0627777576446533\n",
      "Total Valid Loss:  2.0769893328348794  Time:  0.030977249145507812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.029834226162537284  Time:  2.8120086193084717\n",
      "Total Valid Loss:  2.069183429082235  Time:  0.02894115447998047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.029683457007226736  Time:  2.586411476135254\n",
      "Total Valid Loss:  2.125987927118937  Time:  0.03490567207336426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.029438421616087788  Time:  2.772700071334839\n",
      "Total Valid Loss:  2.0453690687815347  Time:  0.04401350021362305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.029534182486974675  Time:  2.839148759841919\n",
      "Total Valid Loss:  2.0876712004343667  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.029288667084082315  Time:  2.826090097427368\n",
      "Total Valid Loss:  2.0825831095377603  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.02924681182788766  Time:  2.739884614944458\n",
      "Total Valid Loss:  2.1022562980651855  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.029520082619527113  Time:  3.2095539569854736\n",
      "Total Valid Loss:  2.1394287745157876  Time:  0.04760909080505371\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.02952622921894426  Time:  2.920336961746216\n",
      "Total Valid Loss:  2.0528177420298257  Time:  0.03468823432922363\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.029558742953383406  Time:  2.7390029430389404\n",
      "Total Valid Loss:  2.1301982402801514  Time:  0.030935287475585938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.029326431712378625  Time:  2.789487600326538\n",
      "Total Valid Loss:  2.111100912094116  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.029361450186242227  Time:  3.1902050971984863\n",
      "Total Valid Loss:  2.128049612045288  Time:  0.04198718070983887\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.02891150384169558  Time:  2.82161808013916\n",
      "Total Valid Loss:  2.057277043660482  Time:  0.032913923263549805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.02939803483693496  Time:  2.6202213764190674\n",
      "Total Valid Loss:  2.1305998961130777  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.02889642078915368  Time:  2.838784694671631\n",
      "Total Valid Loss:  2.0699496269226074  Time:  0.03790855407714844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.02915051323564156  Time:  2.6856026649475098\n",
      "Total Valid Loss:  2.0345985094706216  Time:  0.040891408920288086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.029146415205753368  Time:  2.6216843128204346\n",
      "Total Valid Loss:  2.1177032788594565  Time:  0.030927181243896484\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  85.10563540458679\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.654146501604 =======\n",
      "======= Set val : score(recall_10)=0.712643678161 =======\n",
      "======= Set val : score(recall_20)=0.753058954394 =======\n",
      "======= Set val : score(map_cut_10)=0.635946613227 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.3\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.1564215965245081  Time:  2.938546657562256\n",
      "Total Valid Loss:  2.945112705230713  Time:  0.03541064262390137\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.1097077947595845  Time:  2.5012640953063965\n",
      "Total Valid Loss:  2.745540142059326  Time:  0.026932954788208008\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.10353057520545048  Time:  2.8285787105560303\n",
      "Total Valid Loss:  2.7641857465108237  Time:  0.03509354591369629\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.10225992254588916  Time:  2.667121410369873\n",
      "Total Valid Loss:  2.64114777247111  Time:  0.0799560546875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.10142230164745579  Time:  2.5277771949768066\n",
      "Total Valid Loss:  2.7556753953297934  Time:  0.03490924835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.10097932057536167  Time:  2.790266275405884\n",
      "Total Valid Loss:  2.545328458150228  Time:  0.05380535125732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.09801671602155851  Time:  2.574230909347534\n",
      "Total Valid Loss:  2.682959794998169  Time:  0.04886913299560547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.09298403535200202  Time:  2.624924421310425\n",
      "Total Valid Loss:  2.510122458140055  Time:  0.03305673599243164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.08692275298678356  Time:  2.65285062789917\n",
      "Total Valid Loss:  2.472571770350138  Time:  0.04233145713806152\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.08102885497652966  Time:  2.751655101776123\n",
      "Total Valid Loss:  2.5164778232574463  Time:  0.03981804847717285\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.07494564736666887  Time:  2.6204047203063965\n",
      "Total Valid Loss:  2.4522106647491455  Time:  0.036052703857421875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.07023180315028066  Time:  2.6648077964782715\n",
      "Total Valid Loss:  2.449753443400065  Time:  0.03814339637756348\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.06574938404171363  Time:  2.6954562664031982\n",
      "Total Valid Loss:  2.298084338506063  Time:  0.04385113716125488\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.06146201322907987  Time:  2.5745227336883545\n",
      "Total Valid Loss:  2.4181740283966064  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.057414730508690295  Time:  2.6707684993743896\n",
      "Total Valid Loss:  2.27201255162557  Time:  0.031928062438964844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.05466192730742952  Time:  2.537388324737549\n",
      "Total Valid Loss:  2.189871390660604  Time:  0.03091716766357422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.052203438819750494  Time:  2.8159961700439453\n",
      "Total Valid Loss:  2.3278464476267495  Time:  0.031920433044433594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.049779356918905095  Time:  2.7335355281829834\n",
      "Total Valid Loss:  2.2711852391560874  Time:  0.03282785415649414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.0472761618702308  Time:  2.8052053451538086\n",
      "Total Valid Loss:  2.1916330655415854  Time:  0.03142738342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.045960015090911285  Time:  2.57270884513855\n",
      "Total Valid Loss:  2.158703088760376  Time:  0.04089045524597168\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.0444350872674714  Time:  3.3116745948791504\n",
      "Total Valid Loss:  2.181544065475464  Time:  0.02992558479309082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.0433070161420366  Time:  3.062227725982666\n",
      "Total Valid Loss:  2.208141009012858  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.04228827752496885  Time:  2.4234180450439453\n",
      "Total Valid Loss:  2.1515302658081055  Time:  0.03992629051208496\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.04124915036170379  Time:  2.483502149581909\n",
      "Total Valid Loss:  2.153519630432129  Time:  0.04188895225524902\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.04046419836256815  Time:  2.938436508178711\n",
      "Total Valid Loss:  2.194695313771566  Time:  0.03387856483459473\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.0394902877509594  Time:  3.1076886653900146\n",
      "Total Valid Loss:  2.1756680806477866  Time:  0.04886984825134277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.03860026756706445  Time:  3.592395782470703\n",
      "Total Valid Loss:  2.094468434651693  Time:  0.030916452407836914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.03858874346251073  Time:  3.7110755443573\n",
      "Total Valid Loss:  2.1999189853668213  Time:  0.03989410400390625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.03806387775618097  Time:  3.4051058292388916\n",
      "Total Valid Loss:  2.1578195889790854  Time:  0.05384206771850586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.037626854233119796  Time:  2.7614634037017822\n",
      "Total Valid Loss:  2.103325684865316  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.03723043838272924  Time:  2.7836382389068604\n",
      "Total Valid Loss:  2.195211172103882  Time:  0.0359039306640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.03655400881948678  Time:  2.5191702842712402\n",
      "Total Valid Loss:  2.192794402440389  Time:  0.04389071464538574\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.036564866453409194  Time:  2.709897756576538\n",
      "Total Valid Loss:  2.1135900020599365  Time:  0.04254770278930664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.035806245146238286  Time:  2.84063720703125\n",
      "Total Valid Loss:  2.129647890726725  Time:  0.03020334243774414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.0356862832184719  Time:  2.70528244972229\n",
      "Total Valid Loss:  2.198407252629598  Time:  0.034265995025634766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.03569872129870497  Time:  3.8056931495666504\n",
      "Total Valid Loss:  2.1452061335245767  Time:  0.038895606994628906\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.03523984727976115  Time:  2.628812074661255\n",
      "Total Valid Loss:  2.112732489903768  Time:  0.04156041145324707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.03529337161908979  Time:  2.584325075149536\n",
      "Total Valid Loss:  2.094177563985189  Time:  0.030919790267944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.034823240193983786  Time:  2.719372272491455\n",
      "Total Valid Loss:  2.1251397927602134  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.03461615827096545  Time:  2.715266704559326\n",
      "Total Valid Loss:  2.0991718769073486  Time:  0.03789496421813965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.0345560315510501  Time:  2.738569974899292\n",
      "Total Valid Loss:  2.099027713139852  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.03425055034458637  Time:  2.771289110183716\n",
      "Total Valid Loss:  2.110740582148234  Time:  0.036901235580444336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.03418374479464863  Time:  2.885143518447876\n",
      "Total Valid Loss:  2.0964272816975913  Time:  0.0359344482421875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.03387459851801396  Time:  2.7779626846313477\n",
      "Total Valid Loss:  2.08777650197347  Time:  0.033910274505615234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.03346047752901264  Time:  2.7965102195739746\n",
      "Total Valid Loss:  2.182216008504232  Time:  0.03490614891052246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.03361329201446927  Time:  2.646970510482788\n",
      "Total Valid Loss:  2.0996442635854087  Time:  0.03136277198791504\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.033479278356484746  Time:  2.8148069381713867\n",
      "Total Valid Loss:  2.1328767935434976  Time:  0.034906625747680664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.03331199416323848  Time:  2.9266979694366455\n",
      "Total Valid Loss:  2.052459955215454  Time:  0.03594851493835449\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.033388374000787736  Time:  2.715083360671997\n",
      "Total Valid Loss:  2.071050008138021  Time:  0.0299227237701416\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.03301520780052828  Time:  2.5131256580352783\n",
      "Total Valid Loss:  2.148162285486857  Time:  0.02892160415649414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.032652384058936786  Time:  3.0709869861602783\n",
      "Total Valid Loss:  2.1227169831593833  Time:  0.03220701217651367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.03255175515685393  Time:  2.648778200149536\n",
      "Total Valid Loss:  2.1352996031443277  Time:  0.04415702819824219\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.03275244844996411  Time:  2.6342620849609375\n",
      "Total Valid Loss:  2.101369778315226  Time:  0.02991938591003418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.03247189092571321  Time:  2.730121374130249\n",
      "Total Valid Loss:  2.1678787072499595  Time:  0.0379033088684082\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.03216885636034219  Time:  2.895951747894287\n",
      "Total Valid Loss:  2.0425206820170083  Time:  0.04089093208312988\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.03224506187050239  Time:  2.5923452377319336\n",
      "Total Valid Loss:  2.11102302869161  Time:  0.03489971160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.03226517952330735  Time:  2.6447176933288574\n",
      "Total Valid Loss:  2.087225914001465  Time:  0.027926921844482422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.03247708385081395  Time:  2.863255262374878\n",
      "Total Valid Loss:  2.088601032892863  Time:  0.0359044075012207\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.03206407567081244  Time:  3.545518636703491\n",
      "Total Valid Loss:  2.1596455574035645  Time:  0.03989410400390625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.031894585781771206  Time:  2.4524028301239014\n",
      "Total Valid Loss:  2.0787084897359214  Time:  0.03390765190124512\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.03189517441003219  Time:  2.5309395790100098\n",
      "Total Valid Loss:  2.0979912281036377  Time:  0.03507280349731445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.03195314587134382  Time:  2.404207468032837\n",
      "Total Valid Loss:  2.0574989318847656  Time:  0.03191566467285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.03181182423039623  Time:  2.314810276031494\n",
      "Total Valid Loss:  2.1372934182484946  Time:  0.03091740608215332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.031586516130229704  Time:  2.3566975593566895\n",
      "Total Valid Loss:  2.0975612799326577  Time:  0.03191518783569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.031678822426044424  Time:  2.2529754638671875\n",
      "Total Valid Loss:  2.035675843556722  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.031480663123985994  Time:  2.4703941345214844\n",
      "Total Valid Loss:  2.143308242162069  Time:  0.03789973258972168\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.031271958529301314  Time:  2.750643730163574\n",
      "Total Valid Loss:  2.0889670848846436  Time:  0.034906864166259766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.031435927586710974  Time:  2.302842140197754\n",
      "Total Valid Loss:  2.1132473150889077  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.031463362632886224  Time:  2.701775312423706\n",
      "Total Valid Loss:  2.1129396756490073  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.031278729390190996  Time:  2.8823165893554688\n",
      "Total Valid Loss:  2.0914127826690674  Time:  0.03690218925476074\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.031048945078383322  Time:  3.2572877407073975\n",
      "Total Valid Loss:  2.1132185459136963  Time:  0.030918359756469727\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.03091134529398835  Time:  2.4594244956970215\n",
      "Total Valid Loss:  2.143198013305664  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.030964404004423515  Time:  2.566171646118164\n",
      "Total Valid Loss:  2.0786345799764  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.030830056528034416  Time:  2.7665655612945557\n",
      "Total Valid Loss:  2.0655651092529297  Time:  0.055887460708618164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.030864698277867357  Time:  2.5501434803009033\n",
      "Total Valid Loss:  2.0817415714263916  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.030911310940333035  Time:  2.2938663959503174\n",
      "Total Valid Loss:  2.0933265686035156  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.030961672783545825  Time:  2.5651419162750244\n",
      "Total Valid Loss:  2.116511662801107  Time:  0.041925907135009766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.030678315557863402  Time:  2.730659246444702\n",
      "Total Valid Loss:  2.089509963989258  Time:  0.04388260841369629\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.03074903369921705  Time:  2.943131923675537\n",
      "Total Valid Loss:  2.100231647491455  Time:  0.04787898063659668\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.030849462472226308  Time:  2.5013160705566406\n",
      "Total Valid Loss:  2.0297849973042807  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.030436177729912427  Time:  2.5671353340148926\n",
      "Total Valid Loss:  2.1100426514943442  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.030690589935883233  Time:  2.2749154567718506\n",
      "Total Valid Loss:  2.1247411568959556  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.030478656988428988  Time:  2.4295051097869873\n",
      "Total Valid Loss:  2.1141769091288247  Time:  0.03490638732910156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.03041397132303404  Time:  2.7915356159210205\n",
      "Total Valid Loss:  2.073850949605306  Time:  0.04887056350708008\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.030581760827613914  Time:  3.360013723373413\n",
      "Total Valid Loss:  2.0461445252100625  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.030328528242914574  Time:  3.9241886138916016\n",
      "Total Valid Loss:  2.108001152674357  Time:  0.04047989845275879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.030446993980718696  Time:  3.7924091815948486\n",
      "Total Valid Loss:  2.0953284899393716  Time:  0.04088997840881348\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.030331005674341452  Time:  2.894232749938965\n",
      "Total Valid Loss:  2.0617735385894775  Time:  0.04488635063171387\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.03030438141330429  Time:  2.660989999771118\n",
      "Total Valid Loss:  2.086916923522949  Time:  0.03094792366027832\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.029971091271094655  Time:  2.8965675830841064\n",
      "Total Valid Loss:  2.1178651650746665  Time:  0.02992105484008789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.030384076111342594  Time:  2.7210423946380615\n",
      "Total Valid Loss:  2.0650481383005777  Time:  0.04488086700439453\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.030141383539075438  Time:  2.6886956691741943\n",
      "Total Valid Loss:  2.052069822947184  Time:  0.042852163314819336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.029911171094230984  Time:  2.656736135482788\n",
      "Total Valid Loss:  2.0710090001424155  Time:  0.042848825454711914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.029944288422879967  Time:  2.677823781967163\n",
      "Total Valid Loss:  2.067586342493693  Time:  0.05983901023864746\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.0302007165292035  Time:  2.629969596862793\n",
      "Total Valid Loss:  2.1056645711263022  Time:  0.05588483810424805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.029655883574615353  Time:  2.861823081970215\n",
      "Total Valid Loss:  2.0773751735687256  Time:  0.03293323516845703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.030056742222412773  Time:  2.7139382362365723\n",
      "Total Valid Loss:  2.1334308783213296  Time:  0.043994903564453125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.029809858115470926  Time:  2.6939895153045654\n",
      "Total Valid Loss:  2.0799150466918945  Time:  0.034987688064575195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.02997037360201711  Time:  2.7879798412323\n",
      "Total Valid Loss:  2.0341259638468423  Time:  0.03989410400390625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.02993634505116421  Time:  3.6280174255371094\n",
      "Total Valid Loss:  2.070964813232422  Time:  0.032912492752075195\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  90.16077280044556\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.654287293535 =======\n",
      "======= Set val : score(recall_10)=0.716722284019 =======\n",
      "======= Set val : score(recall_20)=0.758249907304 =======\n",
      "======= Set val : score(map_cut_10)=0.634878554067 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.4\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.15917987933625347  Time:  2.6813180446624756\n",
      "Total Valid Loss:  3.0573222637176514  Time:  0.02596139907836914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.11991536312777062  Time:  2.361766815185547\n",
      "Total Valid Loss:  2.7888071537017822  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.10733563537183015  Time:  2.8290557861328125\n",
      "Total Valid Loss:  2.7754650115966797  Time:  0.03989815711975098\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.10503232731767323  Time:  2.5004782676696777\n",
      "Total Valid Loss:  2.7051708698272705  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.10402536081231159  Time:  3.729797840118408\n",
      "Total Valid Loss:  2.7219455242156982  Time:  0.03989434242248535\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.10326275870851849  Time:  2.6628329753875732\n",
      "Total Valid Loss:  2.6227401892344155  Time:  0.036913156509399414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.10028832457635714  Time:  2.3673760890960693\n",
      "Total Valid Loss:  2.605647007624308  Time:  0.030013561248779297\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.09533406068449435  Time:  2.3839364051818848\n",
      "Total Valid Loss:  2.5678772926330566  Time:  0.027011871337890625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.08907085320223933  Time:  2.36098051071167\n",
      "Total Valid Loss:  2.4681591192881265  Time:  0.029013633728027344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.08274379106967346  Time:  2.622016429901123\n",
      "Total Valid Loss:  2.5878305435180664  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.07644716851089312  Time:  2.3347561359405518\n",
      "Total Valid Loss:  2.444150368372599  Time:  0.03690147399902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.07160659607337869  Time:  2.3178038597106934\n",
      "Total Valid Loss:  2.4350674152374268  Time:  0.06682229042053223\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.0667044700163862  Time:  2.188145875930786\n",
      "Total Valid Loss:  2.2716573079427085  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.0624908119764017  Time:  2.2270443439483643\n",
      "Total Valid Loss:  2.366052230199178  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.058088147283896156  Time:  2.117337465286255\n",
      "Total Valid Loss:  2.289442777633667  Time:  0.06283307075500488\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.05508923090022543  Time:  2.253974199295044\n",
      "Total Valid Loss:  2.2470711867014566  Time:  0.032910823822021484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.05246589582251466  Time:  2.3935999870300293\n",
      "Total Valid Loss:  2.335688591003418  Time:  0.043883323669433594\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.04970036255924598  Time:  2.2828946113586426\n",
      "Total Valid Loss:  2.278380870819092  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.047525003066529396  Time:  2.28688645362854\n",
      "Total Valid Loss:  2.190847158432007  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.046002700179815295  Time:  2.812476873397827\n",
      "Total Valid Loss:  2.213843743006388  Time:  0.02892160415649414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.04455101551569027  Time:  2.3726558685302734\n",
      "Total Valid Loss:  2.139827251434326  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.04340168389937152  Time:  2.4374818801879883\n",
      "Total Valid Loss:  2.214224894841512  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.0422840297870014  Time:  2.4963252544403076\n",
      "Total Valid Loss:  2.141417662302653  Time:  0.030916929244995117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.04158689632363941  Time:  2.485354423522949\n",
      "Total Valid Loss:  2.142693122227987  Time:  0.04587912559509277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.04047099300052809  Time:  2.468397378921509\n",
      "Total Valid Loss:  2.184634526570638  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.03967496325140414  Time:  2.3307666778564453\n",
      "Total Valid Loss:  2.1674091815948486  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.039033934279628424  Time:  2.440474510192871\n",
      "Total Valid Loss:  2.1373000144958496  Time:  0.03191423416137695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.038938928265934404  Time:  2.2449958324432373\n",
      "Total Valid Loss:  2.1647985776265464  Time:  0.03989434242248535\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.038367274759904195  Time:  2.2370176315307617\n",
      "Total Valid Loss:  2.1692357858022056  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.037695789304764374  Time:  2.52325439453125\n",
      "Total Valid Loss:  2.0756508509318032  Time:  0.031912803649902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.03758716311143792  Time:  2.4454619884490967\n",
      "Total Valid Loss:  2.187807639439901  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.03691160082817078  Time:  2.726707935333252\n",
      "Total Valid Loss:  2.1935688654581704  Time:  0.048868656158447266\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.036802328572325085  Time:  2.5561652183532715\n",
      "Total Valid Loss:  2.126488447189331  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.036323754521815674  Time:  2.4205269813537598\n",
      "Total Valid Loss:  2.1208228270212808  Time:  0.028922319412231445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.036103693606412926  Time:  2.178177833557129\n",
      "Total Valid Loss:  2.180264711380005  Time:  0.03191494941711426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.0360227154324884  Time:  2.506296157836914\n",
      "Total Valid Loss:  2.149221420288086  Time:  0.036902666091918945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.03571431259422199  Time:  2.5352213382720947\n",
      "Total Valid Loss:  2.113002300262451  Time:  0.0388948917388916\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.035506251211399616  Time:  2.8264427185058594\n",
      "Total Valid Loss:  2.062209447224935  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.03502449226444182  Time:  2.715829610824585\n",
      "Total Valid Loss:  2.1582678953806558  Time:  0.02996349334716797\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.034949757142559344  Time:  2.214040517807007\n",
      "Total Valid Loss:  2.064100980758667  Time:  0.030916213989257812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.03507397952287093  Time:  2.4175353050231934\n",
      "Total Valid Loss:  2.0582446257273355  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.03470024714327377  Time:  2.518265724182129\n",
      "Total Valid Loss:  2.116238832473755  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.03473500257924847  Time:  2.4165399074554443\n",
      "Total Valid Loss:  2.086683511734009  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.03408787407628868  Time:  2.646920680999756\n",
      "Total Valid Loss:  2.1068974335988364  Time:  0.0359041690826416\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.033917535890055736  Time:  2.5970568656921387\n",
      "Total Valid Loss:  2.136359691619873  Time:  0.028921842575073242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.03392372465004092  Time:  2.216071367263794\n",
      "Total Valid Loss:  2.1115333239237466  Time:  0.041892051696777344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.033940013060751166  Time:  2.4923365116119385\n",
      "Total Valid Loss:  2.1077493031819663  Time:  0.04089069366455078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.033671512811080266  Time:  2.6339547634124756\n",
      "Total Valid Loss:  2.0416502952575684  Time:  0.03091740608215332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.03361330816279287  Time:  2.6160049438476562\n",
      "Total Valid Loss:  2.1159374713897705  Time:  0.036902427673339844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.033544181514045465  Time:  2.4574267864227295\n",
      "Total Valid Loss:  2.142875909805298  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.03313990946373214  Time:  2.361685037612915\n",
      "Total Valid Loss:  2.1023824214935303  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.03313765574408614  Time:  2.7177326679229736\n",
      "Total Valid Loss:  2.133091767628988  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.03328042020616324  Time:  2.8703243732452393\n",
      "Total Valid Loss:  2.051037549972534  Time:  0.038896799087524414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.03314581756358561  Time:  2.7705905437469482\n",
      "Total Valid Loss:  2.113191763559977  Time:  0.04886984825134277\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.03280659173817738  Time:  2.3985865116119385\n",
      "Total Valid Loss:  2.068972667058309  Time:  0.04089069366455078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.03277550896872645  Time:  2.4773757457733154\n",
      "Total Valid Loss:  2.116914431254069  Time:  0.027924537658691406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.032677435016502505  Time:  2.329770088195801\n",
      "Total Valid Loss:  2.108527898788452  Time:  0.02992105484008789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.03264029782427394  Time:  2.640937089920044\n",
      "Total Valid Loss:  2.053479274113973  Time:  0.036901235580444336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.03240316163586534  Time:  2.2340269088745117\n",
      "Total Valid Loss:  2.1002020041147866  Time:  0.026965618133544922\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.03249251962355945  Time:  2.1970832347869873\n",
      "Total Valid Loss:  2.069088617960612  Time:  0.030918121337890625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.03246088609423326  Time:  2.112352132797241\n",
      "Total Valid Loss:  2.1079788208007812  Time:  0.03091883659362793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.032268075806939085  Time:  2.166206121444702\n",
      "Total Valid Loss:  2.037832339604696  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.03229524983983973  Time:  2.2400097846984863\n",
      "Total Valid Loss:  2.0346892674764  Time:  0.035904645919799805\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.03219279815321383  Time:  2.260953664779663\n",
      "Total Valid Loss:  2.051297108332316  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.03205825297728829  Time:  2.183166027069092\n",
      "Total Valid Loss:  2.0568412939707437  Time:  0.03789687156677246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.031754857107349065  Time:  2.1791765689849854\n",
      "Total Valid Loss:  2.1570204893747964  Time:  0.04587388038635254\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.031750584296558214  Time:  2.1811680793762207\n",
      "Total Valid Loss:  2.0385478337605796  Time:  0.033910274505615234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.03167475393932798  Time:  2.1602225303649902\n",
      "Total Valid Loss:  2.101321538289388  Time:  0.032912254333496094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.031966223211392114  Time:  2.1751832962036133\n",
      "Total Valid Loss:  2.0912516911824546  Time:  0.026927709579467773\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.03176760952109876  Time:  2.092404365539551\n",
      "Total Valid Loss:  2.0998164812723794  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.03180740950224192  Time:  2.1911425590515137\n",
      "Total Valid Loss:  2.0539952913920083  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.03172084614634514  Time:  2.119330406188965\n",
      "Total Valid Loss:  2.094177007675171  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.031560500322476676  Time:  2.0934016704559326\n",
      "Total Valid Loss:  2.09341828028361  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.03152985506407593  Time:  2.1941347122192383\n",
      "Total Valid Loss:  2.0327014128367105  Time:  0.0279238224029541\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.031385746339093086  Time:  2.1881492137908936\n",
      "Total Valid Loss:  2.0858347415924072  Time:  0.026927709579467773\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.03136534221146418  Time:  2.189146041870117\n",
      "Total Valid Loss:  2.0853448708852134  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.031451702765796494  Time:  2.2061007022857666\n",
      "Total Valid Loss:  2.0867108503977456  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.03132096069014591  Time:  2.1751887798309326\n",
      "Total Valid Loss:  2.014893809954325  Time:  0.02991652488708496\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.03122372463669466  Time:  2.1891441345214844\n",
      "Total Valid Loss:  2.041438102722168  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.03143344220259915  Time:  2.2071444988250732\n",
      "Total Valid Loss:  2.0338772932688394  Time:  0.03685760498046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.031136445782106857  Time:  2.1582274436950684\n",
      "Total Valid Loss:  2.0837555726369223  Time:  0.02592921257019043\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.031355357332074126  Time:  2.0973918437957764\n",
      "Total Valid Loss:  2.039039134979248  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.030858353395824847  Time:  2.218069076538086\n",
      "Total Valid Loss:  2.074514547983805  Time:  0.02692723274230957\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.03125949936068576  Time:  2.1502509117126465\n",
      "Total Valid Loss:  2.051408131917318  Time:  0.026929855346679688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.03125194701487603  Time:  2.105367660522461\n",
      "Total Valid Loss:  2.087432066599528  Time:  0.02991938591003418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.03131918727379778  Time:  2.185157537460327\n",
      "Total Valid Loss:  2.1366326808929443  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.03089497001922649  Time:  2.3965916633605957\n",
      "Total Valid Loss:  2.058807452519735  Time:  0.03590750694274902\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.031132762360831966  Time:  2.242001533508301\n",
      "Total Valid Loss:  2.0858500798543296  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.03091856646149055  Time:  2.13828444480896\n",
      "Total Valid Loss:  2.0462352434794107  Time:  0.030919790267944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.030608192928459333  Time:  2.242002487182617\n",
      "Total Valid Loss:  2.079076608022054  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.030907906122181725  Time:  2.1552393436431885\n",
      "Total Valid Loss:  2.048999309539795  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.030962430669561676  Time:  2.2140777111053467\n",
      "Total Valid Loss:  2.065075397491455  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.031066756841281185  Time:  2.1731882095336914\n",
      "Total Valid Loss:  2.034602642059326  Time:  0.029919862747192383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.03050280966512535  Time:  2.178175449371338\n",
      "Total Valid Loss:  2.0719505151112876  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.03070230028875496  Time:  2.171193838119507\n",
      "Total Valid Loss:  2.0740180015563965  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.03048091401224551  Time:  2.326777219772339\n",
      "Total Valid Loss:  2.0785322984059653  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.030793350141333498  Time:  2.183161973953247\n",
      "Total Valid Loss:  2.088427464167277  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.030589680649016213  Time:  2.2390127182006836\n",
      "Total Valid Loss:  2.0904921690622964  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.03062014053373233  Time:  2.1881494522094727\n",
      "Total Valid Loss:  2.040275494257609  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.0307483642483535  Time:  2.0754830837249756\n",
      "Total Valid Loss:  2.0292966763178506  Time:  0.0278933048248291\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  75.6946349143982\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.654100055679 =======\n",
      "======= Set val : score(recall_10)=0.714126807564 =======\n",
      "======= Set val : score(recall_20)=0.760103819058 =======\n",
      "======= Set val : score(map_cut_10)=0.635341002054 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.5\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for _, do in enumerate([0, 0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    args.drop_rate = do\n",
    "    ndcg = build(args)\n",
    "    print('dropout rate: ', do)\n",
    "    score.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.1233061601286349  Time:  1.879913091659546\n",
      "Total Valid Loss:  2.5820756753285727  Time:  0.021941423416137695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.09809170112661693  Time:  1.818140983581543\n",
      "Total Valid Loss:  2.5161942640940347  Time:  0.022938013076782227\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.09653665928736976  Time:  1.8929376602172852\n",
      "Total Valid Loss:  2.458691438039144  Time:  0.02493453025817871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.09476935630259306  Time:  1.9497852325439453\n",
      "Total Valid Loss:  2.4049836794535318  Time:  0.05684852600097656\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.09218073208694873  Time:  1.9029102325439453\n",
      "Total Valid Loss:  2.3700083096822104  Time:  0.03989410400390625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.08920951032120249  Time:  1.918869972229004\n",
      "Total Valid Loss:  2.5318692525227866  Time:  0.02393627166748047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.08372187724579935  Time:  2.378638982772827\n",
      "Total Valid Loss:  2.3594908714294434  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.0775668440953545  Time:  2.063480854034424\n",
      "Total Valid Loss:  2.3967183430989585  Time:  0.024932861328125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.07097501758000126  Time:  1.9238550662994385\n",
      "Total Valid Loss:  2.2768802642822266  Time:  0.02293872833251953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.06551003507945849  Time:  1.7782461643218994\n",
      "Total Valid Loss:  2.2499019304911294  Time:  0.022938966751098633\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.05991700485996578  Time:  1.8031797409057617\n",
      "Total Valid Loss:  2.2673927942911782  Time:  0.024933815002441406\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.05554317135525786  Time:  1.9577655792236328\n",
      "Total Valid Loss:  2.1992756525675454  Time:  0.022938251495361328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.052125260298666744  Time:  1.7932031154632568\n",
      "Total Valid Loss:  2.179474115371704  Time:  0.02393627166748047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.049032019823789595  Time:  1.9218626022338867\n",
      "Total Valid Loss:  2.260686715443929  Time:  0.027927398681640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.045713273079498955  Time:  2.1033711433410645\n",
      "Total Valid Loss:  2.14994486172994  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.043690781748813134  Time:  2.175184965133667\n",
      "Total Valid Loss:  2.2088476022084556  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.04164641655009726  Time:  2.1013786792755127\n",
      "Total Valid Loss:  2.172757148742676  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.03955969791049543  Time:  2.05450701713562\n",
      "Total Valid Loss:  2.1479407946268716  Time:  0.026964664459228516\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.03801825362379136  Time:  2.1472556591033936\n",
      "Total Valid Loss:  2.202893336613973  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.03674725274676862  Time:  2.008629560470581\n",
      "Total Valid Loss:  2.224248011906942  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.03568170736341373  Time:  2.1312994956970215\n",
      "Total Valid Loss:  2.126351833343506  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.03474329002201557  Time:  2.025583267211914\n",
      "Total Valid Loss:  2.12496018409729  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.03378642729443052  Time:  2.060490846633911\n",
      "Total Valid Loss:  2.1131437619527182  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.03285487716936547  Time:  2.0963962078094482\n",
      "Total Valid Loss:  2.185084501902262  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.032341116925944456  Time:  2.3955931663513184\n",
      "Total Valid Loss:  2.157066504160563  Time:  0.03889727592468262\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.032098587731952254  Time:  3.324110507965088\n",
      "Total Valid Loss:  2.1863226890563965  Time:  0.030916929244995117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.031060585201434468  Time:  2.327775716781616\n",
      "Total Valid Loss:  2.227749983469645  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.030752358909534372  Time:  2.0764522552490234\n",
      "Total Valid Loss:  2.212864637374878  Time:  0.025931596755981445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.0302300240682519  Time:  2.24299955368042\n",
      "Total Valid Loss:  2.087811231613159  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.029952259507516156  Time:  2.0963964462280273\n",
      "Total Valid Loss:  2.194713592529297  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.029563869762679804  Time:  2.0365872383117676\n",
      "Total Valid Loss:  2.2319976488749185  Time:  0.026893138885498047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.02907009059968202  Time:  2.063481569290161\n",
      "Total Valid Loss:  2.1683640480041504  Time:  0.02593064308166504\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.028937006644580675  Time:  2.3118185997009277\n",
      "Total Valid Loss:  2.167064905166626  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.028441577842054158  Time:  2.0604898929595947\n",
      "Total Valid Loss:  2.199192841847738  Time:  0.025930166244506836\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.02848027876537779  Time:  2.211089849472046\n",
      "Total Valid Loss:  2.1960622469584146  Time:  0.028922319412231445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.02825643527119056  Time:  2.3636770248413086\n",
      "Total Valid Loss:  2.137869914372762  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.027821417185275452  Time:  2.118335008621216\n",
      "Total Valid Loss:  2.2046770254770913  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.02749711192496445  Time:  1.992671012878418\n",
      "Total Valid Loss:  2.172804276148478  Time:  0.02692866325378418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.027332307058184045  Time:  2.287882089614868\n",
      "Total Valid Loss:  2.1506837209065757  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.02743686021346113  Time:  2.075451135635376\n",
      "Total Valid Loss:  2.15474271774292  Time:  0.026930570602416992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.027101719476606535  Time:  1.991671085357666\n",
      "Total Valid Loss:  2.149836301803589  Time:  0.02593064308166504\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.026868434282748595  Time:  1.984694480895996\n",
      "Total Valid Loss:  2.100232203801473  Time:  0.025931835174560547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.026628217910942824  Time:  2.0066311359405518\n",
      "Total Valid Loss:  2.0872651735941568  Time:  0.037899017333984375\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.026474470888143  Time:  1.9956657886505127\n",
      "Total Valid Loss:  2.0679330031077066  Time:  0.03091573715209961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.025922615712751514  Time:  2.0864224433898926\n",
      "Total Valid Loss:  2.169828732808431  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.02595118959636792  Time:  2.4384779930114746\n",
      "Total Valid Loss:  2.1781144936879477  Time:  0.07280111312866211\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.02609245908325133  Time:  2.1123528480529785\n",
      "Total Valid Loss:  2.186074415842692  Time:  0.03091907501220703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.025921419279082963  Time:  2.0614845752716064\n",
      "Total Valid Loss:  2.164024273554484  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.025368002105666244  Time:  2.0225887298583984\n",
      "Total Valid Loss:  2.163254419962565  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.025339165508099223  Time:  1.9547698497772217\n",
      "Total Valid Loss:  2.102759758631388  Time:  0.02593088150024414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.02510585384848325  Time:  2.2719244956970215\n",
      "Total Valid Loss:  2.140829006830851  Time:  0.02992081642150879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.02486743501023106  Time:  2.060492753982544\n",
      "Total Valid Loss:  2.130157232284546  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.024787179072913917  Time:  2.0066332817077637\n",
      "Total Valid Loss:  2.0890594323476157  Time:  0.02593231201171875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.024520363448106725  Time:  2.074449300765991\n",
      "Total Valid Loss:  2.104891856511434  Time:  0.026929616928100586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.024602550154794817  Time:  2.1023786067962646\n",
      "Total Valid Loss:  2.1856130758921304  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.024233580817994864  Time:  2.0006473064422607\n",
      "Total Valid Loss:  2.2291311422983804  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.024437817947372147  Time:  1.9896795749664307\n",
      "Total Valid Loss:  2.172006130218506  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.024692583132697187  Time:  2.0475242137908936\n",
      "Total Valid Loss:  2.1693058808644614  Time:  0.026927709579467773\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.024179477017858754  Time:  2.031566619873047\n",
      "Total Valid Loss:  2.1303993860880532  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.0238181059613176  Time:  2.0664749145507812\n",
      "Total Valid Loss:  2.1612548828125  Time:  0.02991962432861328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.023976811151141707  Time:  2.0614895820617676\n",
      "Total Valid Loss:  2.175485690434774  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.0234864200586858  Time:  2.045527696609497\n",
      "Total Valid Loss:  2.2032097975413003  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.023374108484257822  Time:  2.0136172771453857\n",
      "Total Valid Loss:  2.128230174382528  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.023310544681937797  Time:  1.998652458190918\n",
      "Total Valid Loss:  2.165443181991577  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.02319081522848295  Time:  2.0764479637145996\n",
      "Total Valid Loss:  2.172694206237793  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.023106343363938124  Time:  2.029573440551758\n",
      "Total Valid Loss:  2.1442349751790366  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.023005659197983534  Time:  2.0345616340637207\n",
      "Total Valid Loss:  2.1448259353637695  Time:  0.027924299240112305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.022913646681801132  Time:  1.9996516704559326\n",
      "Total Valid Loss:  2.22155753771464  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.022750652581453323  Time:  2.005638360977173\n",
      "Total Valid Loss:  2.2006115913391113  Time:  0.028922319412231445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.022430328004386112  Time:  2.0195980072021484\n",
      "Total Valid Loss:  2.1591909726460776  Time:  0.027926921844482422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.022517141651200213  Time:  2.061486005783081\n",
      "Total Valid Loss:  2.1527456442515054  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.022266356306879415  Time:  1.9896790981292725\n",
      "Total Valid Loss:  2.126218318939209  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.02256858327790447  Time:  2.109360933303833\n",
      "Total Valid Loss:  2.140087842941284  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.022243972802939622  Time:  2.048520565032959\n",
      "Total Valid Loss:  2.0710646311442056  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.022214218941719637  Time:  2.153240442276001\n",
      "Total Valid Loss:  2.1283187866210938  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.02173460425566072  Time:  2.0535101890563965\n",
      "Total Valid Loss:  2.112955888112386  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.02204678165523902  Time:  2.166207790374756\n",
      "Total Valid Loss:  2.171710252761841  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.021798503058760063  Time:  2.129303216934204\n",
      "Total Valid Loss:  2.1120819250742593  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.02158235230523607  Time:  2.077446937561035\n",
      "Total Valid Loss:  2.1071333090464273  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.021543571417746335  Time:  2.32877254486084\n",
      "Total Valid Loss:  2.1296037832895913  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.021513403385229734  Time:  2.115360736846924\n",
      "Total Valid Loss:  2.1848397254943848  Time:  0.025931358337402344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.02137453432964242  Time:  2.0325655937194824\n",
      "Total Valid Loss:  2.1632046699523926  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.021547937474173048  Time:  2.1003811359405518\n",
      "Total Valid Loss:  2.18958314259847  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.021433967578670252  Time:  2.2390151023864746\n",
      "Total Valid Loss:  2.112037499745687  Time:  0.026927471160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.021442170182000037  Time:  2.0355539321899414\n",
      "Total Valid Loss:  2.130262533823649  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.021159004905949467  Time:  2.0425405502319336\n",
      "Total Valid Loss:  2.1457709471384683  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.02124067567612814  Time:  2.4893434047698975\n",
      "Total Valid Loss:  2.120062510172526  Time:  0.025928497314453125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.02119420676127724  Time:  2.0754525661468506\n",
      "Total Valid Loss:  2.1501232782999673  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.020960616498537685  Time:  2.026581048965454\n",
      "Total Valid Loss:  2.1603175004323325  Time:  0.0279238224029541\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.02087227843053963  Time:  2.0694661140441895\n",
      "Total Valid Loss:  2.148517608642578  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.020806320546113928  Time:  1.9986531734466553\n",
      "Total Valid Loss:  2.143519163131714  Time:  0.025931596755981445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.02082689129140066  Time:  2.0136146545410156\n",
      "Total Valid Loss:  2.147059202194214  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.020850397873183955  Time:  2.0375537872314453\n",
      "Total Valid Loss:  2.147733211517334  Time:  0.04886651039123535\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.02078684014470681  Time:  2.064481496810913\n",
      "Total Valid Loss:  2.1641792456309  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.021097709773027377  Time:  2.023587942123413\n",
      "Total Valid Loss:  2.1725969314575195  Time:  0.02692699432373047\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.021034675885153852  Time:  2.077443838119507\n",
      "Total Valid Loss:  2.1413729190826416  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.02082969739061335  Time:  2.076444387435913\n",
      "Total Valid Loss:  2.1706570784250894  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.020517730097407882  Time:  1.9517810344696045\n",
      "Total Valid Loss:  2.1496724287668862  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.020189504649328147  Time:  2.374650001525879\n",
      "Total Valid Loss:  2.146207412083944  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.02022620959450369  Time:  2.192138195037842\n",
      "Total Valid Loss:  2.1691864331563315  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  75.53206729888916\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.640353745998 =======\n",
      "======= Set val : score(recall_10)=0.705969595847 =======\n",
      "======= Set val : score(recall_20)=0.754171301446 =======\n",
      "======= Set val : score(map_cut_10)=0.619820229414 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.12590796059888343  Time:  1.9886820316314697\n",
      "Total Valid Loss:  2.5554959774017334  Time:  0.023937225341796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.0997217133641243  Time:  2.0265800952911377\n",
      "Total Valid Loss:  2.515959103902181  Time:  0.025931119918823242\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.09757177078205606  Time:  1.9577655792236328\n",
      "Total Valid Loss:  2.6059398651123047  Time:  0.0767967700958252\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.0960787041031796  Time:  2.080432891845703\n",
      "Total Valid Loss:  2.5415722529093423  Time:  0.024932146072387695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.09416830539703369  Time:  1.9009168148040771\n",
      "Total Valid Loss:  2.537329912185669  Time:  0.02593064308166504\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.09189841688975044  Time:  1.8899450302124023\n",
      "Total Valid Loss:  2.378319422403971  Time:  0.06083798408508301\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.0880352047474488  Time:  2.05849552154541\n",
      "Total Valid Loss:  2.3577805360158286  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.08238767411397852  Time:  2.150250196456909\n",
      "Total Valid Loss:  2.3839067618052163  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.07658237925042277  Time:  2.243001699447632\n",
      "Total Valid Loss:  2.3112947940826416  Time:  0.030918598175048828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.07117982098589773  Time:  2.1442666053771973\n",
      "Total Valid Loss:  2.3087080319722495  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.0658803173057411  Time:  2.116340160369873\n",
      "Total Valid Loss:  2.244898239771525  Time:  0.028924226760864258\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.061726614476545996  Time:  2.1791701316833496\n",
      "Total Valid Loss:  2.3239927291870117  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.05813755713727163  Time:  2.1033754348754883\n",
      "Total Valid Loss:  2.327220598856608  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.055163817949917  Time:  2.254971981048584\n",
      "Total Valid Loss:  2.285047690073649  Time:  0.02993178367614746\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.052195774375096614  Time:  2.1931312084198\n",
      "Total Valid Loss:  2.2500995794932046  Time:  0.02892446517944336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.05025503949626632  Time:  2.0804355144500732\n",
      "Total Valid Loss:  2.2269301414489746  Time:  0.03191518783569336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.04870412644484769  Time:  2.201115369796753\n",
      "Total Valid Loss:  2.3004283905029297  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.04683769027823987  Time:  2.216073989868164\n",
      "Total Valid Loss:  2.2003723780314126  Time:  0.027927160263061523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.045183949366859766  Time:  2.090409278869629\n",
      "Total Valid Loss:  2.168693939844767  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.04409315524541813  Time:  2.151287317276001\n",
      "Total Valid Loss:  2.1345414320627847  Time:  0.029920101165771484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.04241821221683336  Time:  2.2200632095336914\n",
      "Total Valid Loss:  2.2501843770345054  Time:  0.027928829193115234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.041860550706801204  Time:  2.024582624435425\n",
      "Total Valid Loss:  2.1823294162750244  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.04081853433795597  Time:  2.119333267211914\n",
      "Total Valid Loss:  2.113133430480957  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.0403952254873255  Time:  2.1013801097869873\n",
      "Total Valid Loss:  2.1308071613311768  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.039405147374972055  Time:  2.0684707164764404\n",
      "Total Valid Loss:  2.0889129638671875  Time:  0.030916213989257812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.038468097701020866  Time:  2.1263136863708496\n",
      "Total Valid Loss:  2.1790219942728677  Time:  0.03091740608215332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.03787503530797751  Time:  2.212083101272583\n",
      "Total Valid Loss:  2.187485694885254  Time:  0.03191661834716797\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.03786474563505338  Time:  2.1362879276275635\n",
      "Total Valid Loss:  2.193417469660441  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.03688112481132798  Time:  2.188147783279419\n",
      "Total Valid Loss:  2.093932549158732  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.036783067946848665  Time:  2.1941306591033936\n",
      "Total Valid Loss:  2.1553271611531577  Time:  0.027927875518798828\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.036253152236990306  Time:  2.0993857383728027\n",
      "Total Valid Loss:  2.233253796895345  Time:  0.033907175064086914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.03550157566433367  Time:  2.3008556365966797\n",
      "Total Valid Loss:  2.1229875882466636  Time:  0.08776473999023438\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.03552476969426093  Time:  2.384622573852539\n",
      "Total Valid Loss:  2.075824022293091  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.03473206635402597  Time:  2.4524412155151367\n",
      "Total Valid Loss:  2.1876975695292153  Time:  0.042885780334472656\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.03493236240161502  Time:  2.296856164932251\n",
      "Total Valid Loss:  2.240409771601359  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.03464740223210791  Time:  2.4733850955963135\n",
      "Total Valid Loss:  2.155038595199585  Time:  0.03191685676574707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.033884656153943225  Time:  2.2559657096862793\n",
      "Total Valid Loss:  2.1896163622538247  Time:  0.02892470359802246\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.03376171588897705  Time:  2.191140651702881\n",
      "Total Valid Loss:  2.24906325340271  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.03340174248037131  Time:  2.4374840259552\n",
      "Total Valid Loss:  2.122843583424886  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n",
      "Total Train Loss:  0.03340737730588602  Time:  2.937143564224243\n",
      "Total Valid Loss:  2.1248598098754883  Time:  0.07180619239807129\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.0330677624143984  Time:  2.33575439453125\n",
      "Total Valid Loss:  2.15493114789327  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.03274245607140271  Time:  2.464409589767456\n",
      "Total Valid Loss:  2.0857604344685874  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.03260877362411955  Time:  2.1532421112060547\n",
      "Total Valid Loss:  2.1047780513763428  Time:  0.039896249771118164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.03219278866182203  Time:  2.188148021697998\n",
      "Total Valid Loss:  2.156156142552694  Time:  0.028923988342285156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.032087307212793306  Time:  2.0764448642730713\n",
      "Total Valid Loss:  2.2598037719726562  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.031691432031600374  Time:  2.141275644302368\n",
      "Total Valid Loss:  2.218682607014974  Time:  0.027932167053222656\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.03163740578229013  Time:  2.106358289718628\n",
      "Total Valid Loss:  2.1619087855021157  Time:  0.02895951271057129\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.03141131315218366  Time:  2.1163041591644287\n",
      "Total Valid Loss:  2.1369508107503257  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.03129743731216244  Time:  2.092406749725342\n",
      "Total Valid Loss:  2.160989761352539  Time:  0.02692890167236328\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.03128883172960385  Time:  2.3786368370056152\n",
      "Total Valid Loss:  2.1608996391296387  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.030892811164907788  Time:  2.0983901023864746\n",
      "Total Valid Loss:  2.1626811822255454  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.031044663958575414  Time:  2.0604872703552246\n",
      "Total Valid Loss:  2.1207918326059976  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.030626788492435993  Time:  2.1003823280334473\n",
      "Total Valid Loss:  2.149449666341146  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.030462753464994222  Time:  2.1532421112060547\n",
      "Total Valid Loss:  2.2210156122843423  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.030129221049339874  Time:  2.242003917694092\n",
      "Total Valid Loss:  2.157428582509359  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.030355984863379728  Time:  2.123322010040283\n",
      "Total Valid Loss:  2.159760077794393  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.029867792097122772  Time:  2.1911427974700928\n",
      "Total Valid Loss:  2.1219356060028076  Time:  0.046872854232788086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.030249059135499207  Time:  2.044532537460327\n",
      "Total Valid Loss:  2.1684629917144775  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.029679076891878375  Time:  2.5352203845977783\n",
      "Total Valid Loss:  2.1204636096954346  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.02976924180984497  Time:  2.190143346786499\n",
      "Total Valid Loss:  2.10585888226827  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.029683913501060526  Time:  2.28289532661438\n",
      "Total Valid Loss:  2.1651785373687744  Time:  0.03291201591491699\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.029531670912452367  Time:  2.062486171722412\n",
      "Total Valid Loss:  2.084681272506714  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.029353533377465994  Time:  2.3177998065948486\n",
      "Total Valid Loss:  2.2101646264394126  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.029031676620892857  Time:  2.0983917713165283\n",
      "Total Valid Loss:  2.125587224960327  Time:  0.027927398681640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.029238423640313357  Time:  2.036550998687744\n",
      "Total Valid Loss:  2.186027765274048  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.028922749181156573  Time:  2.1163408756256104\n",
      "Total Valid Loss:  2.126569906870524  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.02896307483315468  Time:  2.2390129566192627\n",
      "Total Valid Loss:  2.090536038080851  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.028587326860946158  Time:  3.022915840148926\n",
      "Total Valid Loss:  2.1717687447865806  Time:  0.03789830207824707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.02868021475556104  Time:  2.129304885864258\n",
      "Total Valid Loss:  2.1636440753936768  Time:  0.03693962097167969\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.028697371337076893  Time:  2.1611838340759277\n",
      "Total Valid Loss:  2.107968807220459  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.028498060693559438  Time:  2.178175210952759\n",
      "Total Valid Loss:  2.1092543601989746  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.028374200476252515  Time:  2.148256540298462\n",
      "Total Valid Loss:  2.1365840435028076  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.028231237634368564  Time:  2.1053714752197266\n",
      "Total Valid Loss:  2.1080044905344644  Time:  0.029921770095825195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.028056003477262413  Time:  2.337747097015381\n",
      "Total Valid Loss:  2.1725788911183677  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.028173855675951293  Time:  2.256965398788452\n",
      "Total Valid Loss:  2.1294737656911216  Time:  0.03390669822692871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n",
      "Total Train Loss:  0.02813440898190374  Time:  2.1263134479522705\n",
      "Total Valid Loss:  2.1047720114390054  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.028163365550015283  Time:  2.4015772342681885\n",
      "Total Valid Loss:  2.0718411604563394  Time:  0.028925418853759766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.02773951923717623  Time:  3.19046688079834\n",
      "Total Valid Loss:  2.068659782409668  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.027587793978012125  Time:  2.4693984985351562\n",
      "Total Valid Loss:  2.060169776280721  Time:  0.030920028686523438\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.02754268335259479  Time:  2.1492509841918945\n",
      "Total Valid Loss:  2.221354881922404  Time:  0.029921293258666992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.02762259654700756  Time:  2.0943987369537354\n",
      "Total Valid Loss:  2.2088151772816977  Time:  0.03195333480834961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.027777882422442023  Time:  2.0833919048309326\n",
      "Total Valid Loss:  2.1137897968292236  Time:  0.030918121337890625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.027647002235702847  Time:  2.1701974868774414\n",
      "Total Valid Loss:  2.127824624379476  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.027645775627182876  Time:  2.538212299346924\n",
      "Total Valid Loss:  2.1104986667633057  Time:  0.03191375732421875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.02748610636462336  Time:  2.0934014320373535\n",
      "Total Valid Loss:  2.1700375080108643  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.027305568268765575  Time:  2.1023776531219482\n",
      "Total Valid Loss:  2.198036511739095  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.02703687712226225  Time:  2.737679958343506\n",
      "Total Valid Loss:  2.115100622177124  Time:  0.04189181327819824\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.027140486564325248  Time:  2.263939380645752\n",
      "Total Valid Loss:  2.139115571975708  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.02714915784156841  Time:  2.3237857818603516\n",
      "Total Valid Loss:  2.1198569933573403  Time:  0.06482720375061035\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.027078469713097034  Time:  3.374974489212036\n",
      "Total Valid Loss:  2.160066763559977  Time:  0.03091740608215332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.02712519034419371  Time:  2.402575731277466\n",
      "Total Valid Loss:  2.193913777669271  Time:  0.045877695083618164\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.02710688122264717  Time:  2.829435110092163\n",
      "Total Valid Loss:  2.135653575261434  Time:  0.034905195236206055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.02688376406288665  Time:  2.5272412300109863\n",
      "Total Valid Loss:  2.100944995880127  Time:  0.03391098976135254\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.02675127375708974  Time:  2.746654510498047\n",
      "Total Valid Loss:  2.062509059906006  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.026798264099204022  Time:  2.297855854034424\n",
      "Total Valid Loss:  2.1970859368642173  Time:  0.033908843994140625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.02667403000852336  Time:  2.183163642883301\n",
      "Total Valid Loss:  2.182117144266764  Time:  0.04089069366455078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.026728762718646423  Time:  2.14426589012146\n",
      "Total Valid Loss:  2.1371942361195884  Time:  0.030917882919311523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.02647960471070331  Time:  2.479370355606079\n",
      "Total Valid Loss:  2.1503289540608725  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.026491001977220825  Time:  2.3207943439483643\n",
      "Total Valid Loss:  2.1137917836507163  Time:  0.028925180435180664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.026614415386448737  Time:  2.390608072280884\n",
      "Total Valid Loss:  2.07904052734375  Time:  0.028922319412231445\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  76.71087884902954\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.651250484187 =======\n",
      "======= Set val : score(recall_10)=0.720800889878 =======\n",
      "======= Set val : score(recall_20)=0.761216166110 =======\n",
      "======= Set val : score(map_cut_10)=0.629306960703 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.1\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.12788128762141518  Time:  1.9936258792877197\n",
      "Total Valid Loss:  2.58806840578715  Time:  0.0249330997467041\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.1006963396201963  Time:  2.0225915908813477\n",
      "Total Valid Loss:  2.5878617763519287  Time:  0.023936033248901367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.09882636789394461  Time:  2.1193339824676514\n",
      "Total Valid Loss:  2.682492812474569  Time:  0.024932861328125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.09768570849429006  Time:  1.9826977252960205\n",
      "Total Valid Loss:  2.550928751627604  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.0963272732237111  Time:  2.129307746887207\n",
      "Total Valid Loss:  2.5485007762908936  Time:  0.03490567207336426\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.0944878739507302  Time:  2.465407609939575\n",
      "Total Valid Loss:  2.431487719217936  Time:  0.03789877891540527\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.09118267608725507  Time:  2.4434664249420166\n",
      "Total Valid Loss:  2.419228951136271  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.08625048962624177  Time:  2.4215242862701416\n",
      "Total Valid Loss:  2.4147660732269287  Time:  0.03989410400390625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.07980706860189853  Time:  2.8663363456726074\n",
      "Total Valid Loss:  2.4051164786020913  Time:  0.04886960983276367\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.07430321389566297  Time:  2.9540984630584717\n",
      "Total Valid Loss:  2.377490441004435  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.06875812942567079  Time:  2.281898021697998\n",
      "Total Valid Loss:  2.342209577560425  Time:  0.028924942016601562\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.06463153663536776  Time:  2.477374315261841\n",
      "Total Valid Loss:  2.3583695888519287  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.061121178191641104  Time:  2.4155385494232178\n",
      "Total Valid Loss:  2.2723390261332193  Time:  0.02692866325378418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.058403273380321  Time:  2.319795846939087\n",
      "Total Valid Loss:  2.350839535395304  Time:  0.03690147399902344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.05527985176962355  Time:  2.8653388023376465\n",
      "Total Valid Loss:  2.239413102467855  Time:  0.03390860557556152\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.053457625987737074  Time:  3.2034380435943604\n",
      "Total Valid Loss:  2.22224752108256  Time:  0.039893388748168945\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16 starts !\n",
      "Total Train Loss:  0.05158196250381677  Time:  3.876633882522583\n",
      "Total Valid Loss:  2.2991439501444497  Time:  0.04787182807922363\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17 starts !\n",
      "Total Train Loss:  0.04960423050367314  Time:  3.132632255554199\n",
      "Total Valid Loss:  2.2722153663635254  Time:  0.053847551345825195\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18 starts !\n",
      "Total Train Loss:  0.04806668078121932  Time:  3.0827555656433105\n",
      "Total Valid Loss:  2.225213130315145  Time:  0.03590536117553711\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19 starts !\n",
      "Total Train Loss:  0.047034164096998135  Time:  2.423520088195801\n",
      "Total Valid Loss:  2.1765788396199546  Time:  0.033910274505615234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20 starts !\n",
      "Total Train Loss:  0.04555129078419312  Time:  3.2513043880462646\n",
      "Total Valid Loss:  2.2463342348734536  Time:  0.029918909072875977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21 starts !\n",
      "Total Train Loss:  0.04484879986747452  Time:  2.7556312084198\n",
      "Total Valid Loss:  2.1088757514953613  Time:  0.033910274505615234\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 22 starts !\n",
      "Total Train Loss:  0.043881192220293956  Time:  3.039870262145996\n",
      "Total Valid Loss:  2.1731143792470298  Time:  0.026927947998046875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 23 starts !\n",
      "Total Train Loss:  0.04303664471144262  Time:  2.379638671875\n",
      "Total Valid Loss:  2.1899381478627524  Time:  0.029921531677246094\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 24 starts !\n",
      "Total Train Loss:  0.04225431917154271  Time:  2.482358932495117\n",
      "Total Valid Loss:  2.1807403564453125  Time:  0.03790020942687988\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 25 starts !\n",
      "Total Train Loss:  0.04133618418937144  Time:  2.421523094177246\n",
      "Total Valid Loss:  2.1803641319274902  Time:  0.03889656066894531\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 26 starts !\n",
      "Total Train Loss:  0.040549895977196486  Time:  2.2998507022857666\n",
      "Total Valid Loss:  2.1425461769104004  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 27 starts !\n",
      "Total Train Loss:  0.04058036528851675  Time:  2.284891366958618\n",
      "Total Valid Loss:  2.1701058546702066  Time:  0.02992105484008789\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 28 starts !\n",
      "Total Train Loss:  0.03958220394409221  Time:  2.357692003250122\n",
      "Total Valid Loss:  2.1059366861979165  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 29 starts !\n",
      "Total Train Loss:  0.03945887322011201  Time:  2.3577373027801514\n",
      "Total Valid Loss:  2.101579268773397  Time:  0.028880596160888672\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 30 starts !\n",
      "Total Train Loss:  0.03899689226046853  Time:  2.2649455070495605\n",
      "Total Valid Loss:  2.1974026362101235  Time:  0.030917644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 31 starts !\n",
      "Total Train Loss:  0.0384397744808508  Time:  2.210089683532715\n",
      "Total Valid Loss:  2.157331943511963  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 32 starts !\n",
      "Total Train Loss:  0.03806571856788967  Time:  2.131298780441284\n",
      "Total Valid Loss:  2.0662413438161216  Time:  0.028922557830810547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 33 starts !\n",
      "Total Train Loss:  0.0377005554087784  Time:  2.149252414703369\n",
      "Total Valid Loss:  2.199739853541056  Time:  0.02892327308654785\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 34 starts !\n",
      "Total Train Loss:  0.03741931371066881  Time:  2.3806397914886475\n",
      "Total Valid Loss:  2.210190773010254  Time:  0.04587674140930176\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 35 starts !\n",
      "Total Train Loss:  0.037327700723772464  Time:  2.19014310836792\n",
      "Total Valid Loss:  2.1332794030507407  Time:  0.034906864166259766\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 36 starts !\n",
      "Total Train Loss:  0.036820941062077235  Time:  2.7207250595092773\n",
      "Total Valid Loss:  2.1547414461771646  Time:  0.027927398681640625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 37 starts !\n",
      "Total Train Loss:  0.036683051417703214  Time:  2.5541698932647705\n",
      "Total Valid Loss:  2.167146603266398  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 38 starts !\n",
      "Total Train Loss:  0.0360989966146324  Time:  2.622986316680908\n",
      "Total Valid Loss:  2.171398321787516  Time:  0.03390908241271973\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 39 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.03603248516826526  Time:  2.3447303771972656\n",
      "Total Valid Loss:  2.1028645833333335  Time:  0.02892279624938965\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 40 starts !\n",
      "Total Train Loss:  0.035877043235561124  Time:  2.205103635787964\n",
      "Total Valid Loss:  2.080402374267578  Time:  0.03793978691101074\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 41 starts !\n",
      "Total Train Loss:  0.035587662296450655  Time:  2.1541969776153564\n",
      "Total Valid Loss:  2.1192057132720947  Time:  0.02892613410949707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 42 starts !\n",
      "Total Train Loss:  0.035416359065667445  Time:  2.2909154891967773\n",
      "Total Valid Loss:  2.1188417275746665  Time:  0.029875993728637695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 43 starts !\n",
      "Total Train Loss:  0.035072951520914615  Time:  3.0438621044158936\n",
      "Total Valid Loss:  2.0966099898020425  Time:  0.041887521743774414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 44 starts !\n",
      "Total Train Loss:  0.03470928735383179  Time:  2.367668390274048\n",
      "Total Valid Loss:  2.1989086469014487  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 45 starts !\n",
      "Total Train Loss:  0.034855161088964214  Time:  2.794527769088745\n",
      "Total Valid Loss:  2.2052367528279624  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 46 starts !\n",
      "Total Train Loss:  0.03463145811920581  Time:  2.9042341709136963\n",
      "Total Valid Loss:  2.1661640803019204  Time:  0.058843374252319336\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 47 starts !\n",
      "Total Train Loss:  0.03434029070903426  Time:  3.838735342025757\n",
      "Total Valid Loss:  2.1791606744130454  Time:  0.043882131576538086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 48 starts !\n",
      "Total Train Loss:  0.03423569994452207  Time:  2.4773781299591064\n",
      "Total Valid Loss:  2.127058426539103  Time:  0.028922080993652344\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 49 starts !\n",
      "Total Train Loss:  0.03439230603044448  Time:  2.269927501678467\n",
      "Total Valid Loss:  2.1354287465413413  Time:  0.03789925575256348\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 50 starts !\n",
      "Total Train Loss:  0.0339116957038641  Time:  2.2171027660369873\n",
      "Total Valid Loss:  2.115891615549723  Time:  0.029889345169067383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 51 starts !\n",
      "Total Train Loss:  0.03387249380997989  Time:  2.2599563598632812\n",
      "Total Valid Loss:  2.155397812525431  Time:  0.030919313430786133\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 52 starts !\n",
      "Total Train Loss:  0.033614110833276874  Time:  2.2479867935180664\n",
      "Total Valid Loss:  2.1045942306518555  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 53 starts !\n",
      "Total Train Loss:  0.03368171029116796  Time:  2.275913715362549\n",
      "Total Valid Loss:  2.139092127482096  Time:  0.027925729751586914\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 54 starts !\n",
      "Total Train Loss:  0.03305859319541765  Time:  2.1512491703033447\n",
      "Total Valid Loss:  2.087645928064982  Time:  0.02792644500732422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 55 starts !\n",
      "Total Train Loss:  0.03326830961134123  Time:  2.167203426361084\n",
      "Total Valid Loss:  2.1546529134114585  Time:  0.02792835235595703\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 56 starts !\n",
      "Total Train Loss:  0.03281371770021708  Time:  2.1512465476989746\n",
      "Total Valid Loss:  2.111341873804728  Time:  0.026928186416625977\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 57 starts !\n",
      "Total Train Loss:  0.0332905182533938  Time:  2.2060983180999756\n",
      "Total Valid Loss:  2.100927193959554  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 58 starts !\n",
      "Total Train Loss:  0.032733179547864456  Time:  2.117337703704834\n",
      "Total Valid Loss:  2.1809619267781577  Time:  0.026929378509521484\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 59 starts !\n",
      "Total Train Loss:  0.03277686959051568  Time:  2.1163437366485596\n",
      "Total Valid Loss:  2.1605979601542153  Time:  0.02693009376525879\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 60 starts !\n",
      "Total Train Loss:  0.032550577560196754  Time:  2.1053683757781982\n",
      "Total Valid Loss:  2.074142853418986  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 61 starts !\n",
      "Total Train Loss:  0.03230639535771764  Time:  2.3716578483581543\n",
      "Total Valid Loss:  2.101526896158854  Time:  0.0498654842376709\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 62 starts !\n",
      "Total Train Loss:  0.032246458238881566  Time:  2.2599587440490723\n",
      "Total Valid Loss:  2.1402783393859863  Time:  0.03390765190124512\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 63 starts !\n",
      "Total Train Loss:  0.032242195016664005  Time:  2.1462624073028564\n",
      "Total Valid Loss:  2.091864029566447  Time:  0.026929140090942383\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 64 starts !\n",
      "Total Train Loss:  0.03217382489339165  Time:  2.169196128845215\n",
      "Total Valid Loss:  2.1422252655029297  Time:  0.027925968170166016\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 65 starts !\n",
      "Total Train Loss:  0.03198105961732242  Time:  2.116340398788452\n",
      "Total Valid Loss:  2.138127565383911  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 66 starts !\n",
      "Total Train Loss:  0.03187005365996257  Time:  2.1891467571258545\n",
      "Total Valid Loss:  2.0985856850941977  Time:  0.029921293258666992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 67 starts !\n",
      "Total Train Loss:  0.03161093119693839  Time:  2.1991171836853027\n",
      "Total Valid Loss:  2.1617735226949057  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 68 starts !\n",
      "Total Train Loss:  0.03197421904491342  Time:  2.157233238220215\n",
      "Total Valid Loss:  2.1472832361857095  Time:  0.031915903091430664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 69 starts !\n",
      "Total Train Loss:  0.03168803655906864  Time:  2.346724033355713\n",
      "Total Valid Loss:  2.133960485458374  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 70 starts !\n",
      "Total Train Loss:  0.03152584276445534  Time:  2.1432743072509766\n",
      "Total Valid Loss:  2.073838392893473  Time:  0.03091716766357422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 71 starts !\n",
      "Total Train Loss:  0.03155006273933079  Time:  2.2220559120178223\n",
      "Total Valid Loss:  2.164970636367798  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 72 starts !\n",
      "Total Train Loss:  0.031283479799395025  Time:  2.14725923538208\n",
      "Total Valid Loss:  2.130650361378988  Time:  0.031914710998535156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 73 starts !\n",
      "Total Train Loss:  0.03109784722328186  Time:  2.2240512371063232\n",
      "Total Valid Loss:  2.1487061977386475  Time:  0.0329136848449707\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 74 starts !\n",
      "Total Train Loss:  0.031090144537713218  Time:  2.289874792098999\n",
      "Total Valid Loss:  2.122901678085327  Time:  0.026928424835205078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 75 starts !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Loss:  0.03111103998254175  Time:  2.2140793800354004\n",
      "Total Valid Loss:  2.1302101612091064  Time:  0.028923511505126953\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 76 starts !\n",
      "Total Train Loss:  0.031374643014177035  Time:  2.1951324939727783\n",
      "Total Valid Loss:  2.1243383089701333  Time:  0.03490638732910156\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 77 starts !\n",
      "Total Train Loss:  0.030883620808953825  Time:  2.1821653842926025\n",
      "Total Valid Loss:  2.108703056971232  Time:  0.02892303466796875\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 78 starts !\n",
      "Total Train Loss:  0.030920135877702547  Time:  2.1253163814544678\n",
      "Total Valid Loss:  2.087153514226278  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 79 starts !\n",
      "Total Train Loss:  0.030799601308029632  Time:  2.1991167068481445\n",
      "Total Valid Loss:  2.131251811981201  Time:  0.030918121337890625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 80 starts !\n",
      "Total Train Loss:  0.03039488614253376  Time:  2.2031073570251465\n",
      "Total Valid Loss:  2.1433610121409097  Time:  0.0359044075012207\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 81 starts !\n",
      "Total Train Loss:  0.030365786863409953  Time:  2.1293063163757324\n",
      "Total Valid Loss:  2.1205972035725913  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 82 starts !\n",
      "Total Train Loss:  0.030473408216367598  Time:  2.336751699447632\n",
      "Total Valid Loss:  2.1769564151763916  Time:  0.028923749923706055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 83 starts !\n",
      "Total Train Loss:  0.030306495224004207  Time:  2.1263139247894287\n",
      "Total Valid Loss:  2.14310630162557  Time:  0.029920339584350586\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 84 starts !\n",
      "Total Train Loss:  0.030502321149991907  Time:  2.0934011936187744\n",
      "Total Valid Loss:  2.130328814188639  Time:  0.03390955924987793\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 85 starts !\n",
      "Total Train Loss:  0.030625909437303957  Time:  2.175183057785034\n",
      "Total Valid Loss:  2.122398296991984  Time:  0.03690171241760254\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 86 starts !\n",
      "Total Train Loss:  0.030048283675442572  Time:  2.0993881225585938\n",
      "Total Valid Loss:  2.0985427697499595  Time:  0.02792668342590332\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 87 starts !\n",
      "Total Train Loss:  0.030300441465300063  Time:  2.2679316997528076\n",
      "Total Valid Loss:  2.0899767875671387  Time:  0.029921293258666992\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 88 starts !\n",
      "Total Train Loss:  0.030170141775970872  Time:  2.644927978515625\n",
      "Total Valid Loss:  2.153384526570638  Time:  0.028922319412231445\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 89 starts !\n",
      "Total Train Loss:  0.029997449773161308  Time:  2.128307819366455\n",
      "Total Valid Loss:  2.112964073816935  Time:  0.027926206588745117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 90 starts !\n",
      "Total Train Loss:  0.030082655681864075  Time:  2.244995355606079\n",
      "Total Valid Loss:  2.094773530960083  Time:  0.02792525291442871\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 91 starts !\n",
      "Total Train Loss:  0.02992003932595253  Time:  2.500314950942993\n",
      "Total Valid Loss:  2.1023457050323486  Time:  0.039893150329589844\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 92 starts !\n",
      "Total Train Loss:  0.030421178302039272  Time:  2.846389055252075\n",
      "Total Valid Loss:  2.052014112472534  Time:  0.04487967491149902\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 93 starts !\n",
      "Total Train Loss:  0.029821792212517365  Time:  2.6319618225097656\n",
      "Total Valid Loss:  2.1380252838134766  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 94 starts !\n",
      "Total Train Loss:  0.030018128503275954  Time:  2.6898081302642822\n",
      "Total Valid Loss:  2.1633737087249756  Time:  0.05485200881958008\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 95 starts !\n",
      "Total Train Loss:  0.02959474407784317  Time:  2.366671562194824\n",
      "Total Valid Loss:  2.1141107082366943  Time:  0.02792501449584961\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 96 starts !\n",
      "Total Train Loss:  0.029842087626457216  Time:  2.169201135635376\n",
      "Total Valid Loss:  2.079392592112223  Time:  0.027927160263061523\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 97 starts !\n",
      "Total Train Loss:  0.029404900223016738  Time:  2.174184799194336\n",
      "Total Valid Loss:  2.117689291636149  Time:  0.030915498733520508\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 98 starts !\n",
      "Total Train Loss:  0.029507622965004133  Time:  2.1023776531219482\n",
      "Total Valid Loss:  2.117947260538737  Time:  0.029920578002929688\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 99 starts !\n",
      "Total Train Loss:  0.02982067867465641  Time:  2.2270472049713135\n",
      "Total Valid Loss:  2.1141275564829507  Time:  0.027925491333007812\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_none_xx1.model\n",
      "--id_bank: checkpoints/t1_none_xx1.pickle\n",
      "Run output files:\n",
      "Predict time:  76.1753396987915\n",
      "--validation: baseline_outputs\\xx1\\t1\\valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.650522635492 =======\n",
      "======= Set val : score(recall_10)=0.724508713385 =======\n",
      "======= Set val : score(recall_20)=0.770114942529 =======\n",
      "======= Set val : score(map_cut_10)=0.627338871527 =======\n",
      "===============\n",
      "Experiment finished successfully!\n",
      "dropout rate:  0.2\n",
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1\\train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(2698, 16)\n",
      "  (gmf_embedding_item): Embedding(1386, 16)\n",
      "  (mlp_embedding_user): Embedding(2698, 16)\n",
      "  (mlp_embedding_item): Embedding(1386, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (3): Linear(in_features=16, out_features=8, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=24, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.13112758449886155  Time:  1.930793285369873\n",
      "Total Valid Loss:  2.724071820576986  Time:  0.025930404663085938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.1021756829774898  Time:  2.020606279373169\n",
      "Total Valid Loss:  2.6355350812276206  Time:  0.024966716766357422\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.10007899008367373  Time:  2.2120418548583984\n",
      "Total Valid Loss:  2.6818994681040444  Time:  0.024932861328125\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.09912990538970284  Time:  2.1163439750671387\n",
      "Total Valid Loss:  2.543452819188436  Time:  0.025926828384399414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.09806721709344698  Time:  2.3207919597625732\n",
      "Total Valid Loss:  2.575798829396566  Time:  0.07081079483032227\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for _, do in enumerate([10, 0.1, 0.2, 0.3, 0.4, 0.5]):\n",
    "    args.drop_rate = do\n",
    "    ndcg = build(args)\n",
    "    print('dropout rate: ', do)\n",
    "    score.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jl1P2XMV_Aa2"
   },
   "outputs": [],
   "source": [
    "# Zip the run files into a single archive to prepare for submission \n",
    "run_dir = f'./baseline_outputs/{args.exp_name}/'   \n",
    "! cd {run_dir} && zip -r ../sample_run.zip ./\n",
    "\n",
    "print(\"*** Validating the submission Zip file ***\")\n",
    "# Run the validate_submission.py script to check if the file format is okay and get the performance on validation set.\n",
    "! python validate_submission.py ./baseline_outputs/sample_run.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "tmmoQyrFZN3x",
    "outputId": "ed843b45-8c6d-4d98-eec7-c6564b6c980d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = pd.DataFrame(score)\n",
    "a.columns = ['1e-5', '1e-6', '1e-7', '1e-8', '1e-9']\n",
    "a.rows = ['0.01', '0.008', '0.005', '0.003', '0.001', '0.0005', '0.0001']\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.axes().set_facecolor('white')\n",
    "sns.heatmap(a, vmin = 0,vmax=0.65,annot=True, fmt ='.3f', yticklabels=['0.01', '0.008', '0.005', '0.003', '0.001', '0.0005', '0.0001'])\n",
    "plt.tight_layout()\n",
    "plt.savefig('tune_lr_l2reg.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mea-DPqs4EnT",
    "outputId": "b2dc3534-bae7-467b-aa19-f354ba999a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(13135, 24)\n",
      "  (gmf_embedding_item): Embedding(3024, 24)\n",
      "  (mlp_embedding_user): Embedding(13135, 16)\n",
      "  (mlp_embedding_item): Embedding(3024, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=32, out_features=24, bias=True)\n",
      "    (2): Linear(in_features=24, out_features=16, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Pretrained weights from checkpoints/t1_none_newera.model are loaded!\n"
     ]
    }
   ],
   "source": [
    "args2 = deepcopy(args)\n",
    "model_dir = f'checkpoints/{args2.tgt_market}_{args2.src_markets}_{args2.exp_name}.model'\n",
    "id_bank_dir = f'checkpoints/{args2.tgt_market}_{args2.src_markets}_{args2.exp_name}.pickle'\n",
    "with open(id_bank_dir, 'rb') as centralid_file:\n",
    "    my_id_bank = pickle.load(centralid_file)\n",
    "mymodel = Model(args, my_id_bank)\n",
    "mymodel.load(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzw7hCVkZWcU",
    "outputId": "bd95ba34-7bc8-457b-f313-30b75e5098ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-3.7795046e-01, -3.4457183e-01, -3.1924966e-01,  3.7405184e-01,\n",
       "        -3.6592543e-01,  3.3929378e-01,  3.6263445e-01, -3.5807815e-01,\n",
       "        -3.8204446e-01, -3.1892782e-01,  3.6766115e-01,  3.3093750e-01,\n",
       "         4.2153841e-01, -3.9577463e-01,  3.4611386e-01,  3.2825613e-01,\n",
       "        -3.4050366e-01,  3.2440177e-01, -3.3866969e-01, -3.2769167e-01,\n",
       "        -3.8053679e-01,  3.7522858e-01,  3.2445052e-01, -3.6280113e-01,\n",
       "         7.9160117e-02,  4.6506548e-01, -4.7372818e-01, -1.2381218e-02,\n",
       "        -4.4568647e-02,  7.2960079e-01, -2.5297704e-01,  1.0679835e-01,\n",
       "        -8.5897315e-03, -3.5472799e-04, -6.2426411e-02, -1.7831250e-03,\n",
       "        -8.4843457e-02,  4.5015950e-02,  5.0447738e-01, -1.0182265e-01],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mymodel.model.affine_output.weight\n",
    "list(a.detach().numpy()) ## after decrease negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYNMcVFL_sGz",
    "outputId": "92f0f5ca-5e93-4b89-aa8d-8b99b9545e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cpu\n",
      "Loading target market t1: DATA/t1/train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Loading s1: DATA/s1/train_5core.tsv\n",
      "Loading s2: DATA/s2/train_5core.tsv\n",
      "Loaded source data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(14984, 20)\n",
      "  (gmf_embedding_item): Embedding(11074, 20)\n",
      "  (mlp_embedding_user): Embedding(14984, 20)\n",
      "  (mlp_embedding_item): Embedding(11074, 20)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=40, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): Linear(in_features=32, out_features=20, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.03772844553288256  Time:  295.6457488536835\n",
      "Total Valid Loss:  0.3337777058283488  Time:  0.032622575759887695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.030903027090977624  Time:  294.57435059547424\n",
      "Total Valid Loss:  0.31341519951820374  Time:  0.01981496810913086\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.029164034268839904  Time:  295.07062458992004\n",
      "Total Valid Loss:  0.3029489318529765  Time:  0.02999591827392578\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.02811793912425555  Time:  299.38079833984375\n",
      "Total Valid Loss:  0.3002041081587474  Time:  0.030794858932495117\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.02743012799287803  Time:  298.1150496006012\n",
      "Total Valid Loss:  0.3020112216472626  Time:  0.02256298065185547\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.026996018725919453  Time:  297.6443741321564\n",
      "Total Valid Loss:  0.3108907639980316  Time:  0.03329133987426758\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.02663390379426862  Time:  297.136043548584\n",
      "Total Valid Loss:  0.3148408631483714  Time:  0.030664682388305664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.026354580282065308  Time:  296.66896963119507\n",
      "Total Valid Loss:  0.3146276573340098  Time:  0.030657052993774414\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.026155844834288754  Time:  298.5436074733734\n",
      "Total Valid Loss:  0.30987916390101117  Time:  0.02457427978515625\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.025950638198943974  Time:  297.26723289489746\n",
      "Total Valid Loss:  0.32592536012331647  Time:  0.030779600143432617\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 starts !\n",
      "Total Train Loss:  0.02585947206305652  Time:  298.3940315246582\n",
      "Total Valid Loss:  0.312794307867686  Time:  0.03523707389831543\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11 starts !\n",
      "Total Train Loss:  0.02573915533700854  Time:  297.4334919452667\n",
      "Total Valid Loss:  0.3097074230511983  Time:  0.02184772491455078\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12 starts !\n",
      "Total Train Loss:  0.025664439790399778  Time:  298.50044417381287\n",
      "Total Valid Loss:  0.3023732900619507  Time:  0.03517556190490723\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13 starts !\n",
      "Total Train Loss:  0.025534095174662312  Time:  298.65261936187744\n",
      "Total Valid Loss:  0.31685978174209595  Time:  0.032831430435180664\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14 starts !\n",
      "Total Train Loss:  0.02546064083857257  Time:  299.2974627017975\n",
      "Total Valid Loss:  0.3269190788269043  Time:  0.03321433067321777\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15 starts !\n",
      "Total Train Loss:  0.02534535018039374  Time:  300.6588463783264\n",
      "Total Valid Loss:  0.3195504943529765  Time:  0.03500723838806152\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t1_s1-s2_nmfusesrc.model\n",
      "--id_bank: checkpoints/t1_s1-s2_nmfusesrc.pickle\n",
      "Run output files:\n",
      "Predict time:  368.97409200668335\n",
      "--validation: baseline_outputs/nmfusesrc/t1/valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.522105669095 =======\n",
      "======= Set val : score(recall_10)=0.637745643307 =======\n",
      "===============\n",
      "Experiment finished successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5221056690948465"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#args.pretrain = f'checkpoints/{args.tgt_market}_{args.src_markets}_{args.exp_name}.model'\n",
    "args.num_negative = 10\n",
    "args.num_epoch = 10\n",
    "args.batch_size = 1024\n",
    "args.fastmode = True\n",
    "args.use_qrel = False\n",
    "build(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHLdulGsaYOi",
    "outputId": "6e0eacb2-28ad-4446-df3e-c646238ca033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cpu\n",
      "Loading target market t2: DATA/t2/train_5core.tsv\n",
      "Loaded target data!\n",
      "\n",
      "Loading s2: DATA/s2/train_5core.tsv\n",
      "Loading s3: DATA/s3/train_5core.tsv\n",
      "Loaded source data!\n",
      "\n",
      "Model is NMF!\n",
      "NMF(\n",
      "  (gmf_embedding_user): Embedding(15920, 24)\n",
      "  (gmf_embedding_item): Embedding(4710, 24)\n",
      "  (mlp_embedding_user): Embedding(15920, 16)\n",
      "  (mlp_embedding_item): Embedding(4710, 16)\n",
      "  (fc_layers): ModuleList(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): Linear(in_features=32, out_features=24, bias=True)\n",
      "    (2): Linear(in_features=24, out_features=16, bias=True)\n",
      "  )\n",
      "  (affine_output): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (logistic): Sigmoid()\n",
      ")\n",
      "Epoch 0 starts !\n",
      "Total Train Loss:  0.037790112448195114  Time:  183.04605793952942\n",
      "Total Valid Loss:  0.4817862759033839  Time:  0.06336474418640137\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1 starts !\n",
      "Total Train Loss:  0.027865523623337073  Time:  180.96554446220398\n",
      "Total Valid Loss:  0.4265134632587433  Time:  0.06367897987365723\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 starts !\n",
      "Total Train Loss:  0.02449418571497383  Time:  181.1131956577301\n",
      "Total Valid Loss:  0.42005423208077747  Time:  0.05945611000061035\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 starts !\n",
      "Total Train Loss:  0.023099800065895657  Time:  178.97808289527893\n",
      "Total Valid Loss:  0.4407668064037959  Time:  0.07655930519104004\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 starts !\n",
      "Total Train Loss:  0.022243520018952197  Time:  179.406165599823\n",
      "Total Valid Loss:  0.4382022072871526  Time:  0.07250165939331055\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 starts !\n",
      "Total Train Loss:  0.02160427537940753  Time:  177.5764434337616\n",
      "Total Valid Loss:  0.42709126075108844  Time:  0.06085920333862305\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 starts !\n",
      "Total Train Loss:  0.02126133181823038  Time:  179.70502305030823\n",
      "Total Valid Loss:  0.4288342495759328  Time:  0.08015179634094238\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 starts !\n",
      "Total Train Loss:  0.020835195714751557  Time:  180.59925651550293\n",
      "Total Valid Loss:  0.42658480008443195  Time:  0.055449724197387695\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 starts !\n",
      "Total Train Loss:  0.02057453663480744  Time:  180.9960572719574\n",
      "Total Valid Loss:  0.423382302125295  Time:  0.07438325881958008\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 starts !\n",
      "Total Train Loss:  0.02043244066572012  Time:  178.37274050712585\n",
      "Total Valid Loss:  0.4250189910332362  Time:  1.2051289081573486\n",
      "--------------------------------------------------------------------------------\n",
      "Model is trained! and saved at:\n",
      "--model: checkpoints/t2_s2-s3_newera.model\n",
      "--id_bank: checkpoints/t2_s2-s3_newera.pickle\n",
      "Run output files:\n",
      "Predict time:  471.84324502944946\n",
      "--validation: baseline_outputs/newera/t2/valid_pred.tsv\n",
      "Evaluating the validation set\n",
      " \n",
      "======= Set val : score(ndcg_cut_10)=0.480431740825 =======\n",
      "======= Set val : score(recall_10)=0.575155052900 =======\n",
      "===============\n",
      "Experiment finished successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48043174082500556"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args2 = deepcopy(args)\n",
    "args2.tgt_market = 't2'\n",
    "args2.src_markets = 's2-s3'\n",
    "args2.use_qrel = False\n",
    "args2.pretrain = None\n",
    "args2.sample_func= lambda:random.uniform(0,0.2)\n",
    "#args2.pretrain = f'checkpoints/{args2.tgt_market}_{args2.src_markets}_{args2.exp_name}.model'\n",
    "args2.tgt_market_valid = f'DATA/{args2.tgt_market}/valid_run.tsv'\n",
    "args2.tgt_market_test = f'DATA/{args2.tgt_market}/test_run.tsv'\n",
    "args2.idbank_pretrain = None\n",
    "args2.num_negative = 15\n",
    "args2.batch_size = 1024\n",
    "args2.num_epoch = 10\n",
    "args2.lr = 0.01\n",
    "args2.fastmode = True\n",
    "build(args2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njDvcokxz6sW"
   },
   "outputs": [],
   "source": [
    "# load pretrained model \n",
    "model_dir = f'checkpoints/{args.tgt_market}_{args.src_markets}_{args.exp_name}.model'\n",
    "id_bank_dir = f'checkpoints/{args.tgt_market}_{args.src_markets}_{args.exp_name}.pickle'\n",
    "\n",
    "with open(id_bank_dir, 'rb') as centralid_file:\n",
    "    my_id_bank= pickle.load(centralid_file)\n",
    "\n",
    "mymodel = Model(args, my_id_bank)\n",
    "mymodel.load(model_dir)\n",
    "############\n",
    "## Target Market Evaluation data\n",
    "############\n",
    "tgt_task_generator = TaskGenerator(my_id_bank)\n",
    "args.batch_size = 2048\n",
    "#tgt_valid_dataloader = tgt_task_generator.instance_a_market_valid_dataloader(args.tgt_market_valid, args.batch_size)\n",
    "tgt_test_dataloader = tgt_task_generator.instance_a_market_valid_dataloader(args.tgt_market_test, args.batch_size)\n",
    "print('loaded target test data!')\n",
    "test_run_mf = mymodel.predict(tgt_test_dataloader)\n",
    "write_run_file(test_run_mf, os.path.join('baseline_outputs', args.exp_name, args.tgt_market, 'test_pred.tsv'))\n",
    "#valid_run_mf = mymodel.predict(tgt_valid_dataloader)\n",
    "#write_run_file(valid_run_mf, os.path.join('baseline_outputs', args.exp_name, args.tgt_market, 'valid_pred.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "for i in range(4105, 4151):\n",
    "    pil_im = Image.open(fr\"C:\\Users\\HAI.NH194039\\Documents\\Nhp mn AI\\New folder\\IMG_{i}.JPG\", 'r')\n",
    "    w,h = pil_im.size\n",
    "    left = 850\n",
    "    top = 500\n",
    "    right = w-150\n",
    "    bottom = h-450\n",
    "    im1 = pil_im.crop((left, top, right, bottom))\n",
    "    #imshow(np.asarray(im1))\n",
    "    im1.save(fr'C:\\Users\\HAI.NH194039\\Documents\\Nhp mn AI\\dethi\\IMG_{i}.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (4124,):\n",
    "    pil_im = Image.open(fr\"C:\\Users\\HAI.NH194039\\Documents\\Nhp mn AI\\New folder\\IMG_{i}.JPG\", 'r')\n",
    "    w,h = pil_im.size\n",
    "    left = 700\n",
    "    top = 500\n",
    "    right = w-300\n",
    "    bottom = h-450\n",
    "    im1 = pil_im.crop((left, top, right, bottom))\n",
    "    #imshow(np.asarray(im1))\n",
    "    im1.save(fr'C:\\Users\\HAI.NH194039\\Documents\\Nhp mn AI\\dethi\\IMG_{i}.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "recsys-team10-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (rs4)",
   "language": "python",
   "name": "rs4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
